## =============================================================================
## COMBINED SCRIPTS - auto-generated by combine_scripts.py
## Files included: 38
## =============================================================================



## ===========================================================================
## FILE: ActionModules\Add_Outcomes_to_Active_Courses.py
## ===========================================================================

# Author: Bryce Miller - brycezmiller@nnu.edu
# Last Updated by: Bryce Miller

## Import Generic Moduels
import os, sys, traceback, requests, re, threading, math, json
from datetime import datetime, date, timedelta
from dateutil import parser
import pandas as pd

## Add Script repository to syspath
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

# Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = __file__.replace(".py", "")

scriptPurpose = r"""
The Outcome Exporter script is to copy the most recent relative outcome/s into the courses that need them.
"""
externalRequirements = r"""
To function properly this script requires a spreadsheet of the most recent outcomes and the courses they are assigned to.
"""

## Initialize LocalSetup and resource helpers
try: ## Irregular try clause, do not comment out in testing
    from Local_Setup import LocalSetup
    from TLC_Common import makeApiCall
    from Canvas_Report import CanvasReport
    from Error_Email import errorEmail

except ImportError:
    from ResourceModules.Local_Setup import LocalSetup
    from ResourceModules.TLC_Common import makeApiCall
    from ResourceModules.Canvas_Report import CanvasReport
    from ResourceModules.Error_Email import errorEmail

# Create LocalSetup and localSetup.logger
localSetup = LocalSetup(datetime.now(), __file__)

## Bring in action module functions
from Outcome_Attachment_Report import termOutcomeAttachmentReport
from Outcome_Results_Report import termProcessOutcomeResults
from Common_Configs import coreCanvasApiUrl

## Setup error handlerF
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

todaysDateDateTime = datetime.now()

## This function takes in a start date and end date and returns what course week the course is currently in and what week the final week is
def determineCourseWeek (p1_startDate, p2_endDate):
    
    ## Record the course start and end date as date time variables
    courseStartDateTime = datetime.strptime(p1_startDate, "%m/%d/%Y") + timedelta(weeks=3) ## Add 3 weeks as the sis date sent over is always 3 weeks earlier than the actual start date
    courseEndDateTime = datetime.strptime(p2_endDate, "%m/%d/%Y") - timedelta(weeks=3) ## Subtract 3 weeks as the sis date sent over is always 3 weeks earlier than the actual start date

    ## Determine the course's final week (e.g. 16 if it is a 16 week course)
    courseFinalWeek = math.ceil((courseEndDateTime - courseStartDateTime).days / 7) ## Round up as even a partial week is a week 

    ## Record the day of the week that the course starts
    courseStartWeekDay = courseStartDateTime.weekday()

    ## Determine what week the course is currently in
    courseWeek = (((todaysDateDateTime - (courseStartDateTime- timedelta(days=courseStartWeekDay))).days // 7) + 1) ## Add one week to make the first week be considered week 1

    ## Return the course week and the course final week
    return courseWeek, courseFinalWeek

## This function retrieves the data neccessary for determining and sending out relevent communication
def retrieveDataForRelevantCommunication (p2_inputTerm
                                          , p3_targetDesignator
                                          ):
    
    functionName = "Retrieve Data For Relevant Communication"
    
    try:
    
        ## Define an auxillary data dict and auxillary df dict
        auxillaryDataDict = {}
        auxillaryDFDict = {}

        ## Get the year of the term
        termYear = int(f"{localSetup.dateDict['century']}{p2_inputTerm[2:]}")
        termPrefix = p2_inputTerm[:2]
        termWord = localSetup._determineTermName(termPrefix)

        ## Define the current school year
        auxillaryDataDict["Target School Year"] = localSetup._determineSchoolYear(termWord, termYear)

        ## Retrieve the df of Active outcome courses which includes course code, required outcome/s, and the relevant instructor name/s, id/s, and email/s
        rawActiveOutcomeCourseDf = CanvasReport.getActiveOutcomeCoursesDf(localSetup, p2_inputTerm, p3_targetDesignator)

        ## If the raw active outcome course df is empty
        if rawActiveOutcomeCourseDf.empty:

            ## Return an empty dataframe for the active outcome courses df and the auxillary df dict
            return rawActiveOutcomeCourseDf, auxillaryDFDict
        
        ## Make a list of the unique outcomes that are not blank 
        ## and a dict to hold the course id of the course named after each outcome
        auxillaryDFDict["Unique Outcomes"], auxillaryDFDict["Outcome Canvas Data Dict"] = getUniqueOutcomesAndOutcomeCoursesDict(p2_inputTerm, rawActiveOutcomeCourseDf, p3_targetDesignator)
        
        ## Remove any outcomes that don't have corresponding courses
        auxillaryDFDict["Active Outcome Courses DF"] = removeMissingOutcomes (
            rawActiveOutcomeCourseDf
            , auxillaryDFDict["Unique Outcomes"]
            , auxillaryDFDict["Outcome Canvas Data Dict"]
            )
        
        ## Retrieve the csv of courses being uploaded to Canvas
        rawTermSisCoursesDF = pd.read_csv(f"{localSetup.getExternalResourcePath('SIS')}canvas_course.csv")

        ## Keep only the courses with a status of active and a term_id of the input term
        activeSisCoursesDF = rawTermSisCoursesDF[(rawTermSisCoursesDF["status"] == "active") 
                                                 & (rawTermSisCoursesDF["term_id"] == p2_inputTerm)]

        ## Remove all columns from the active Sis courses df except the course_id column, the start_date, and the end_date
        reducedActiveSisCoursesDF = activeSisCoursesDF[["course_id", "start_date", "end_date"]]

        ## Get the raw term canvas courses df
        rawTermCanvasCoursesDF = CanvasReport.getCoursesDf(localSetup, p2_inputTerm)

        ## Reset the index to ensure unique indices
        rawTermCanvasCoursesDF.reset_index(drop=True, inplace=True)

        ## Keep only the courses that are active and created_by_sis
        activeCanvasCoursesDF = rawTermCanvasCoursesDF[(rawTermCanvasCoursesDF["status"] != "deleted") 
                                                       & (rawTermCanvasCoursesDF["created_by_sis"] == True)]

        ## Add a Parent_Course_sis_id column to the completeActiveCanvasCoursesDF
        activeCanvasCoursesDF["Parent_Course_sis_id"] = ""

        ## Merge the two DataFrames prioritizing the start_date and end_date from reducedActiveSisCoursesDF
        ## and then using the data from rawCompleteActiveCanvasCoursesDF where the value from reducedActiveSisCoursesDF is nan or ""
        rawCompleteActiveCanvasCoursesDF = pd.merge(
            activeCanvasCoursesDF,
            reducedActiveSisCoursesDF,
            on="course_id",
            how="left",
            suffixes=('', '_sis')
        )


        ## Fill the start_date and end_date in rawCompleteActiveCanvasCoursesDF with the values from reducedActiveSisCoursesDF where they are nan or ""
        rawCompleteActiveCanvasCoursesDF['start_date'] = rawCompleteActiveCanvasCoursesDF['start_date_sis'].combine_first(rawCompleteActiveCanvasCoursesDF['start_date'])
        rawCompleteActiveCanvasCoursesDF['end_date'] = rawCompleteActiveCanvasCoursesDF['end_date_sis'].combine_first(rawCompleteActiveCanvasCoursesDF['end_date'])

        ## For any rows of auxillaryDFDict["Active Outcome Courses DF"] where there is a non nan Parent_Course_sis_id value
        for index, row in auxillaryDFDict["Active Outcome Courses DF"].dropna(subset=['Parent_Course_sis_id']).iterrows():

            ## Define a target course sis id
            targetCourseSisId = None

            ## If there is a parent course id
            if not pd.isna(row["Parent_Course_sis_id"]) and row["Parent_Course_sis_id"] not in ["", None]:

                ## Define the target course sis id as the parent course id
                targetCourseSisId = row["Parent_Course_sis_id"]

            ## If there is no parent course id
            else:

                ## Define the target course sis id as the course id
                targetCourseSisId = row['Course_sis_id']

            ## Get the index of the rawCompleteActiveCanvasCoursesDF that matches the course id
            index = rawCompleteActiveCanvasCoursesDF[rawCompleteActiveCanvasCoursesDF["course_id"] == targetCourseSisId].index[0]

            ## Set the Parent_Course_sis_id value in the rawCompleteActiveCanvasCoursesDF to the Parent_Course_sis_id value in the auxillaryDFDict["Active Outcome Courses DF"]
            rawCompleteActiveCanvasCoursesDF.at[index, "Parent_Course_sis_id"] = row["Parent_Course_sis_id"]

        ## Retrieve the all terms file
        allCanvasTermsDf = CanvasReport.getTermsDf(localSetup)

        ## Drop the temporary columns
        rawCompleteActiveCanvasCoursesDF.drop(columns=['start_date_sis', 'end_date_sis'], inplace=True)

        ## Keep only the rows that have a canvas course id and a start_date
        completeActiveCanvasCoursesDF = rawCompleteActiveCanvasCoursesDF[
            (
                pd.notna(
                    rawCompleteActiveCanvasCoursesDF["canvas_course_id"]
                    )
             )
            & (
                pd.notna(
                    rawCompleteActiveCanvasCoursesDF["start_date"]
                    )
               )
            ]

        ## For each row in the completeActiveCanvasCoursesDF 
        for index, row in completeActiveCanvasCoursesDF.iterrows():

            ## If there is a parent course sis id
            if (
               not pd.isna(row["Parent_Course_sis_id"]) 
                and row["Parent_Course_sis_id"] not in ["", None]
                    ):

                ## Find the index of the parent course sis id
                parent_index = rawCompleteActiveCanvasCoursesDF[rawCompleteActiveCanvasCoursesDF["course_id"] == row["Parent_Course_sis_id"]].index[0]

                ## Set the start_date value from the parent course to the value for the row
                row["start_date"] = rawCompleteActiveCanvasCoursesDF.at[parent_index, "start_date"]

                ## Set the end_date value from the parent course to the value for the row
                row["end_date"] = rawCompleteActiveCanvasCoursesDF.at[parent_index, "end_date"]

            ## Retrieve the Term of the course
            courseTerm = rawCompleteActiveCanvasCoursesDF.at[index, "term_id"]

            ## Get the index of the term within the term_id column of the allCanvasTermsDf
            term_index = allCanvasTermsDf[allCanvasTermsDf["term_id"] == courseTerm].index[0]
                    
            ## If the start date is nan or blank
            if not str(row["start_date"]) or str(row["start_date"]) == "nan":

                ## Set the start_date value from the term to the value for the row
                row["start_date"] = allCanvasTermsDf.at[term_index, "start_date"]

            ## If the end date is nan or blank
            if not str(row["end_date"]) or str(row["end_date"]) == "nan":

                ## Set the end_date value from the term to the value for the row
                row["end_date"] = allCanvasTermsDf.at[term_index, "end_date"]

            ## Get the start date and end date from the row
            start_date = parser.parse(row["start_date"])
            end_date = parser.parse(row["end_date"])

            ## Transform both to %m%d%Y format
            start_date = start_date.strftime("%m/%d/%Y")
            end_date = end_date.strftime("%m/%d/%Y")

            ## Set the start_date and end_date values in the rawCompleteActiveCanvasCoursesDF to the reformatted values
            completeActiveCanvasCoursesDF.at[index, "start_date"] = start_date
            completeActiveCanvasCoursesDF.at[index, "end_date"] = end_date

        ## If the complete active canvas courses df is empty
        if completeActiveCanvasCoursesDF.empty:
            
            ## Return an empty dataframe for the active outcome courses df and the auxillary df dict
            return completeActiveCanvasCoursesDF, auxillaryDFDict
            
        ## Define the term related path to the outcome attachment report
        termOutcomeAttachmentReportPath = termOutcomeAttachmentReport(p2_inputTerm, p3_targetDesignator)
        auxillaryDFDict["Outcome Courses Without Attachments DF"] = pd.read_csv(termOutcomeAttachmentReportPath)

        ## Define the term related path to the outcome results report
        termProcessOutcomeResultsPath = termProcessOutcomeResults(p2_inputTerm, p3_targetDesignator)[0]
        outcomeCoursesDataDF = pd.read_excel(termProcessOutcomeResultsPath)

        ## Create a df of outcome courses that have not been assessed
        auxillaryDFDict["Unassessed Outcome Courses DF"] = outcomeCoursesDataDF[outcomeCoursesDataDF["Assessment_Status"] != "Assessed"]
            
        ## Create a new "Course Week" column and a "Course Final Week" column in the complete active canvas courses df by sending the start and end dates to determineCourseWeek
        completeActiveCanvasCoursesDF["Course Week"], completeActiveCanvasCoursesDF["Course Final Week"] = zip(
            *completeActiveCanvasCoursesDF.apply(
                lambda row: determineCourseWeek(
                    row["start_date"]
                    , row["end_date"]
                    )
                , axis=1
                )
            )
        
        ## Return the active outcome courses df, the complete active canvas courses df, and the auxillary df dict
        return completeActiveCanvasCoursesDF, auxillaryDFDict

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This function processes the rows of the CSV file and sends on the relavent data to process_course
def addOutcomeToCourse (targetCourseDataDict
                        , auxillaryDFDict
                        ):
    functionName = "Add Outcome/s to courses"

    try:
        
        ## If the targetCourseDataDict's course_sis_id is not in the aux df dict's active outcome course df,
        ## or if it is empty, skip it
        if (targetCourseDataDict['course_id'] not in auxillaryDFDict["Active Outcome Courses DF"]["Course_sis_id"].values 
            or not targetCourseDataDict['course_id']):
            return

        ## Get the index of the course_id with the auxillaryDFDict's Active Outcome Courses Df
        targetCourseActiveOutcomeCourseDfIndex = auxillaryDFDict["Active Outcome Courses DF"][auxillaryDFDict["Active Outcome Courses DF"]["Course_sis_id"] == targetCourseDataDict['course_id']].index[0]

        ## Get the row of the targetCourseActiveOutcomeCourseDfIndex as a dict
        targetCourseActiveOutcomeCourseDataDict = auxillaryDFDict["Active Outcome Courses DF"].loc[targetCourseActiveOutcomeCourseDfIndex].to_dict()

        ## For each targetCourseDataDict in our CSV file pull the course sis id column and outcome column names
        ## Sample sess values: FA2022_PHIL2030_01
        ## Sample outcome value: GE_CF4_V1.0
        targetCourseSisId = None
        outcomeKeys = [col for col in targetCourseActiveOutcomeCourseDataDict.keys() if "Outcome" in col and "Area" not in col]

        ## If there is a parent course id
        if (
            pd.isna(targetCourseDataDict["Parent_Course_sis_id"]) 
            and targetCourseDataDict["Parent_Course_sis_id"] not in ["", None]
            ):

                ## Define the target course sis id as the parent course id
                targetCourseSisId = targetCourseDataDict["Parent_Course_sis_id"]

        ## If there is no parent course id
        else:

            ## Define the target course sis id as the course id
            targetCourseSisId = targetCourseDataDict['course_id']
            
        ## Log the start of the process
        localSetup.logger.info("\n     Course:" + targetCourseDataDict['course_id'])

        ## Create the base course API urls
        baseCourseApiUrl = f"{coreCanvasApiUrl}courses/sis_course_id:{targetCourseSisId}"
        # contentMigrationApiUrl = baseCourseApiUrl + "/content_migrations"
        
        # ## Make a content migration API call to find out what content has already been copied to the course
        # courseMigrationsObject = makeApiCall(localSetup, p1_apiUrl=contentMigrationApiUrl)
        
        # ## If the API status code is anything other than 200 it is an error, so log it and skip
        # if (courseMigrationsObject.status_code != 200):
        #     localSetup.logger.error("\nCourse Error: " + str(courseMigrationsObject.status_code))
        #     localSetup.logger.error(contentMigrationApiUrl)
        #     localSetup.logger.error(courseMigrationsObject.url)
        #     return
        
        # ## If the API status code is 200, save the result as courseMigrations
        # courseMigrations = courseMigrationsObject.json()
        
        ## For each outcome in the targetCourseDataDict
        for outcome in outcomeKeys:
            
            ## If the outcome is empty skip it
            if pd.isna(targetCourseActiveOutcomeCourseDataDict[outcome]) or not targetCourseActiveOutcomeCourseDataDict[outcome] or not outcome or pd.isna(outcome):
                continue

            ## Get the outcome canvas data dict from the auxillary df dict
            outcomeCanvasData = auxillaryDFDict[
                "Outcome Canvas Data Dict"
                ][
                    targetCourseActiveOutcomeCourseDataDict[
                        outcome
                        ]
                    ]

            ## Define the API url to get the outcome groups of the course
            courseOutcomeGroupsApiUrl = f"{baseCourseApiUrl}/outcome_groups"

            ## Make the API call to get the outcome groups of the course
            courseOutcomeGroupsObject = makeApiCall(localSetup, p1_apiUrl=courseOutcomeGroupsApiUrl)

            ## If the API status code is anything other than 200 it is an error, so log it and skip
            if (courseOutcomeGroupsObject.status_code != 200):
                localSetup.logger.error("\nCourse Error: " + str(courseOutcomeGroupsObject.status_code))
                localSetup.logger.error(courseOutcomeGroupsApiUrl)
                localSetup.logger.error(courseOutcomeGroupsObject.url)
                continue

            ## Define a variable to hold the whether the course already has the outcome group and another to hold its canvas id
            outcomeGroupAlreadyInCourse = False
            outcomeGroupCanvasIdInCourse = None

            ## Define a variable to hold the outcome group id of the course itself in case the outcome group needs to be added to the course
            courseOutcomeGroupCanvasId = None

            ## For each outcome group in the course outcome groups object
            for courseOutcomeGroup in courseOutcomeGroupsObject.json():
                
                ## If the title contains the target sis id 
                if targetCourseSisId in courseOutcomeGroup['title']:
                    ## Set the course outcome group canvas id to the id of the outcome group
                    courseOutcomeGroupCanvasId = courseOutcomeGroup['id']
                    if outcomeCanvasData["Outcome Group is Root Account"]:
                        outcomeGroupAlreadyInCourse = True
                        outcomeGroupCanvasIdInCourse = courseOutcomeGroup['id']


                ## Else if the the title is equal to the outcome group title from the outcome canvas data dict
                elif courseOutcomeGroup['title'] == outcomeCanvasData["Outcome Group Title"] or courseOutcomeGroup['title'] == outcomeCanvasData["Outcome Group Id"]:
                    ## Set the outcome group already in course variable to true
                    outcomeGroupAlreadyInCourse = True
                    outcomeGroupCanvasIdInCourse = courseOutcomeGroup['id']
                    ## Break out of the loop
                    break

            if courseOutcomeGroupCanvasId is None:
                rootOutcomeGroupApiUrl = f"{baseCourseApiUrl}/root_outcome_group"

                rootOutcomeGroupObject = makeApiCall(localSetup, p1_apiUrl=rootOutcomeGroupApiUrl)

                if (rootOutcomeGroupObject.status_code != 200):
                    localSetup.logger.error("\nCourse Error: " + str(rootOutcomeGroupObject.status_code))
                    localSetup.logger.error(rootOutcomeGroupApiUrl)
                    localSetup.logger.error(rootOutcomeGroupObject.url)
                    continue

                courseOutcomeGroupCanvasId = rootOutcomeGroupObject.json()['id']

            ## If the outcome group is not already in the course
            if not outcomeGroupAlreadyInCourse:

                ## Define the API url to add the outcome group to the course using the course outcome group canvas id
                addOutcomeGroupToCourseApiUrl = f"{baseCourseApiUrl}/outcome_groups/{courseOutcomeGroupCanvasId}/import"

                ## Define the API payload to add the outcome group to the course
                addOutcomeGroupToCourseApiPayload = {
                    "source_outcome_group_id": outcomeCanvasData["Outcome Group Id"],
                    }

                ## Make the API call to add the outcome group to the course
                addOutcomeGroupToCourseObject = makeApiCall(
                    localSetup, 
                    p1_apiUrl=addOutcomeGroupToCourseApiUrl, 
                    p1_payload=addOutcomeGroupToCourseApiPayload, 
                    p1_apiCallType="post"
                    )

                ## If the API status code is anything other than 200 it is an error, so log it and skip
                if (addOutcomeGroupToCourseObject.status_code != 200):
                    localSetup.logger.error("\nCourse Error: " + str(addOutcomeGroupToCourseObject.status_code))
                    localSetup.logger.error(addOutcomeGroupToCourseApiUrl)
                    localSetup.logger.error(addOutcomeGroupToCourseObject.url)
                    continue

                ## Log the fact that the outcome group has been added to the course
                localSetup.logger.info(f"\n {targetCourseSisId} has been added outcome group {outcomeCanvasData['Outcome Group Title']}")

                ## Retrieve the ooutcomeGroupCanvasIdInCourse from the API call response
                outcomeGroupCanvasIdInCourse = addOutcomeGroupToCourseObject.json()['id']

            ## Define the API url to add the outcome to the course outcome group
            addOutcomeToCourseApiUrl = f"{baseCourseApiUrl}/outcome_groups/{outcomeGroupCanvasIdInCourse}/outcomes/{outcomeCanvasData['Outcome Canvas Id']}"

            ## Make the API call to add the outcome to the course
            addOutcomeToCourseObject = makeApiCall(localSetup, p1_apiUrl=addOutcomeToCourseApiUrl, p1_apiCallType="put")

            ## If the API status code is anything other than 200 it is an error, so log it and skip
            if (addOutcomeToCourseObject.status_code != 200):
                localSetup.logger.error("\nCourse Error: " + str(addOutcomeToCourseObject.status_code))
                localSetup.logger.error(addOutcomeToCourseApiUrl)
                localSetup.logger.error(addOutcomeToCourseObject.url)
                continue

            ## Log the fact that the outcome has been added to the course
            localSetup.logger.info(f"\n {targetCourseSisId} has had outcome {targetCourseActiveOutcomeCourseDataDict[outcome]} added")
            
            ## If a migration that has settings has the outcome name in the migration's setting's source course name and has a status of completed
            # if any([migration['settings']['source_course_id'] == outcomeCourseCanvasId and migration['workflow_state'] == 'completed' for migration in courseMigrations if 'settings' in migration.keys()]):

            #     ## Log the fact that the outcome has already been copied in
            #     localSetup.logger.info(f"\n {targetCourseSisId} already has {targetCourseActiveOutcomeCourseDataDict[outcome]}")

            #     ## Skip to the next outcome
            #     continue

            ## Create the API Payload from the outcome sis id
            #payload = {'migration_type': 'course_copy_importer', 'settings[source_course_id]': [outcomeCourseCanvasId], 'selective_import': True}
                
            ## Make the API call and save the result as course_object
            # courseCopyObject = makeApiCall(localSetup, p1_apiUrl=contentMigrationApiUrl, p1_payload=payload, p1_apiCallType="post")
            
            # ## Turn the text of the API call into a json object
            # courseCopy = courseCopyObject.json()

            # ## Define the list items endpoint api url using the migration id
            # listSelectiveImportItemsApiUrl = f"{contentMigrationApiUrl}/{courseCopy['id']}/selective_data"

            # ## Make a get request to the list items endpoint
            # listSelectiveImportItemsObject = makeApiCall(localSetup, p1_apiUrl=listSelectiveImportItemsApiUrl)

            # ## If the API status code is anything other than 200 it is an error, so log it and skip
            # if (listSelectiveImportItemsObject.status_code != 200):
            #     localSetup.logger.error("\nCourse Error: " + str(listSelectiveImportItemsObject.status_code))
            #     localSetup.logger.error(listSelectiveImportItemsApiUrl)
            #     localSetup.logger.error(listSelectiveImportItemsObject.url)
            #     continue
            
            # ## Turn the text of the API call into a json object
            # listSelectiveImportItems = listSelectiveImportItemsObject.json()

            # ## Find the list item that has the learning_outcomes as the value of the type key
            # learningOutcomesListItem = [item for item in listSelectiveImportItems if item['type'] == 'learning_outcomes'][0]

            # ## Save the value of the property key of the learning_outcomes list item as as the selected import item
            # selectedImportItem = learningOutcomesListItem['property']

            # ## Define a payload with the selected import item = 1
            # updateContentMigrationApiPayload = {selectedImportItem: 1}

            # ## Define the update content migration api url using the course copy id
            # updateContentMigrationApiUrl = f"{contentMigrationApiUrl}/{courseCopy['id']}"

            # ## Make a put request to the update content migration api url with the update content migration api payload
            # updateContentMigrationObject = makeApiCall(localSetup, p1_apiUrl=updateContentMigrationApiUrl, p1_payload=updateContentMigrationApiPayload, p1_apiCallType="put")

            # ## If the API status code is anything other than 200 it is an error, so log it and skip
            # if (updateContentMigrationObject.status_code != 200):
            #     localSetup.logger.error("\nCourse Error: " + str(updateContentMigrationObject.status_code))
            #     localSetup.logger.error(updateContentMigrationApiUrl)
            #     localSetup.logger.error(updateContentMigrationObject.url)
            #     continue

            # ## Log the fact that the outcome has been copied in
            # localSetup.logger.info(f"\n {targetCourseSisId} has {targetCourseActiveOutcomeCourseDataDict[outcome]}")



    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function removes any outcomes that don't have corresponding courses
def removeMissingOutcomes (p1_activeOutcomeCourseDf, p1_uniqueOutcomes, p1_outcomeCanvasDataDict):
    functionName = "Remove Missing Outcomes"

    try:

        ## Get a list of all unique outcomes that are not in the keys of the outcomeCanvasDataDict
        missingOutcomes = [outcome for outcome in p1_uniqueOutcomes if outcome not in p1_outcomeCanvasDataDict.keys()]
        
        ## If there are missing outcomes
        if missingOutcomes:
            
            ## For each row of the active outcome course df
            for index, row in p1_activeOutcomeCourseDf.iterrows():
                
                ## Create a list of the outcome columns in the row
                outcomesColumns = [col for col in row.keys() if "Outcome" in col and "Area" not in col]
                
                ## For each outcome column in the row
                for outcome in outcomesColumns:
                    
                    ## If the outcome is in the missing outcomes list
                    if row[outcome] in missingOutcomes:
                        
                        ## Replace it with a blank string
                        p1_activeOutcomeCourseDf.loc[index, outcome] = ""

                        ## Send an error email about the missing outcome
                        errorHandler.sendError (f"External Input Error: {functionName}", f"Outcome Missing Import Course: {row[outcome]}")
                        
                ## If all outcome values in the row are blank strings
                if all([pd.isna(row[outcome]) for outcome in outcomesColumns]):
                    
                    ## Drop the row
                    p1_activeOutcomeCourseDf.drop(index, inplace=True)

        ## Return the active outcome course df
        return p1_activeOutcomeCourseDf
    
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function returns a dict with the course id of the course named after each outcome
def getUniqueOutcomesAndOutcomeCoursesDict (p3_inputTerm, p1_activeOutcomeCourseDf, p4_targetDesignator):
    functionName = "Get Unique Outcomes And Outcome Courses Dict"
    
    try:

        ## Make a df with one collumn where all outcome columns that don't have area in the name are stacked
        targetOutcomesDF = p1_activeOutcomeCourseDf[[col for col in p1_activeOutcomeCourseDf.columns if "Outcome" in col and "Area" not in col]].stack().reset_index(drop=True)
        
        ## Make a list of the unique outcomes that are not blank
        uniqueTargetOutcomes = [outcome for outcome in targetOutcomesDF.unique() 
                          if (
                              pd.notna(outcome)
                              and str(outcome).strip() not in ("", "nan", "none", "NaN", "None")
                              )
                          ]

        ## Retrieve the Automated Outcome Tool Variables excel file as a df    
        automatedOutcomeToolVariablesDf = pd.read_excel(
            os.path.join(
                localSetup.getExternalResourcePath("TLC"), 
                "Automated Outcome Tool Variables.xlsx"
                )
        )

        ## Get the account name associated with the target designator
        targetAccountName = automatedOutcomeToolVariablesDf.loc[
            automatedOutcomeToolVariablesDf["Target Designator"] == p4_targetDesignator, 
            "Outcome Location Account Name"
            ].values[0]

        ## Open the p4_targetDesignator relevant outcome df
        targetDesignatorCanvasOutcomeDf = CanvasReport.getOutcomesDf(localSetup, p3_inputTerm, targetAccountName, p4_targetDesignator)

        ## Open the accounts df
        accountsDf = CanvasReport.getAccountsDf(localSetup)

        ## Get the target account id from the accounts df using the target account name
        targetCanvasAccountId = accountsDf.loc[accountsDf["name"] == targetAccountName, "canvas_account_id"].values[0]

        ## Define a dict to hold tail of the api url to add the outcome to a course
        uniqueOutcomesCanvasData = {}

        ## For each outcome in the unique target outcomes list
        for outcome in uniqueTargetOutcomes:

            ## Get the index of the outcome from the title column of the targetDesignatorCanvasOutcomeDf
            outcomeIndexSearch = targetDesignatorCanvasOutcomeDf[targetDesignatorCanvasOutcomeDf['title'] == outcome].index

            ## If the outcomeIndexs is empty
            if outcomeIndexSearch.empty:
                
                ## Log the fact that the outcome was not found
                localSetup.logger.error(f"\nOutcome not found: {outcome}")
                    
                ## Email the fact that the outcome was not found
                errorHandler.sendError (f"External Input Error: {functionName}", f"Outcome not found: {outcome}")
                ## Skip to the next outcome
                continue

            ## Use the outcome index to get the vendor_guid from the outcome with the outcome as the title
            outcomeParentGuid = targetDesignatorCanvasOutcomeDf.loc[outcomeIndexSearch[0], 'parent_guids']

            ## Define the API url to add the outcome to the course using the target canvas account id 
            ## and the outcome parent guid and outcome vendor guid
            outcomeGroupsApiUrl = f"{coreCanvasApiUrl}accounts/{targetCanvasAccountId}/outcome_groups"

            ## Make an API call to get the outcome groups in the target account
            outcomeGroupsObject = makeApiCall(localSetup, p1_apiUrl=outcomeGroupsApiUrl)

            ## If the API status code is anything other than 200 it is an error, so log it and skip`
            if (outcomeGroupsObject.status_code != 200):
                localSetup.logger.error("\nCourse Error: " + str(outcomeGroupsObject.status_code))
                localSetup.logger.error(outcomeGroupsApiUrl)
                localSetup.logger.error(outcomeGroupsObject.url)
                continue

            ## Define a variable to hold the outcome group Canvas id
            outcomeGroupCanvasId = None

            ## For each outcome group in the outcome groups object
            for outcomeGroup in outcomeGroupsObject.json():
                
                ## If the outcomeParentGuid is nan
                if (
                    pd.isna(outcomeParentGuid) 
                    or not outcomeParentGuid 
                    or str(outcomeParentGuid).strip() in ("", "nan", "none", "NaN", "None")
                    ):
                    ## The outcome is in the root outcome group, so test if the title is equal to the target account name
                    if outcomeGroup['title'] == targetAccountName:
                        ## Set the outcome group canvas id to the id of the outcome group
                        outcomeGroupCanvasId = outcomeGroup['id']
                        ## Break out of the loop
                        break
                
                ## If the outcome group's vendor guid is equal to the outcome parent guid
                if outcomeGroup['vendor_guid'] == outcomeParentGuid:
                    ## Set the outcome group canvas id to the id of the outcome group
                    outcomeGroupCanvasId = outcomeGroup['id']
                    ## Break out of the loop
                    break

            ## Define an outcome api url by tagging on the outcome group canvas id 
            ## and /outcomes to the end of the outcome groups api url
            outcomesApiUrl = f"{outcomeGroupsApiUrl}/{outcomeGroupCanvasId}/outcomes"

            ## Make an API call to the outcomes api url to get the outcomes in the outcome group
            outcomesObjects = makeApiCall(localSetup, p1_apiUrl=outcomesApiUrl)

            ## If the API status code is anything other than 200 it is an error, so log it and skip
            if (outcomesObjects.status_code != 200):
                localSetup.logger.error("\nCourse Error: " + str(outcomesObjects.status_code))
                localSetup.logger.error(outcomesApiUrl)
                localSetup.logger.error(outcomesObjects.url)
                continue

            ## Use the outcome index to get the vendor_guid from the outcome with the outcome as the title
            outcomeVendorGuid = targetDesignatorCanvasOutcomeDf.loc[outcomeIndexSearch[0], 'vendor_guid']

            ## Define a variable to hold the outcome canvas id
            outcomeCanvasId = None

            ## For each outcome in the outcomes object
            for outcomeData in [
                outcomeObject["outcome"] 
                for outcomeObject in outcomesObjects.json() 
                if "outcome" in outcomeObject
                ]:
                ## If the outcome's vendor guid is equal to the outcome vendor guid
                ## Or if the outcomeData id is equal to the outcome vendor guid when split by ':'
                if (
                    outcomeData['vendor_guid'] == outcomeVendorGuid 
                    or str(outcomeData["id"]) == str(outcomeVendorGuid.split(':')[1])
                    ):
                    ## Set the outcome canvas id to the id of the outcome
                    outcomeCanvasId = outcomeData['id']
                    ## Break out of the loop
                    break

            ## If the outcome canvas id is not found
            if outcomeCanvasId is None:
                ## Log the fact that the outcome was not found in the outcome group
                localSetup.logger.error(f"\nOutcome not found in outcome group: {outcome}")
                    
                ## Email the fact that the outcome was not found in the outcome group
                errorHandler.sendError (f"External Input Error: {functionName}", f"Outcome not found in outcome group: {outcome}")
                ## Skip to the next outcome
                continue

            ## Use the outcome Parent guide to find the index of the outcome group 
            ## with the same parent guid in the outcome groups object for the target account
            outcomeGroupIndexSearch = (
                targetDesignatorCanvasOutcomeDf[targetDesignatorCanvasOutcomeDf['vendor_guid'] == outcomeParentGuid].index
                )

            ## Use the outcome group index to get the outcome group title 
            ## from the outcome group column in the targetDesignatorCanvasOutcomeDf
            outcomeGroupTitle = (
                targetAccountName if str(outcomeParentGuid).strip() == "nan" 
                else targetDesignatorCanvasOutcomeDf.loc[outcomeGroupIndexSearch[0], 'title']
                )

            ## Make a dict for the outcome with the outcome group title and outcome canvas id
            uniqueOutcomesCanvasData[outcome] = {
                "Outcome Group Title": outcomeGroupTitle,
                "Outcome Canvas Id": outcomeCanvasId,
                "Outcome Group Id": outcomeGroupCanvasId,
                "Outcome Group is Root Account" : True if outcomeGroupTitle == targetAccountName else False
            }


        return uniqueTargetOutcomes, uniqueOutcomesCanvasData

        # ## Make a dict to hold the course id of the course named after each outcome
        # outcomeCanvasDataDict = {}
        
        # ## For each outcome in the unique outcomes list
        # for outcome in uniqueOutcomes:
            
        #     ## Define a variable to hold the courseIndex
        #     courseIndex = None

        #     try: ## Irregular try clause, do not comment out in testing

        #         ## Make a list of the indexes where the long_name column is equal to the outcome (there should only be 1)
        #         courseIndexSearch = allCanvasCoursesDF[allCanvasCoursesDF['long_name'] == outcome].index

        #         ## If the courseIndexs is not empty
        #         if not courseIndexSearch.empty:

        #             ## Get the first index from the courseIndexSearch
        #             courseIndex = courseIndexSearch[0]

            
        #         ## Set the courseIndex to the index of the course with the outcome as the long name
        #         courseIndex = allCanvasCoursesDF[allCanvasCoursesDF['long_name'] == outcome].index[0]
            
        #     ## If no course is found with the outcome as the long name
        #     except: ## Irregular except clause, do not comment out in testing
                
        #         ## Make a list of the indexes where the short_name column is equal to the outcome (there should only be 1)
        #         courseIndexeSearch = allCanvasCoursesDF[allCanvasCoursesDF['short_name'] == outcome].index

        #         ## If the courseIndexs is not empty
        #         if not courseIndexeSearch.empty:

        #             ## Get the first index from the courseIndexSearch
        #             courseIndex = courseIndexeSearch[0]
                
        #     ## Finally
        #     finally:

        #         ## If there is still no course index
        #         if courseIndex is None:

        #             ## Log the fact that the course was not found
        #             localSetup.logger.error(f"\nOutcome not found: {outcome}")
                    
        #             ## Email the fact that the course was not found
        #             errorHandler.sendError (f"External Input Error: {functionName}", f"Outcome course not found: {outcome}")

        #             ## Skip to the next outcome
        #             continue
                
        #     ## Use the course index to get the canvas course id from the course with the outcome as the name
        #     courseCanvasId = allCanvasCoursesDF.loc[courseIndex, 'canvas_course_id']
                
        #     ## Add the course id to the outcomeCanvasDataDict
        #     outcomeCanvasDataDict[outcome] = courseCanvasId

        # ## Return the outcomeCanvasDataDict
        # return uniqueOutcomes, outcomeCanvasDataDict    
    
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

# This function checks whether a term's outcome courses have their associated outcomes and adds them if they don't
def termOutcomeExporter(p1_inputTerm, p1_targetDesignator):
    functionName = "outcome_exporter"

    try:    

        ## Make a list to hold the active add outcome threads
        activeThreads = []

        ## Retrieve the data for determining and sending out relevant communication
        completeActiveCanvasCoursesDF, auxillaryDFDict = (
            retrieveDataForRelevantCommunication(
                p2_inputTerm = p1_inputTerm
                , p3_targetDesignator = p1_targetDesignator
                )
            )

        ## If the complete active canvas courses df is empty
        if completeActiveCanvasCoursesDF.empty:

            ## Log the fact that there are no active courses
            localSetup.logger.info(f"\nNo {p1_targetDesignator} active courses within {p1_inputTerm}")

            ## Return
            return

        ## For each row in the active outcome course df
        for index, row in completeActiveCanvasCoursesDF.iterrows():

            ## If the course is in the auxillaryDFDict active
            
            ## Create an add outcome to course thread
            addOutcomeThread = threading.Thread(target=addOutcomeToCourse
                                                , args=(row
                                                        , auxillaryDFDict
                                                        )
                                                )
            
            ## Start the thread
            addOutcomeThread.start()
            
            ## Add the thread to the active threads list
            activeThreads.append(addOutcomeThread)
            
        ## For each active thread
        for thread in activeThreads:
            
            ## Wait for the thread to finish
            thread.join()    
     
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

if __name__ == "__main__":

    ## Start and download the Canvas report
    termOutcomeExporter (p1_inputTerm = input("Enter the desired term in four character format (FA20, SU20, SP20): ")
        , p1_targetDesignator = input("Enter the desired target designator (GE, I-EDUC, U-ENGR): ")
        )

    input("Press enter to exit")


## ===========================================================================
## FILE: ActionModules\CX_Data_Sync.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import necessary modules
import os, time, pandas as pd, zipfile, sys
from datetime import datetime

## Ensure ResourceModules path is available and import shared helpers
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))
from Local_Setup import LocalSetup
from TLC_Common import makeApiCall
from Common_Configs import coreCanvasApiUrl
from Error_Email import errorEmail

## Initialize LocalSetup and localSetup.logger so this module works when imported
localSetup = LocalSetup(datetime.now(), __file__)
logger = localSetup.logger

## External SIS resource path
SISResourcePath = localSetup.getExternalResourcePath("SIS")

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "CX_Data_Sync"

scriptPurpose = r"""
This script pulls the Canvas SIS data from the Canvas Resources directory, zips the files, and uploads them to the Canvas API.
"""
externalRequirements = r"""
This script requires the following external resources:
1. Canvas Resources directory containing the SIS data files in CSV format.
2. A valid Canvas API access token stored in the Configs TLC directory as Canvas_Access_Token.txt.
3. The Core_Canvas_Url.txt file in the Configs TLC directory containing the base URL for the Canvas API.
4. The External_Resource_Paths.json file in the Configs TLC directory containing the SISResourcePath and IEResourcePath values.
5. The ResourceModules and ActionModules directories in the Scripts TLC directory for additional functionality.
"""

## Setup error handler
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function reads the CSV file, deletes the enrollment, and re-enrolls the user with the new role
def importCXData():

    functionName = "importCXData"

    try:

        ## Create the url to check if there is an ongoing sis import
        checkSisImportUrl = f"{coreCanvasApiUrl}accounts/1/sis_imports"

        ## Make the api call to check if there is an ongoing sis import
        sisImportCheckResponse = makeApiCall(localSetup, p1_apiUrl=checkSisImportUrl, firstPageOnly = True)

        ## Define a blank object to hold the sis imports
        sisImports = None

        ## If the response was not successful, log the error
        if sisImportCheckResponse.status_code != 200:

            localSetup.logger.error(f"Failed to check SIS imports. Status code: {sisImportCheckResponse.status_code}")
            localSetup.logger.error(f"Response: {sisImportCheckResponse.text}")
            ## Send an error email
            errorHandler.sendError(p1_errorLocation="importCXData", p1_errorInfo=f"Failed to check SIS imports. Status code: {sisImportCheckResponse.status_code}. Response: {sisImportCheckResponse.text}")
            return False

        ## Otherwise
        else:
            ## Get the sis imports from the response
            sisImports = sisImportCheckResponse.json()["sis_imports"]

        ## If the first element of the the sis_imports list has a status of "initializing"
        if sisImports and sisImports[0]['workflow_state'] == 'initializing':

            ## Get the id of the import
            importId = sisImports[0]['id']

            ## Define an abort api url 
            abortImportUrl = f"{coreCanvasApiUrl}accounts/1/sis_imports/{importId}/abort"

            ## Make the api call to abort the import
            abortImportResponse = makeApiCall(localSetup, p1_apiUrl=abortImportUrl, p1_apiCallType="put")

            ## If the response was not successful, log the error
            if abortImportResponse.status_code != 200:

                localSetup.logger.error(f"Failed to abort SIS import. Status code: {abortImportResponse.status_code}")
                localSetup.logger.error(f"Response: {abortImportResponse.text}")
                ## Send an error email
                errorHandler.sendError(p1_errorLocation="importCXData", p1_errorInfo=f"Failed to abort SIS import. Status code: {abortImportResponse.status_code}. Response: {abortImportResponse.text}")
                return False

        ## Make a list of the CSV files in the SISResourcePath directory
        sisImportFilesList = os.listdir(SISResourcePath)

        ## For each file
        for sisImportFile in sisImportFilesList:

            ## Define an empty DataFrame to hold the file data
            fileDataDf = pd.DataFrame()

            ## Open it as a pd.DataFrame
            if sisImportFile.endswith('.csv'):
                filePath = os.path.join(SISResourcePath, sisImportFile)
                fileDataDf = pd.read_csv(filePath)

            ## If there are start_date and an end_date columns
            if not fileDataDf.empty and ('start_date' in fileDataDf.columns and 'end_date' in fileDataDf.columns):

                ## Set the date format to be compatible with the Canvas API (i.e. 2012-03-14)
                fileDataDf['start_date'] = pd.to_datetime(fileDataDf['start_date']).dt.strftime('%Y-%m-%d')
                fileDataDf['end_date'] = pd.to_datetime(fileDataDf['end_date']).dt.strftime('%Y-%m-%d')

                ## Overwrite the file with the updated dates
                fileDataDf.to_csv(filePath, index=False)



        ## Define the zip file name and path
        zipFileName = "cxDataImportZip.zip"
        zipFilePath = os.path.join(SISResourcePath, zipFileName)

        ## Create a zip file from all CSVs in the directory
        with zipfile.ZipFile(zipFilePath, 'w') as zipf:
            for file in os.listdir(SISResourcePath):
                if file.endswith('.csv') and file != "canvas_dept.csv":
                    filePath = os.path.join(SISResourcePath, file)
                    zipf.write(filePath, arcname=file)

        ## Open the temporary zip file
        with open (zipFilePath, 'rb') as CXDataFile:

            ## Define the neccessary files dict
            files = {
                'attachment': ('sis_import.zip', CXDataFile, 'application/zip')
            }

            ## Define the parameters
            params = {
                'import_type': 'instructure_csv'
            }

            ## Define the neccessary url
            importSisDataUrl = f"{coreCanvasApiUrl}accounts/1/sis_imports"

            ## Make the api call and save the response
            sisImportOjbect = makeApiCall(localSetup,
                                          p1_apiUrl=importSisDataUrl,
                                          p1_payload=params,
                                          p1_files=files,
                                          p1_apiCallType="post",
                                          )

            ## If the response was not successful, log the error
            if sisImportOjbect.status_code != 200:

                localSetup.logger.error(f"Failed to import SIS data. Status code: {sisImportOjbect.status_code}")
                localSetup.logger.error(f"Response: {sisImportOjbect.text}")

                ## Send an error email
                errorHandler.sendError(p1_errorLocation="importCXData", p1_errorInfo=f"Failed to import SIS data. Status code: {sisImportOjbect.status_code}. Response: {sisImportOjbect.text}")

            ## Otherwise
            else:

                ## Get the id of the import
                importId = sisImportOjbect.json()['id']

                ## Define the import status check url by adding 1/sis_imports/:id
                checkImportStatusUrl = f"{coreCanvasApiUrl}accounts/1/sis_imports/{importId}"

                ## Define a blank ojbect to hold the import status
                importStatus = None

                ## While the import status is not complete
                while importStatus != 100:

                    ## Make the api call to check the import status
                    importStatusResponse = makeApiCall(localSetup, p1_apiUrl=checkImportStatusUrl)

                    ## If the response was not successful, log the error
                    if importStatusResponse.status_code != 200:
                        localSetup.logger.error(f"Failed to check SIS import status. Status code: {importStatusResponse.status_code}")
                        localSetup.logger.error(f"Response: {importStatusResponse.text}")
                        
                        ## Send an error email
                        errorHandler.sendError(p1_errorLocation="importCXData", p1_errorInfo=f"Failed to check SIS import status. Status code: {importStatusResponse.status_code}. Response: {importStatusResponse.text}")
                        break

                    ## Otherwise, get the import status from the response
                    else:

                        importStatus = importStatusResponse.json()['progress']
                        localSetup.logger.info(f"SIS Import Status: {importStatus}")

                
                    ## Wait 5 minutes
                    localSetup.logger.info("Waiting 2 minutes for the SIS import to complete...")
                    time.sleep(120)

                ## Once the import is complete, log the success
                localSetup.logger.info(f"SIS Import Status: {importStatus}")

                ## If the import was successful, return True
                return True
        
        ## If the import was not successful, return False    
        return False
        

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":
    ## Set working directory
    os.chdir(os.path.dirname(__file__))

    ## Run the cx data sync
    CXDataSyncStatus = importCXData()
    
    ## If the cx data sync was successful
    if CXDataSyncStatus:
        ## Log the successful cx data sync
        localSetup.logger.info("CX Data Sync Successful")

    ## Otherwise
    else:

        ## Log the failed cx data sync
        localSetup.logger.error("CX Data Sync Failed")

        ## Send an error email
        errorHandler.sendError (scriptName, p1_ErrorInfo = "The CX Data Sync Failed. Please check the messages at https://nnu.instructure.com/accounts/1/sis_import for more information.")


## ===========================================================================
## FILE: ActionModules\Change_Account_For_Listed_Courses.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller (refactored to use common TLC modules)

## Import Generic Moduels

import os, sys, threading, time, pandas as pd
from datetime import datetime

## Add the resource modules path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

# Try direct imports if run as main, else relative for package usage
try:
    from Local_Setup import LocalSetup
    from TLC_Common import makeApiCall
    from Error_Email import errorEmail
    from Common_Configs import coreCanvasApiUrl, canvasAccessToken, scriptLibrary
except ImportError:  # When imported as a package/module
    from .Local_Setup import LocalSetup
    from .TLC_Common import makeApiCall
    from .Error_Email import errorEmail
    from .Common_Configs import coreCanvasApiUrl, canvasAccessToken, scriptLibrary

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")
scriptPurpose = r"""
This script reads a CSV file containing Canvas course IDs and changes the account
for each course using the Canvas API.
"""
externalRequirements = r"""
To function properly, this script requires:
- Valid Canvas API configuration in Common_Configs (coreCanvasApiUrl, canvasAccessToken).
- A CSV file named "Target_Canvas_Course_Ids.csv" located in the Canvas internal
  resources directory (LocalSetup.getInternalResourcePaths("Canvas")).
"""

## Set the account for the given course ID
def changeCourseAccount(
    localSetup: LocalSetup,
    errorHandler: errorEmail,
    courseId: str,
    accountId: str,
) -> None:
    """
    Change the account for a Canvas course given its course ID and target account ID.
    Uses TLC_Common.makeApiCall with retry behavior.
    """
    functionName = "changeCourseAccount"
    try:
        changeAccountUrl = f"{coreCanvasApiUrl}courses/{courseId}"
        payload = {"course": {"account_id": accountId}}

        response = makeApiCall(
            localSetup=localSetup,
            p1_apiUrl=changeAccountUrl,
            p1_payload=payload,
            p1_apiCallType="put",
        )

        ## Get the status code
        statusCode = getattr(response, "status_code", None)

        if statusCode == 200:
            localSetup.logger.info(
                f"Successfully changed account for course with ID: {courseId} "
                f"to account_id: {accountId}"
            )
        else:
            localSetup.logger.warning(
                f"Failed to change account for course with ID: {courseId}. "
                f"Status code: {statusCode}"
            )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)


def changeListedCoursesAccount(
    localSetup: LocalSetup,
    errorHandler: errorEmail,
    csvFileName: str = "Target_Canvas_Course_Ids.csv",
    threadSleep: float = 0.1,
) -> None:
    """
    Read a CSV file of course/account IDs and change each course's account.

    Expected columns in CSV:
      - canvas_course_id
      - canvas_account_id
    """
    functionName = "changeListedCoursesAccount"
    try:
        ## Canvas internal resources root
        canvasResourcePath = localSetup.getInternalResourcePaths("Canvas")
        targetCoursesCsvFilePath = os.path.join(canvasResourcePath, csvFileName)

        ## Log start
        localSetup.logger.info(
            f"Starting {functionName}. Input file: {targetCoursesCsvFilePath}"
        )

        ## Verify CSV file exists
        if not os.path.exists(targetCoursesCsvFilePath):
            raise FileNotFoundError(
                f"Target courses CSV not found: {targetCoursesCsvFilePath}"
            )

        ## Thread tracking
        ongoingThreads = []

        ## Load CSV
        rawTargetCoursesDf = pd.read_csv(targetCoursesCsvFilePath)

        ## Filter out rows with null canvas_course_id
        targetCoursesDf = rawTargetCoursesDf[
            rawTargetCoursesDf["canvas_course_id"].notna()
        ]

        ## Iterate and spawn threads
        for _, row in targetCoursesDf.iterrows():
            courseId = str(row["canvas_course_id"]).replace(".0", "")
            accountId = str(row["canvas_account_id"]).replace(".0", "")

            ## Skip if either is empty
            if not courseId or not accountId:
                localSetup.logger.warning(
                    f"Skipping row with courseId='{courseId}' accountId='{accountId}'"
                )
                continue

            ## Start thread to change account and append it to the tracking list
            changeAccountThread = threading.Thread(
                target=changeCourseAccount,
                args=(localSetup, errorHandler, courseId, accountId),
                name=f"change_course_{courseId}",
            )
            changeAccountThread.start()
            ongoingThreads.append(changeAccountThread)

            # Throttle slightly to avoid hammering the API
            time.sleep(threadSleep)

        # Wait for all threads to complete
        for thread in ongoingThreads:
            thread.join()

        ## Log completion
        localSetup.logger.info(
            f"{functionName} completed. Processed {len(targetCoursesDf)} courses."
        )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":
    # Initialize shared LocalSetup (paths, logging)
    localSetup = LocalSetup(datetime.now(), __file__)

    # Setup the error handler (sends one email per function error)
    errorHandler = errorEmail(
        scriptName,
        scriptPurpose,
        externalRequirements,
        localSetup,
    )

    localSetup.logger.info(
        f"Starting script: {scriptName} | Purpose: {scriptPurpose.strip()}"
    )

    changeListedCoursesAccount(localSetup, errorHandler)

    localSetup.logger.info(f"Script {scriptName} completed.")
    input("Press Enter to exit...")


## ===========================================================================
## FILE: ActionModules\Change_Grading_Scheme_For_Listed_Courses.py
## ===========================================================================


# Author: Bryce Miller - brycezmiller@nnu.edu
# Last Updated by: Bryce Miller (refactored to update grading standards via Courses API)

import os, threading, time, pandas as pd, sys
from datetime import datetime

## Ensure ResourceModules are importable when running from ActionModules
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

# Try direct imports if run as main, else relative for package usage
try:
    from Local_Setup import LocalSetup
    from TLC_Common import makeApiCall
    from Error_Email import errorEmail
    from Common_Configs import coreCanvasApiUrl, canvasAccessToken
except ImportError:  # When imported as a package/module
    from .Local_Setup import LocalSetup
    from .TLC_Common import makeApiCall
    from .Error_Email import errorEmail
    from .Common_Configs import coreCanvasApiUrl, canvasAccessToken

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Change_Grading_Standard_For_Listed_Courses"
scriptPurpose = r"""
This script reads a CSV file containing Canvas course IDs and grading standard IDs
and updates the grading standard for each listed course using the Canvas Courses API
("Update a course" - course[grading_standard_id]).
"""
externalRequirements = r"""
To function properly, this script requires:
- Valid Canvas API configuration in Common_Configs (coreCanvasApiUrl, canvasAccessToken).
- A CSV file located in the Canvas internal resources directory
  (LocalSetup.getInternalResourcePaths("Canvas")) with:
    - canvas_course_id
    - grading_standard_id  (or grading_scheme_id)
"""

## Change the grading standard for the given course ID
def changeCourseGradingStandard(
    localSetup: LocalSetup,
    errorHandler: errorEmail,
    header: dict,
    courseId: str,
    gradingStandardId: str,
) -> None:
    """
    Change the grading standard for a Canvas course given its course ID and
    target grading standard ID.

    Uses the Courses "Update a course" endpoint:
    PUT /api/v1/courses/:id
    with course[grading_standard_id].
    """
    functionName = "changeCourseGradingStandard"
    try:
        updateCourseUrl = f"{coreCanvasApiUrl}courses/{courseId}"
        # Build payload using nested course object, matching Rails-style parameters
        payload = {
            "course": {
                "grading_standard_id": int(gradingStandardId)
            }
        }

        response = makeApiCall(
            localSetup,
            p1_apiUrl=updateCourseUrl,
            p1_payload=payload,
            p1_apiCallType="put"
        )

        # makeApiCall may return a Response or a list; handle the primary case.
        statusCode = getattr(response, "status_code", None)

        if statusCode == 200:
            localSetup.logger.info(
                f"Successfully changed grading_standard_id for course with ID: "
                f"{courseId} to {gradingStandardId}"
            )
        else:
            localSetup.logger.warning(
                f"Failed to change grading_standard_id for course with ID: {courseId}. "
                f"Status code: {statusCode}"
            )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)


## Change grading standards for listed courses from CSV
def changeListedCoursesGradingStandard(
    localSetup: LocalSetup,
    errorHandler: errorEmail,
    csvFileName: str = "Target_Canvas_Course_Ids.csv",
    threadSleep: float = 0.1,
) -> None:
    """
    Read a CSV file of course/grading standard IDs and change each course's grading standard.

    Expected columns in CSV:
      - canvas_course_id
      - grading_standard_id  (preferred)
        or grading_scheme_id (alias, will be treated as grading_standard_id)
    """
    functionName = "changeListedCoursesGradingStandard"
    try:
        # Canvas internal resources root
        canvasResourcePath = localSetup.getInternalResourcePaths("Canvas")
        targetCoursesCsvFilePath = os.path.join(canvasResourcePath, csvFileName)

        localSetup.logger.info(
            f"Starting {functionName}. Input file: {targetCoursesCsvFilePath}"
        )

        if not os.path.exists(targetCoursesCsvFilePath):
            raise FileNotFoundError(
                f"Target courses CSV not found: {targetCoursesCsvFilePath}"
            )

        header = {"Authorization": f"Bearer {canvasAccessToken}"}

        # Thread tracking
        ongoingThreads = []

        # Load CSV
        rawTargetCoursesDf = pd.read_csv(targetCoursesCsvFilePath)

        # Keep rows that have a value in canvas_course_id
        if "canvas_course_id" not in rawTargetCoursesDf.columns:
            raise KeyError(
                "Expected column 'canvas_course_id' not found in CSV."
            )

        # Support either grading_standard_id (Canvas term) or grading_scheme_id (your wording)
        gradingColumnName = None
        if "grading_standard_id" in rawTargetCoursesDf.columns:
            gradingColumnName = "grading_standard_id"
        elif "grading_scheme_id" in rawTargetCoursesDf.columns:
            gradingColumnName = "grading_scheme_id"
        else:
            raise KeyError(
                "Expected column 'grading_standard_id' or 'grading_scheme_id' "
                "not found in CSV."
            )

        targetCoursesDf = rawTargetCoursesDf[
            rawTargetCoursesDf["canvas_course_id"].notna()
        ]

        localSetup.logger.info(
            f"Found {len(targetCoursesDf)} target course rows with non-null canvas_course_id."
        )

        # Iterate and spawn threads
        for _, row in targetCoursesDf.iterrows():
            courseId = str(row["canvas_course_id"]).replace(".0", "")
            gradingStandardId = str(row[gradingColumnName]).replace(".0", "")

            # Skip if either is empty
            if not courseId or not gradingStandardId:
                localSetup.logger.warning(
                    f"Skipping row with courseId='{courseId}' "
                    f"{gradingColumnName}='{gradingStandardId}'"
                )
                continue

            changeGradingThread = threading.Thread(
                target=changeCourseGradingStandard,
                args=(localSetup, errorHandler, header, courseId, gradingStandardId),
                name=f"change_grading_standard_{courseId}",
                daemon=True,
            )
            changeGradingThread.start()
            ongoingThreads.append(changeGradingThread)

            # Sleep for a short time to avoid overloading the server
            time.sleep(threadSleep)

        # Check if all ongoing change grading standard threads have completed
        for thread in ongoingThreads:
            thread.join()

        localSetup.logger.info(
            f"{functionName} completed. Processed {len(targetCoursesDf)} courses."
        )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":
    ## Initialize the local setup object and error handler
    localSetup = LocalSetup(datetime.now(), __file__)
    errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

    localSetup.logger.info(
        f"Starting script: {scriptName} | Purpose: {scriptPurpose.strip()}"
    )

    # Change the grading standard for the listed courses
    changeListedCoursesGradingStandard(localSetup, errorHandler)

    localSetup.logger.info(f"Script {scriptName} completed.")
    input("Press Enter to exit...")


## ===========================================================================
## FILE: ActionModules\Change_Long_Name_For_Listed_Courses.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

import traceback, os, sys, logging, requests, threading, time, pandas as pd
from datetime import datetime

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Change_Long_Name_For_Listed_Courses"

scriptPurpose = r"""
This script reads a CSV file containing Canvas course IDs and changes the long name for each course using the Canvas API.
"""
externalRequirements = r"""
To function properly, this script requires a valid access header and URL, and a CSV file named "Target_Canvas_Course_Ids.csv" located in the Canvas Resources directory.
"""

## Date Variables
currentDateTime = datetime.now()
currentMonth = currentDateTime.month
currentYear = currentDateTime.year

## Set working directory
os.chdir(os.path.dirname(__file__))

## Relative Path (this changes depending on the working directory of the main script)
PFRelativePath = r".\\"

## If the Canvas directory is not in the folder the relative path points to
## find the Canvas directory and set the relative path to its parent folder
while "Scripts TLC" not in os.listdir(PFRelativePath):
    PFRelativePath = f"..\\{PFRelativePath}"

## Change the relative path to an absolute path
absolutePath = f"{os.path.abspath(PFRelativePath)}\\"

## Local Path Variables
baseLogPath = f"{absolutePath}Logs\\{scriptName}\\"
baseLocalInputPath = f"{absolutePath}Canvas Resources\\"
configPath = f"{absolutePath}Configs TLC\\"

## If the base log path doesn't already exist, create it
if not os.path.exists(baseLogPath):
    os.makedirs(baseLogPath, mode=0o777, exist_ok=False)

## Add Input Modules to the sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ResourceModules")
sys.path.append(f"{absolutePath}Scripts TLC\\ActionModules")

## Import local modules
from Error_Email_API import errorEmailApi  ## Import errorEmailApi
from Make_Api_Call import makeApiCall  ## Import makeApiCall

## Canvas Instance Url
coreCanvasApiUrl = None
## Open the Core_Canvas_Url.txt from the config path
with open(f"{configPath}Core_Canvas_Url.txt", "r") as file:
    coreCanvasApiUrl = file.readlines()[0]

## If the script is run as main the folder with the access token is in the parent directory
canvasAccessToken = ""

## Open and retrieve the Canvas Access Token
with open(f"{configPath}Canvas_Access_Token.txt", "r") as file:
    canvasAccessToken = file.readlines()[0]

## Log configurations
logger = logging.getLogger(__name__)
rootFormat = ("%(asctime)s %(levelname)s %(message)s")
FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
logging.basicConfig(format=rootFormat, filemode="a", level=logging.INFO)

## Info Log Handler
infoLogFile = f"{baseLogPath}\\Info Log.txt"
logInfo = logging.FileHandler(infoLogFile, mode='a')
logInfo.setLevel(logging.INFO)
logInfo.setFormatter(FORMAT)
localSetup.logger.addHandler(logInfo)

## Warning Log handler
warningLogFile = f"{baseLogPath}\\Warning Log.txt"
logWarning = logging.FileHandler(warningLogFile, mode='a')
logWarning.setLevel(logging.WARNING)
logWarning.setFormatter(FORMAT)
localSetup.logger.addHandler(logWarning)

## Error Log handler
errorLogFile = f"{baseLogPath}\\Error Log.txt"
logError = logging.FileHandler(errorLogFile, mode='a')
logError.setLevel(logging.ERROR)
logError.setFormatter(FORMAT)
localSetup.logger.addHandler(logError)

## Setup the error handler
## an error email the first time the function triggers an error
errorHandler = errorEmailApi(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function handles function errors
def errorHandler (p1_ErrorLocation, p1_ErrorInfo, sendOnce=True):
    functionName = "## errorHandler.sendError"
    localSetup.logger.error(f"\nA script error occurred while running {p1_ErrorLocation}. Error: {str(p1_ErrorInfo)}")

    ## If the function with the error has not already been processed send an email alert
    if p1_ErrorLocation not in setOfFunctionsWithErrors:
        errorEmailApi.sendEmailError(p2_ScriptName=scriptName, p2_ScriptPurpose=scriptPurpose,
                                     p2_ExternalRequirements=externalRequirements,
                                     p2_ErrorLocation=p1_ErrorLocation, p2_ErrorInfo=p1_ErrorInfo)
        setOfFunctionsWithErrors.add(p1_ErrorLocation)
        localSetup.logger.error(f"\nError Email Sent")
    else:
        localSetup.logger.error(f"\nError email already sent")

## This function sets the long name for a course given its Canvas course ID and long name
def setCourseLongName(p1_header, p1_courseId, p1_longName):
    functionName = "setCourseLongName"
    try:
        setLongNameApiUrl = f"{coreCanvasApiUrl}courses/{p1_courseId}"
        payload = {"course": {"name": p1_longName}}
        response = makeApiCall(localSetup, p1_header=p1_header, p1_apiUrl=setLongNameApiUrl, p1_payload=payload, p1_apiCallType="put")

        if response.status_code == 200:
            localSetup.logger.info(f"Successfully set long name for course with ID: {p1_courseId}")
        else:
            localSetup.logger.warning(f"Failed to set long name for course with ID: {p1_courseId}. Status code: {response.status_code}")

    except Exception as Error:
        except(functionName, Error)

## This function reads the CSV file and sets the long name for the listed courses
def setListedCoursesLongName():
    functionName = "setListedCoursesLongName"
    try:
        targetCoursesCsvFilePath = f"{baseLocalInputPath}Target_Canvas_Course_Ids.csv"
        header = {'Authorization': f"Bearer {canvasAccessToken}"}
        
        ## Define the necessary thread list
        ongoingSetLongNameThreads = []

        ## Read the CSV file using pandas
        rawTargetCoursesDf = pd.read_csv(targetCoursesCsvFilePath)

        ## Retain only rows that have a value in canvas_course_id
        targetCoursesDf = rawTargetCoursesDf[rawTargetCoursesDf["canvas_course_id"].notna()]

        ## Iterate over each row in the DataFrame
        for index, row in targetCoursesDf.iterrows():

            ## Get the course id from the row
            courseId = str(row["canvas_course_id"]).replace('.0', '')

            ## Get the long name from the row
            longName = str(row["long_name"])

            ## Create a thread to set the long name for the course
            setLongNameThread = threading.Thread(target=setCourseLongName, args=(header, courseId, longName))

            ## Start the thread
            setLongNameThread.start()

            ## Add the thread to the ongoing set long name threads list
            ongoingSetLongNameThreads.append(setLongNameThread)

            ## Sleep for a short time to avoid overloading the server
            time.sleep(0.1)

        ## Check if all ongoing set long name threads have completed
        for thread in ongoingSetLongNameThreads:
            thread.join()

    except Exception as Error:
        except(functionName, Error)

if __name__ == "__main__":
    ## Set working directory
    os.chdir(os.path.dirname(__file__))

    ## Set the long name for the listed courses
    setListedCoursesLongName()

    input("Press enter to exit")


## ===========================================================================
## FILE: ActionModules\Change_Role_For_Listed_Enrollments.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import necessary modules
import traceback, os, sys, logging, requests, csv, threading, time, pandas as pd
from datetime import datetime

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Change_Role_For_Listed_Enrollments"

scriptPurpose = r"""
This script reads a CSV file containing Canvas enrollment IDs and changes the role for each enrollment using the Canvas API.
"""
externalRequirements = r"""
To function properly, this script requires a valid access header and URL, and a CSV file named "Target_Canvas_Enrollment_Ids.csv" located in the Canvas Resources directory.
"""

## Date Variables
currentDateTime = datetime.now()
## Get the current date and time
currentMonth = currentDateTime.month
## Get the current month
currentYear = currentDateTime.year
## Get the current year

## Set working directory
os.chdir(os.path.dirname(__file__))
## Change the working directory to the script's directory

## Relative Path (this changes depending on the working directory of the main script)
pfRelativePath = r".\\"

## If the Canvas directory is not in the folder the relative path points to
## find the Canvas directory and set the relative path to its parent folder
while "Scripts TLC" not in os.listdir(pfRelativePath):
    pfRelativePath = f"..\\{pfRelativePath}"

## Change the relative path to an absolute path
absolutePath = f"{os.path.abspath(pfRelativePath)}\\"

## Local Path Variables
baseLogPath = f"{absolutePath}Logs\\{scriptName}\\"
## Define the base log path
baseLocalInputPath = f"{absolutePath}Canvas Resources\\"
## Define the base input path
configPath = f"{absolutePath}Configs TLC\\"
## Define the config path

## If the base log path doesn't already exist, create it
if not os.path.exists(baseLogPath):
    os.makedirs(baseLogPath, mode=0o777, exist_ok=False)
    ## Create the base log path

## Add Input Modules to the sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ResourceModules")
## Add ResourceModules to sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ActionModules")
## Add ActionModules to sys path

## Import local modules
from Error_Email_API import errorEmailApi
## Import errorEmailApi
from Make_Api_Call import makeApiCall
## Import makeApiCall

## Canvas Instance Url
coreCanvasApiUrl = None
## Open the Core_Canvas_Url.txt from the config path
with open(f"{configPath}Core_Canvas_Url.txt", "r") as file:
    coreCanvasApiUrl = file.readlines()[0]
    ## Read the Canvas URL

## If the script is run as main the folder with the access token is in the parent directory
canvasAccessToken = ""
## Open and retrieve the Canvas Access Token
with open(f"{configPath}Canvas_Access_Token.txt", "r") as file:
    canvasAccessToken = file.readlines()[0]
    ## Read the Canvas Access Token

## Log configurations
logger = logging.getLogger(__name__)
rootFormat = ("%(asctime)s %(levelname)s %(message)s")
FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
logging.basicConfig(format=rootFormat, filemode="a", level=logging.INFO)

## Info Log Handler
infoLogFile = f"{baseLogPath}\\Info Log.txt"
logInfo = logging.FileHandler(infoLogFile, mode='a')
logInfo.setLevel(logging.INFO)
logInfo.setFormatter(FORMAT)
localSetup.logger.addHandler(logInfo)

## Warning Log handler
warningLogFile = f"{baseLogPath}\\Warning Log.txt"
logWarning = logging.FileHandler(warningLogFile, mode='a')
logWarning.setLevel(logging.WARNING)
logWarning.setFormatter(FORMAT)
localSetup.logger.addHandler(logWarning)

## Error Log handler
errorLogFile = f"{baseLogPath}\\Error Log.txt"
logError = logging.FileHandler(errorLogFile, mode='a')
logError.setLevel(logging.ERROR)
logError.setFormatter(FORMAT)
localSetup.logger.addHandler(logError)

## The variable below holds a set of the functions that have had errors. This enables the ## errorHandler.sendError function to only send
## an error email the first time the function triggers an error
errorHandler = errorEmailApi(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function handles function errors
def errorHandler.sendError(p1_errorLocation, p1_errorInfo, sendOnce=True):
    functionName = "## errorHandler.sendError"
    localSetup.logger.error(f"\nA script error occurred while running {p1_errorLocation}. Error: {str(p1_errorInfo)}")

    ## If the function with the error has not already been processed send an email alert
    if p1_errorLocation not in setOfFunctionsWithErrors:
        errorEmailApi.sendEmailError(p1_scriptName=scriptName, p2_scriptPurpose=scriptPurpose,
                                     p2_externalRequirements=externalRequirements,
                                     p2_errorLocation=p1_errorLocation, p2_ErrorInfo=p1_errorInfo)
        setOfFunctionsWithErrors.add(p1_errorLocation)
        localSetup.logger.error(f"\nError Email Sent")
    else:
        localSetup.logger.error(f"\nError email already sent")

## This function deletes an enrollment given its Canvas enrollment ID
def deleteEnrollment(p1_header, p3_courseId, p1_enrollmentId):
    functionName = "deleteEnrollment"
    try:

        ## Define the API URL for deleting the enrollment
        deleteEnrollmentUrl = f"{coreCanvasApiUrl}courses/{p3_courseId}/enrollments/{p1_enrollmentId}"

        ## Define the API URL for deleting the enrollment
        response = makeApiCall(localSetup, p1_header=p1_header, p1_apiUrl=deleteEnrollmentUrl, p1_apiCallType="delete")

        ## Make the API call to delete the enrollment
        if response.status_code == 200:
            localSetup.logger.info(f"Successfully deleted enrollment with ID: {p1_enrollmentId}")
        else:
            localSetup.logger.warning(f"Failed to delete enrollment with ID: {p1_enrollmentId}. Status code: {response.status_code}")

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This function re-enrolls a user with a new role given the Canvas user ID, course ID, role ID, and base role type
def reEnrollUser(p1_header, p1_userId, p2_courseId, p3_roleId, p4_baseRoleType):
    functionName = "reEnrollUser"
    try:

        ## Define the API URL for re-enrolling the user
        reEnrollUrl = f"{coreCanvasApiUrl}courses/{p2_courseId}/enrollments"

        ## Define the API URL for re-enrolling the user
        payload = {"enrollment[user_id]": p1_userId
                   , "enrollment[type]": p4_baseRoleType
                   , "enrollment[role_id]": p3_roleId
                   , "enrollment[enrollment_state]": "active"
                   }

        ## Define the payload
        response = makeApiCall(localSetup, p1_header=p1_header, p1_apiUrl=reEnrollUrl, p1_payload=payload, p1_apiCallType="post")

        ## Make the API call to re-enroll the user
        if response.status_code == 200:
            localSetup.logger.info(f"Successfully re-enrolled user with ID: {p1_userId} in course with ID: {p2_courseId} with role ID: {p3_roleId}")
        else:
            localSetup.logger.warning(f"Failed to re-enroll user with ID: {p1_userId} in course with ID: {p2_courseId}. Status code: {response.status_code}")

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This function deletes the enrollment and re-enrolls the user with the new role
def deleteAndReenroll(p1_header, p1_enrollmentId, p1_userId, p2_courseId, p3_roleId, p4_baseRoleType):
    reEnrollUser(p1_header, p1_userId, p2_courseId, p3_roleId, p4_baseRoleType)
    deleteEnrollment(p1_header, p2_courseId, p1_enrollmentId)

## This function reads the CSV file, deletes the enrollment, and re-enrolls the user with the new role
def changeListedEnrollmentsRole():
    functionName = "changeListedEnrollmentsRole"
    try:
        targetEnrollmentsCsvFilePath = f"{baseLocalInputPath}Target_Canvas_Enrollment_Ids.csv"
        ## Define the CSV file path
        header = {'Authorization': f"Bearer {canvasAccessToken}"}
        ## Define the header

        ## Define the necessary thread list
        ongoingChangeRoleThreads = []

        ## Read the CSV file using pandas
        rawTargetEnrollmentsDf = pd.read_csv(targetEnrollmentsCsvFilePath)

        ## Retain only rows that have a value in canvas_enrollment_id
        targetEnrollmentsDf = rawTargetEnrollmentsDf[rawTargetEnrollmentsDf["canvas_enrollment_id"].notna()]

                ## Iterate over each row in the DataFrame
        for index, row in targetEnrollmentsDf.iterrows():

            ## Get the enrollment id from the row
            enrollmentId = str(row["canvas_enrollment_id"]).replace('.0', '')

            ## Get the user id from the row
            userId = str(row["canvas_user_id"]).replace('.0', '')
            
            ## Get the course id from the row
            courseId = str(row["canvas_course_id"]).replace('.0', '')

            ## Get the role id from the row
            roleId = str(row["role_id"]).replace('.0', '')

            ## Get the base role type from the row
            baseRoleType = str(row["base_role_type"])

            ## Create a thread to delete the enrollment and re-enroll the user
            changeRoleThread = threading.Thread(target=deleteAndReenroll, args=(header, enrollmentId, userId, courseId, roleId, baseRoleType))

            ## Start the thread
            changeRoleThread.start()

            ## Add the thread to the ongoing change role threads list
            ongoingChangeRoleThreads.append(changeRoleThread)

            ## Sleep for a short time to avoid overloading the server
            time.sleep(0.2)

        ## Check if all ongoing change role threads have completed
        for thread in ongoingChangeRoleThreads:
            thread.join()

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":
    ## Set working directory
    os.chdir(os.path.dirname(__file__))
    
    ## Change the role for the listed enrollments
    changeListedEnrollmentsRole()

    ## Wait for user input to exit
    input("Press enter to exit")


## ===========================================================================
## FILE: ActionModules\Change_Syllabus_Tab.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Moduels
from __future__ import print_function
import traceback, os, sys, logging, requests, re, os, os.path, threading, math, json
from datetime import datetime, date, timedelta
from dateutil import parser
import pandas as pd

## Import necessary functions from local modules
## Add Script repository to syspath
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

## New resource modules
try:
    
    from Local_Setup import LocalSetup
    from TLC_Common import makeApiCall, isFileRecent
    from Canvas_Report import CanvasReport
    from Error_Email import errorEmail
except ImportError:
    from ResourceModules.Local_Setup import LocalSetup
    from ResourceModules.TLC_Common import makeApiCall, isFileRecent
    from ResourceModules.Canvas_Report import CanvasReport
    from ResourceModules.Error_Email import errorEmail

## Create the localsetup variable
localSetup = LocalSetup(datetime.now(), __file__)  ## sets cwd, paths, logs, date parts

## Import configs
from Common_Configs import coreCanvasApiUrl, canvasAccessToken, gradTermsWordsToCodesDict

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Change Syllabus Tab"

scriptPurpose = r"""
Ensure Simple Syllabus is second in course navigation and hide the Canvas Syllabus tab if visible.
"""
externalRequirements = r"""
To function properly this script requires a spreadsheet of the most recent outcomes and the courses they are assigned to.
"""
## Setup the error handler
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function retrieves the navigation tabs for a given course sis id
def getNavigationTabs (p1_targetCourseSisId):
    functionName = "Get Navigation Tabs"
    try:
        ## Create the base and specific course API urls
        baseCourseApiUrl = coreCanvasApiUrl + "courses/sis_course_id:" + p1_targetCourseSisId
        navigationApiUrl = baseCourseApiUrl + "/tabs"
        ## Make the API call and save the result as navigationObject
        navigationObject = makeApiCall (localSetup, p1_apiUrl = navigationApiUrl)
        ## If the API status code is anything other than 200 it is an error, so log it and skip
        if (navigationObject.status_code != 200):
            localSetup.logger.error("\nNavigation Error: " + str(navigationObject.status_code))
            localSetup.logger.error(navigationApiUrl)
            localSetup.logger.error(navigationObject.url)
            return None
        ## If the API status code is 200, save the result as navigationTabs
        navigationTabs = navigationObject.json()
        ## Return the navigation tabs
        return navigationTabs

    except Exception as e:
        errorHandler.sendError (functionName, e)
        return None

def updateCourseSyllabusTab (p1_targetCourseSisId):
    functionName = "Update Course Syllabus Tab"
    try:
        ## Get the navigation tabs for the target course sis id
        navigationTabs = getNavigationTabs (p1_targetCourseSisId)

        ## If the navigation tabs is None, return
        if navigationTabs is None:
            return

        ## Define variables to hold the syllabus tab and simple syllabus tab
        syllabusTab = None
        simpleSyllabusTab = None
        
        ## Get the tab with the id of 'syllabus' and the tab with the id of 'external_tool_4856' if it exists
        for tab in navigationTabs:
            ## If the tab is the syllabus tab
            if tab['id'] == 'syllabus':
                syllabusTab = tab
            ## If the tab is the simple syllabus tab
            if tab['id'] == 'context_external_tool_4856':
                simpleSyllabusTab = tab

        ## If the syllabus tab's visibility is public, or if its position is not equal to the length of the navigation tabs, hide the syllabus tab and move it to the end
        if syllabusTab['visibility'] == 'public' or syllabusTab['position'] != (len(navigationTabs) - 2):
            ## Create the base and specific course API urls
            baseCourseApiUrl = coreCanvasApiUrl + "courses/sis_course_id:" + p1_targetCourseSisId
            updateTabApiUrl = baseCourseApiUrl + f"/tabs/{syllabusTab['id']}"
            ## Define the payload to hide the tab
            payload = {"hidden": True, "position": (len(navigationTabs) - 2)}
            ## Make the API call and save the result as updateTabObject
            updateTabObject = makeApiCall (localSetup, p1_apiUrl = updateTabApiUrl, p1_payload = payload, p1_apiCallType = "put")
            ## If the API status code is anything other than 200 it is an error, so log it and skip
            if (updateTabObject.status_code != 200):
                localSetup.logger.error("\nUpdate Tab Error: " + str(updateTabObject.status_code))
                localSetup.logger.error(updateTabApiUrl)
                localSetup.logger.error(updateTabObject.url)
                return
            ## Log the fact that the tab was updated
            localSetup.logger.info(f"\nSyllabus tab hidden for course {p1_targetCourseSisId}")

        ## If there isn't a simple syllabus tab in the list or if it exists but it is not in position 2 tab is the simple syllabus tab
        if not simpleSyllabusTab or (simpleSyllabusTab.get('position') != 2 or simpleSyllabusTab.get('hidden') == True):
            ## Create the base and specific course API urls
            baseCourseApiUrl = coreCanvasApiUrl + "courses/sis_course_id:" + p1_targetCourseSisId
            updateTabApiUrl = baseCourseApiUrl + f"/tabs/{simpleSyllabusTab['id']}"
            ## Define the payload to move the tab to position 2
            payload = {'visibility' : 'public', 'position': 2, 'hidden': False}
            ## Make the API call and save the result as updateTabObject
            updateTabObject = makeApiCall (localSetup, p1_apiUrl = updateTabApiUrl, p1_payload = payload, p1_apiCallType = "put")
            ## If the API status code is anything other than 200 it is an error, so log it and skip
            if (updateTabObject.status_code != 200):
                localSetup.logger.error("\nUpdate Tab Error: " + str(updateTabObject.status_code))
                localSetup.logger.error(updateTabApiUrl)
                localSetup.logger.error(updateTabObject.url)
                return
            ## Log the fact that the tab was updated
            localSetup.logger.info(f"\nSimple Syllabus tab moved to position 2 for course {p1_targetCourseSisId}")


    except Exception as e:
        errorHandler.sendError (functionName, e)
        ##return

if __name__ == "__main__":

    ## Target the course Sandbox_Bryce_Miller for testing
    targetCourseSisId = "GS2026_ACCT6016_1L"
    ## Update the course syllabus tab
    updateCourseSyllabusTab (targetCourseSisId)

    input("Press enter to exit")

## ===========================================================================
## FILE: ActionModules\Change_Term_For_Listed_Courses.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

import traceback, os, sys, logging, requests, threading, time, pandas as pd
import pandas as pd
from datetime import datetime

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Change_Term_For_Listed_Courses"

scriptPurpose = r"""
This script reads a CSV file containing Canvas course IDs and changes the term for each course using the Canvas API.
"""
externalRequirements = r"""
To function properly, this script requires a valid access header and URL, and a CSV file named "courses_to_set_term.csv" located in the Canvas Resources directory.
"""

## Date Variables
currentDateTime = datetime.now()
currentMonth = currentDateTime.month
currentYear = currentDateTime.year

## Set working directory
os.chdir(os.path.dirname(__file__))

## Relative Path (this changes depending on the working directory of the main script)
PFRelativePath = r".\\"

## If the Canvas directory is not in the folder the relative path points to
## find the Canvas directory and set the relative path to its parent folder
while "Scripts TLC" not in os.listdir(PFRelativePath):
    PFRelativePath = f"..\\{PFRelativePath}"

## Change the relative path to an absolute path
absolutePath = f"{os.path.abspath(PFRelativePath)}\\"

## Local Path Variables
baseLogPath = f"{absolutePath}Logs\\{scriptName}\\"
baseLocalInputPath = f"{absolutePath}Canvas Resources\\"
configPath = f"{absolutePath}Configs TLC\\"

## If the base log path doesn't already exist, create it
if not os.path.exists(baseLogPath):
    os.makedirs(baseLogPath, mode=0o777, exist_ok=False)

## Add Input Modules to the sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ResourceModules")
sys.path.append(f"{absolutePath}Scripts TLC\\ActionModules")

## Import local modules
from Error_Email_API import errorEmailApi  ## Import errorEmailApi
from Make_Api_Call import makeApiCall  ## Import makeApiCall

## Canvas Instance Url
coreCanvasApiUrl = None
## Open the Core_Canvas_Url.txt from the config path
with open(f"{configPath}Core_Canvas_Url.txt", "r") as file:
    coreCanvasApiUrl = file.readlines()[0]

## If the script is run as main the folder with the access token is in the parent directory
canvasAccessToken = ""

## Open and retrieve the Canvas Access Token
with open(f"{configPath}Canvas_Access_Token.txt", "r") as file:
    canvasAccessToken = file.readlines()[0]

## Log configurations
logger = logging.getLogger(__name__)
rootFormat = ("%(asctime)s %(levelname)s %(message)s")
FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
logging.basicConfig(format=rootFormat, filemode="a", level=logging.INFO)

## Info Log Handler
infoLogFile = f"{baseLogPath}\\Info Log.txt"
logInfo = logging.FileHandler(infoLogFile, mode='a')
logInfo.setLevel(logging.INFO)
logInfo.setFormatter(FORMAT)
localSetup.logger.addHandler(logInfo)

## Warning Log handler
warningLogFile = f"{baseLogPath}\\Warning Log.txt"
logWarning = logging.FileHandler(warningLogFile, mode='a')
logWarning.setLevel(logging.WARNING)
logWarning.setFormatter(FORMAT)
localSetup.logger.addHandler(logWarning)

## Error Log handler
errorLogFile = f"{baseLogPath}\\Error Log.txt"
logError = logging.FileHandler(errorLogFile, mode='a')
logError.setLevel(logging.ERROR)
logError.setFormatter(FORMAT)
localSetup.logger.addHandler(logError)

## Setup the error handler
## an error email the first time the function triggers an error
errorHandler = errorEmailApi(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function handles function errors
def errorHandler(p1_ErrorLocation, p1_ErrorInfo, sendOnce=True):
    functionName = "## errorHandler.sendError"
    localSetup.logger.error(f"\nA script error occurred while running {p1_ErrorLocation}. Error: {str(p1_ErrorInfo)}")

    ## If the function with the error has not already been processed send an email alert
    if p1_ErrorLocation not in setOfFunctionsWithErrors:
        errorEmailApi.sendEmailError(p2_ScriptName=scriptName, p2_ScriptPurpose=scriptPurpose,
                                     p2_ExternalRequirements=externalRequirements,
                                     p2_ErrorLocation=p1_ErrorLocation, p2_ErrorInfo=p1_ErrorInfo)
        setOfFunctionsWithErrors.add(p1_ErrorLocation)
        localSetup.logger.error(f"\nError Email Sent")
    else:
        localSetup.logger.error(f"\nError email already sent")

## This function sets the term for a course given its Canvas course ID and term ID
def setCourseTerm(p1_header, p1_courseId, p1_termId):
    functionName = "setCourseTerm"
    try:
        set_term_url = f"{coreCanvasApiUrl}courses/{p1_courseId}"
        payload = {"course": {"enrollment_term_id": p1_termId}}
        response = makeApiCall(localSetup, p1_header=p1_header, p1_apiUrl=set_term_url, p1_payload=payload, p1_apiCallType="put")

        if response.status_code == 200:
            localSetup.logger.info(f"Successfully set term for course with ID: {p1_courseId}")
        else:
            localSetup.logger.warning(f"Failed to set term for course with ID: {p1_courseId}. Status code: {response.status_code}")

    except Exception as Error:
        except(functionName, Error)

## This function reads the CSV file and sets the term for the listed courses
def setListedCoursesTerm():
    functionName = "setListedCoursesTerm"
    try:
        targetCoursesCsvFilePath = f"{baseLocalInputPath}Target_Canvas_Course_Ids.csv"
        header = {'Authorization': f"Bearer {canvasAccessToken}"}
        
        ## Define the necessary thread list
        ongoingSetTermThreads = []

        ## Read the CSV file using pandas
        rawTargetCoursesDf = pd.read_csv(targetCoursesCsvFilePath)

        ## Retain only rows that have a value in canvas_course_id
        targetCoursesDf = rawTargetCoursesDf[rawTargetCoursesDf["canvas_course_id"].notna()]

        ## Iterate over each row in the DataFrame
        for index, row in targetCoursesDf.iterrows():

            ## Get the course id from the row
            courseId = str(row["canvas_course_id"]).replace('.0', '')

            ## Get the term id from the row
            termId = str(row["canvas_term_id"]).replace('.0', '')

            ## Create a thread to set the term for the course
            setTermThread = threading.Thread(target=setCourseTerm, args=(header, courseId, termId))

            ## Start the thread
            setTermThread.start()

            ## Add the thread to the ongoing set term threads list
            ongoingSetTermThreads.append(setTermThread)

            ## Sleep for a short time to avoid overloading the server
            time.sleep(0.1)

        ## Check if all ongoing set term threads have completed
        for thread in ongoingSetTermThreads:
            thread.join()

    except Exception as Error:
        except(functionName, Error)

if __name__ == "__main__":
    ## Set working directory
    os.chdir(os.path.dirname(__file__))

    ## Set the term for the listed courses
    setListedCoursesTerm()

    input("Press enter to exit")


## ===========================================================================
## FILE: ActionModules\Comment Out Error Handling.py
## ===========================================================================

import os
import re


def comment_keywords_in_py_files(directory):
    # pattern -> {exception: <regex or None>, strip_indent: bool}
    patterns = {
        # Just comment the keyword wherever it appears
        r'\b    functionName\b': {
            'exception': None,
            'strip_indent': False,
        },

        # Comment any "    try:"-style line, but strip indent in the comment
        r'^\s*try\s*:': {
            'exception': r'try\s*:\s*##\s*Irregular',
            'strip_indent': True,
        },

        # Comment any "    except ...:" line, strip indent in the comment
        r'^\s*except\b.*:\s*$': {
            'exception': r'except\b.*:\s*##\s*Irregular',
            'strip_indent': True,
        },

        # Comment errorHandler.sendError usage
        r'\berrorHandler\.sendError\b': {
            'exception': r'def\s+errorHandler\.sendError',
            'strip_indent': False,
        },
    }

    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.py') and "Canvas_Report" not in file:
                file_path = os.path.join(root, file)

                # Skip the excluded file
                if 'comment out error handling' in file_path.lower():
                    continue

                with open(file_path, 'r') as f:
                    lines = f.readlines()

                modified_lines = []
                for line in lines:
                    modified_line = line
                    for pattern, cfg in patterns.items():
                        exception = cfg['exception']
                        strip_indent = cfg['strip_indent']

                        if re.search(pattern, line):
                            # Skip commenting if the exception pattern matches
                            if exception and re.search(exception, line):
                                continue

                            # Comment the matched keyword
                            def repl(m):
                                text = m.group(0)
                                if strip_indent:
                                    # Remove leading spaces from the matched text
                                    text = text.lstrip()
                                return f'## {text}'

                            modified_line = re.sub(pattern, repl, modified_line)
                    modified_lines.append(modified_line)

                with open(file_path, 'w') as f:
                    f.writelines(modified_lines)

    
## Replace this with your actual path
if __name__ == "__main__":
    target_directory = input("Enter the path to the target directory: ").strip()
    if os.path.isdir(target_directory):
        comment_keywords_in_py_files(target_directory)
        print(f"Processing complete for directory: {target_directory}")
    else:
        print("Invalid directory path. Please try again.")
    
        input ("Press Enter to exit...")


## ===========================================================================
## FILE: ActionModules\Count_Respondus_Quizzes_and_Users.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

import os, sys, threading, time, pandas as pd
from datetime import datetime

# Make ResourceModules importable (mirrors Course_Date_Related_Actions.py)
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

try:  # Irregular try clause, do not comment out in testing
    from Local_Setup import LocalSetup
    from Error_Email import errorEmail
    from TLC_Common import makeApiCall
except ImportError:
    # Fallback to relative imports if package layout differs
    from ResourceModules.Local_Setup import LocalSetup
    from ResourceModules.Error_Email import errorEmail
    from ResourceModules.TLC_Common import makeApiCall

#
# Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Count_Respondus_Quizzes"
scriptPurpose = r"""
This script counts the number of Respondus quizzes and the number of unique students who have submitted to
these quizzes in Canvas courses.
"""
externalRequirements = r"""
To function properly, this script requires:
1. Access to the Canvas API via the standard TLC makeApiCall / LocalSetup configuration.
2. A CSV file in the Canvas resources directory listing target course IDs
   (e.g. 'Target_Canvas_Course_Ids.csv' / 'courses_to_check.csv').
"""

# Initialize LocalSetup and error handler (mirrors Course_Date_Related_Actions.py)
localSetup = LocalSetup(datetime.now(), __file__)
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## Import Config Variables
from Common_Configs import coreCanvasApiUrl

# This function counts Respondus quizzes and students for a given course
def countRespondusQuizzes(p1_courseId: str, result_dict: dict) -> None:
    functionName = "countRespondusQuizzes"
    try:
        quizzes_count = 0
        students_count = set()

        # Get the assignments for the course
        assignments_url = f"{coreCanvasApiUrl}courses/{p1_courseId}/assignments"
        courseAssignmentsParams = {
            "search_term": "Respondus",
            "include[]": "submission",
        }

        # Header is provided by makeApiCall (via LocalSetup), no explicit header needed
        response = makeApiCall(
            localSetup,
            p1_apiUrl=assignments_url,
            p1_payload=courseAssignmentsParams,
            p1_apiCallType="get",
        )

        # If the response is successful
        if response.status_code == 200:
            # Convert the response to JSON
            assignments = response.json()

            # For each assignment in the course
            for assignment in assignments:
                # If the assignment name contains "Respondus"
                if "Respondus" in assignment.get("name", ""):
                    # Save the assignment ID
                    assignment_id = assignment["id"]

                    # Save the assignment URL
                    assignment_details_url = (
                        f"{coreCanvasApiUrl}courses/{p1_courseId}/assignments/{assignment_id}"
                    )

                    # Make an API call to get the assignment details
                    assignment_response = makeApiCall(
                        localSetup,
                        p1_apiUrl=assignment_details_url,
                        p1_apiCallType="get",
                    )

                    # If the response is successful
                    if assignment_response.status_code == 200:
                        # Convert the response to JSON
                        assignment_details = assignment_response.json()

                        # If the assignment is published and has submitted submissions
                        if assignment_details.get("published") and assignment_details.get(
                            "has_submitted_submissions"
                        ):
                            quizzes_count += 1

                            # If we haven't loaded enrollments yet, do it once per course
                            if len(students_count) == 0:
                                # Define an API url to get the course's enrollments
                                enrollments_url = (
                                    f"{coreCanvasApiUrl}courses/{p1_courseId}/enrollments"
                                )
                                # Define a payload to get only student enrollments
                                enrollments_params = {
                                    "type[]": "StudentEnrollment",
                                }

                                # Make an API call to get the course's enrollments
                                enrollments_response = makeApiCall(
                                    localSetup,
                                    p1_apiUrl=enrollments_url,
                                    p1_payload=enrollments_params,
                                    p1_apiCallType="get",
                                )

                                # If the response is successful
                                if enrollments_response.status_code == 200:
                                    # Convert the response to JSON
                                    enrollments = enrollments_response.json()

                                    # For each enrollment in the course
                                    for enrollment in enrollments:
                                        # If the enrollment is active
                                        if (
                                            enrollment.get("enrollment_state")
                                            == "active"
                                        ):
                                            # Get the user ID from the enrollment
                                            user_id = enrollment["user_id"]
                                            # Add the user ID to the students_count set
                                            students_count.add(user_id)
                                else:
                                    localSetup.logger.warning(
                                        f"Failed to get enrollments for course {p1_courseId}. "
                                        f"Status code: {enrollments_response.status_code}"
                                    )
        else:
            localSetup.logger.warning(
                f"Failed to get assignments for course with ID: {p1_courseId}. "
                f"Status code: {response.status_code}"
            )

        # Store results as (quiz_count, set_of_student_ids)
        result_dict[p1_courseId] = (quizzes_count, students_count)

    except Exception as Error:
        # Use the shared error handler from Error_Email
        errorHandler.sendError(functionName, Error)
        # Optionally, still record something in result_dict to avoid KeyError downstream
        result_dict[p1_courseId] = (0, set())


## This function reads the CSV file and counts Respondus quizzes and students for the listed courses
def countListedCoursesRespondusQuizzes() -> None:
    functionName = "countListedCoursesRespondusQuizzes"
    try:
        # Locate the Canvas resources directory using LocalSetup, similar to SIS in Course_Date_Related_Actions.py
        baseCanvasResourcesPath = localSetup.getInternalResourcePaths('Canvas')

        # Adjust the filename here if you prefer 'courses_to_check.csv'
        targetCoursesCsvFilePath = os.path.join(
            baseCanvasResourcesPath, "Target_Canvas_Course_Ids.csv"
        )

        # Define the necessary thread list
        ongoingCountThreads = []
        result_dict = {}

        # Read the CSV file using pandas
        rawTargetCoursesDf = pd.read_csv(targetCoursesCsvFilePath)

        # Retain only rows that have a value in canvas_course_id
        targetCoursesDf = rawTargetCoursesDf[
            rawTargetCoursesDf["canvas_course_id"].notna()
        ]

        # Iterate over each row in the DataFrame
        for index, row in targetCoursesDf.iterrows():
            # Get the course id from the row
            courseId = str(row["canvas_course_id"]).replace(".0", "")

            # Create a thread to count Respondus quizzes for the course
            countThread = threading.Thread(
                target=countRespondusQuizzes,
                args=(courseId, result_dict),
            )

            # Start the thread
            countThread.start()

            # Add the thread to the ongoing count threads list
            ongoingCountThreads.append(countThread)

            # Sleep for a short time to avoid overloading the server
            time.sleep(0.1)

        # Wait for all count threads to complete
        for thread in ongoingCountThreads:
            thread.join()

        total_quizzes = sum(result[0] for result in result_dict.values())
        total_students = set()
        for result in result_dict.values():
            total_students.update(result[1])

        localSetup.logger.info(f"Total Respondus quizzes: {total_quizzes}")
        localSetup.logger.info(
            f"Total unique students: {len(total_students)} across all courses"
        )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":
    ## Set working directory
    os.chdir(os.path.dirname(__file__))

    ## Count Respondus quizzes for the listed courses
    countListedCoursesRespondusQuizzes()

    input("Press enter to exit")


## ===========================================================================
## FILE: ActionModules\Course_Date_Related_Actions.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller.

## Import Generic Moduels

import os, sys, threading, asyncio
import pandas as pd
from datetime import datetime

# Ensure ResourceModules are importable when running from ActionModules
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

try: ## Irregular try clause, do not comment out in testing
    from Local_Setup import LocalSetup
    from Canvas_Report import CanvasReport
    from Core_Microsoft_Api import sendOutlookEmail, CoreMicrosoftAPI
    from Error_Email import errorEmail
    from TLC_Common import isPresent
    from Add_Outcomes_to_Active_Courses import (
        retrieveDataForRelevantCommunication,
        getUniqueOutcomesAndOutcomeCoursesDict,
        removeMissingOutcomes,
        addOutcomeToCourse,
    )
except ImportError:
    # Fallback to relative imports if package layout differs
    from ResourceModules.Local_Setup import LocalSetup
    from ResourceModules.Canvas_Report import CanvasReport
    from ResourceModules.Core_Microsoft_Api import sendOutlookEmail
    from ResourceModules.Error_Email import errorEmail
    from ResourceModules.TLC_Common import isPresent
    from ActionModules.Add_Outcomes_to_Active_Courses import (
            retrieveDataForRelevantCommunication,
            getUniqueOutcomesAndOutcomeCoursesDict,
            removeMissingOutcomes,
            addOutcomeToCourse,
        )

## Set working directory
os.chdir(os.path.dirname(__file__))

# Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Course_Date_Related_Actions"

scriptPurpose = r"""
This script determines what course date related actions need to be taken for a specific term, such as sending outcome related emails to instructors, and performs those actions.
"""
externalRequirements = r"""
This script requires the following external resources:
1. Access to the Canvas API for retrieving course and instructor data.
2. Access to the email system for sending outcome related emails to instructors.
3. The ResourceModules and ActionModules directories in the Scripts TLC directory for additional functionality.
"""

## Initialize LocalSetup and helpers from ResourceModules
localSetup = LocalSetup(datetime.now(), __file__)
errorHandler = errorEmail(scriptName if 'scriptName' in globals() else 'Course_Date_Related_Actions', scriptPurpose, externalRequirements, localSetup)


# Canvas API header is provided by makeApiCall default; do not define header here

## This Function creates a formated Mising Outcome Attachment Email Body
def createOutcomeEmailBody (p3_relevantEmail
                            , p4_inputTerm
                            , p1_instructorNameOrNames
                            , p1_course
                            , p1_relevantAuthority
                            , p1_outcome
                            , p1_emailDetails
                            ):
    
    functionName = "createErrorEmailBody"

    ## Define the email body dictionary
    emailBodyDict = {}        
    
    ## Define a variable for the singular or plural word dict according to whether
    singularOrPluralDict = {}
    
    ## If </li> appears more than once in the outcome string
    if p1_outcome.count("</li>") > 1:
        
        ## Assign the plural word dict
        singularOrPluralDict = {"is/are" : "are"
                                , "has/have" : "have"
                                , "this/these" : "these"
                                , "a/" : ""
                                , "outcome/outcomes" : "outcomes"
                                , "designatorSpecificTerm" : "habits" if "GE" in p1_outcome else "outcomes"
                                , "rubric/rubrics" : "rubrics"
                                , "assignment/assignments" : "assignments"
                                }
        
    ## Otherwise
    else:
        
        ## Assign the singular word dict
        singularOrPluralDict = {"is/are" : "is"
                                , "has/have" : "has"
                                , "this/these" : "this"
                                , "a/" : " a"
                                , "outcome/outcomes" : "outcome"
                                , "designatorSpecificTerm" : "habit" if "GE" in p1_outcome else "outcome"
                                , "rubric/rubrics" : "rubric"
                                , "assignment/assignments" : "assignment"
                                }
        
    ## If there is more than one instructor, designated by whether there is is a comma in the instructor name string
    if ',' in p1_instructorNameOrNames:
        
        ## Assign the neccessary plural Professor/Professors string
        singularOrPluralDict["Professor/Professors"] = "Professors"
        
        ## Assign the neccessary plural instructor/instructors string
        singularOrPluralDict["an instructor/instructors"] = "instructors"
        
    ## Otherwise
    else:
        
        ## Assign the neccessary singular Professor/Professors string
        singularOrPluralDict["Professor/Professors"] = "Professor"
        
        ## Assign the neccessary singular an instructor/instructors string
        singularOrPluralDict["an instructor/instructors"] = "an instructor"

    ## Set the emailbodysignature to Client Email Signature
    emailBodyDict["signature"] = p1_emailDetails["Client Email Signature"]
        
    ## Define the action
    emailBodyDict["bulletted resource list"]  = """<li><a href='https://community.canvaslms.com/t5/Instructor-Guide/How-do-I-align-an-outcome-with-a-rubric-in-a-course-using/ta-p/609340' target='_blank'>Attaching an outcome to a rubric</a></li>
    <li><a href='https://community.canvaslms.com/t5/Instructor-Guide/How-do-I-add-a-rubric-to-an-assignment/ta-p/1058#open_assignment' target='_blank'>Attaching a rubric to an assignment</a></li>
    <li><a href='https://community.canvaslms.com/t5/Instructor-Guide/How-do-I-add-a-rubric-to-a-graded-discussion/ta-p/1062#open_discussion' target='_blank'>Attaching a rubric to a graded discussion</a></li>
    <li><a href='https://community.canvaslms.com/t5/Instructor-Guide/How-do-I-add-a-rubric-to-a-quiz/ta-p/1009#open_quiz' target='_blank'>Attaching a rubric to a classic quiz</a></li>
    <li><a href='https://community.canvaslms.com/t5/Instructor-Guide/How-do-I-align-an-outcome-to-a-quiz-in-New-Quizzes/ta-p/776#open-assessment' target='_blank'>Attaching an outcome to a new quiz</a></li>
    <li><a href='https://community.canvaslms.com/t5/Instructor-Guide/How-do-I-align-an-outcome-to-a-quiz-question-in-New-Quizzes/ta-p/778#edit-quiz' target='_blank'>Attaching an outcome to a new quiz question</a></li>
    <li><a href='https://community.canvaslms.com/t5/Instructor-Guide/How-do-I-use-a-rubric-to-grade-submissions-in-SpeedGrader/ta-p/1015#open_student_submission' target='_blank'>Using a rubric to grade submissions in SpeedGrader</a></li>
    <li><a href='https://community.canvaslms.com/t5/Instructor-Guide/How-do-I-use-a-non-scoring-rubric-to-assess-submissions-in/ta-p/989' target='_blank'>Using a non-scoring rubric to assess submissions in SpeedGrader</a></li>"""

    ## If the relevant email is a course start email
    if "Course Start" in p3_relevantEmail:
            
        ## Assign the future or current instructor dynamic string
        emailBodyDict["future/current instructor"] = "are scheduled to be"
            
        ## Assign the course start dynamic cause string
        emailBodyDict["dynamic cause"] = f"which has the following {singularOrPluralDict['outcome/outcomes']} associated with it:"
            
        ## Assign the course start reminder to attach outcomes to published assignments string
        emailBodyDict["timeOfYearReminder"] = f"""As we begin the term, please ensure that the {singularOrPluralDict['designatorSpecificTerm']} langauge is included in your courses's syllabus.{p1_emailDetails['Dept Specific Wording']}</p>
        <p> Additionally, please consider how you will perform your outcome assessment, particularly which course assignment or assignments you will attach the {singularOrPluralDict['outcome/outcomes']} to."""
        
    ## If the relevant email is a reminder
    elif  "Reminder" in p3_relevantEmail:
            
        ## Assign the future or current instructor dynamic string
        emailBodyDict["future/current instructor"] = "are"
            
        ## Assign the reminder dynamic cause string
        emailBodyDict["dynamic cause"] = f"where it appears that the following {singularOrPluralDict['is/are']} not attached to a published assignment:"
    
        ## If it is a midterm reminder
        if "Midterm" in p3_relevantEmail:
        
            ## Assign the midterm reminder to attach outcomes to published assignments string
            emailBodyDict["timeOfYearReminder"] = f"""As we proceed through midterm week for your course, please consider how you will perform your outcome assessment, and make sure that you have the most recent version of your {singularOrPluralDict['outcome/outcomes']} attached to an assignment rubric."""

        ## If it is a finals reminder
        elif "Finals" in p3_relevantEmail:
        
            ## Assign the finals reminder to attach outcomes to published assignments string
            emailBodyDict["timeOfYearReminder"] = f"""As finals week has arrived, please make sure that you have the most recent version of the {singularOrPluralDict['outcome/outcomes']} attached to at least one rubric and that the associated {singularOrPluralDict['rubric/rubrics']} are attached to {singularOrPluralDict['a/']}published {singularOrPluralDict['assignment/assignments']}."""

    elif "Missing" in p3_relevantEmail:
            
        ## Assign the future or current instructor dynamic string
        emailBodyDict["future/current instructor"] = "were"

        ## Assign the alert that there outcome data missing dynamic cause string
        emailBodyDict["dynamic cause"] = f"where it appears that less than 75% of the students have been scored for the following {singularOrPluralDict['outcome/outcomes']}:"
        
        ## Assign the missing data alert string
        emailBodyDict["timeOfYearReminder"] = f"""For outcome data to be recorded, an additional grading step is required for each student that submitted to an assignment with an outcome rubric attached."""
        
    emailBodyDict["formatedEmaiBody"] = f"""<!DOCTYPE html>
<html>
<body>
<p>Hello {singularOrPluralDict["Professor/Professors"]} {p1_instructorNameOrNames},<br></p>
    
<p>You are receiving this email because you {emailBodyDict["future/current instructor"]} {singularOrPluralDict["an instructor/instructors"]} of the NNU outcome course {p1_course}, {emailBodyDict["dynamic cause"]}</p>
    
<ul>{p1_outcome}</ul>
    
<p>{emailBodyDict["timeOfYearReminder"]}<br></p>
    
<p>If you would like a refresher on how to do this, please identify your interest below:</p>
    
<ul>{emailBodyDict["bulletted resource list"]}</ul>
    
<p>{p1_emailDetails['User Contact Name'] or p1_emailDetails['Client Contact Name']} can be reached at <a href='mailto:{p1_emailDetails["User Contact Email"] or p1_emailDetails['Client Send/Recieve Email']}'>{p1_emailDetails["User Contact Email"] or p1_emailDetails['Client Send/Recieve Email']}</a> and is a good resource for how to assess your associated outcomes in your field of study. Additionally, NNU's Teaching and Learning Center at <a href='mailto:tlc@nnu.edu'>tlc@nnu.edu</a> is always ready to provide ideas, best practice tips, and assistance with creating and assessing outcomes.<br></p>

    {emailBodyDict["signature"]}
"""
        
    return emailBodyDict["formatedEmaiBody"]

## This function crafts and sends the relevant outcome email
def craftAndSendRelevantEmail(
        p3_inputTerm,
        p2_relevantEmail,
        p2_row,
        p1_auxiliaryDfDict,
    ):
    
    functionName = "craftAndSendRelevantEmail"
    
    try:
        ## Define baseExternalInputPath in function scope
        baseExternalInputPath = localSetup.getExternalResourcePath("SIS") or localSetup.configPath

        ## Retrieve the Automated Outcome Tool Variables excel file as a df    
        automatedOutcomeToolVariablesDf = pd.read_excel(os.path.join(baseExternalInputPath, "Internal Tool Files", "Automated Outcome Tool Variables.xlsx"))
        
        ## Filter the automated outcome tool variables df to only the row with the relevant outcome area
        automatedOutcomeToolVariablesDict = automatedOutcomeToolVariablesDf[
            automatedOutcomeToolVariablesDf["Target Designator"] == p2_row["Outcome Area"]
            ].iloc[0].to_dict()

        ## If the Outcome Communication Opt In is false for the relevant outcome area
        if not automatedOutcomeToolVariablesDict["Outcome Communication Opt In"]:

            ## Return from the function without sending an email
            return
        
        ## Make a filtered Unassessed Outcome Courses DF that only includes the course that the email is being sent about
        filteredUnassessedOutcomeCoursesDF = p1_auxiliaryDfDict["Unassessed Outcome Courses DF"][
            p1_auxiliaryDfDict["Unassessed Outcome Courses DF"]["Course_name"] == p2_row["Course_name"]
            ]

        ## Create an email details dictionary
        emailDetails = {"Client Name" : automatedOutcomeToolVariablesDict["Client Name"]
                        , "Client Contact Name" : automatedOutcomeToolVariablesDict["Client Contact Name"]
                        , "Client Send/Recieve Email" : automatedOutcomeToolVariablesDict["Client Send/Recieve Email"]
                        , "Client Email Signature" : f"""{automatedOutcomeToolVariablesDict["Client Email Signature"]}"""
                        , "User Contact Name" : (
                            automatedOutcomeToolVariablesDict["User Contact Name"] 
                            if isPresent(automatedOutcomeToolVariablesDict["User Contact Name"]) 
                            else automatedOutcomeToolVariablesDict["Client Contact Name"]
                            )
                        , "User Contact Email" :automatedOutcomeToolVariablesDict["User Contact Email"]
                        , "Input Term": p3_inputTerm
                        , "Course Name": p2_row["Course_name"]
                        , "Relevant Email": p2_relevantEmail
                        , "Outcome Email Subject": f"{p2_row['Course_name']} {p2_relevantEmail}"
                        , "Dept Specific Wording": (
                            " " + str(automatedOutcomeToolVariablesDict["Dept Specific Wording"])
                            if isPresent(automatedOutcomeToolVariablesDict["Dept Specific Wording"]) 
                            else ""
                            )
                        }


        ## If the relevant email is an outcome email
        if "Outcome" in p2_relevantEmail:

            ## Add the outcome area to the email details
            emailDetails["Outcome Area"] = p2_row["Outcome Area"]
    
            ## Iterate through the p2_rows datapoints to find the instructor and outcome information
            for key, datapoint in p2_row.items():
        
                ## If the datapoint is teacher related
                if "Instructor" in key:
        
                    ## If the datapoint is a teacher name
                    if "name" in key and pd.notna(datapoint):
                
                        ## If there is already a name in instructorNameOrNamesString
                        if "Instructor Name Or Names String" in emailDetails.keys():

                            ## Seperate the last name from the datapoint
                            lastName = datapoint.split(" ")[-1]
                
                            ## Add a comma and space and then the additional name
                            emailDetails["Instructor Name Or Names String"] += f", {lastName}"
                        
                        ## Otherwise
                        else:

                            ## Seperate the last name from the datapoint
                            lastName = datapoint.split(" ")[-1]
                        
                            ## Change the instructor name string to the datapoint name
                            emailDetails["Instructor Name Or Names String"] = lastName

                    ## If the datapoint is a teacher email
                    elif "email" in key and pd.notna(datapoint):

                        ## If the key does not already exist in the email details
                        if "Instructor Email Or Emails String" not in emailDetails.keys():
                            
                            ## Add the teacher name to the list of instructor names
                            emailDetails["Instructor Email Or Emails String"] = f"{datapoint}"
                        
                        ## Otherwise
                        else:

                            ## Add the teacher name to the list of instructor names
                            emailDetails["Instructor Email Or Emails String"] += f", {datapoint}"


                ## If the datapoint is an outcome
                elif "Outcome" in key and pd.notna(datapoint) and key != "Outcome Area":
                    
                    ## If the email is a missing required data email
                    if "Missing" in p2_relevantEmail:
                        
                        ## If the data point is not amoung a list of the unique outcome titles in the filteredUnassessedOutcomeCoursesDF
                        if datapoint not in filteredUnassessedOutcomeCoursesDF["Outcome_Title"].values:
                            
                            ## Skip the datapoint
                            continue

                    ## If the key does not already exist in the email details
                    if "Outcome Or Outcomes String" not in emailDetails.keys():
                        
                        ## Add the outcome to the list of outcomes as an li element
                        emailDetails["Outcome Or Outcomes String"] = f"<li>{datapoint}</li>"

                    ## Otherwise
                    else:
            
                        ## Add the outcome to the list of outcomes as an li element
                        emailDetails["Outcome Or Outcomes String"] += f"<li>{datapoint}</li>"

            ## Create the formated email contents
            emailDetails['Outcome Email Body'] = createOutcomeEmailBody(p3_relevantEmail = p2_relevantEmail
                                                          , p4_inputTerm = p3_inputTerm
                                                          , p1_instructorNameOrNames = emailDetails["Instructor Name Or Names String"]
                                                          , p1_course = p2_row["Course_name"]
                                                          , p1_outcome = emailDetails["Outcome Or Outcomes String"]
                                                          , p1_relevantAuthority = emailDetails["Client Name"]
                                                          , p1_emailDetails = emailDetails
                                                          )

            ## Send the Outcome Email
            sendOutlookEmail(p1_subject = emailDetails['Relevant Email']
                             , p1_body = emailDetails['Outcome Email Body']
                             , p1_recipientEmailList = emailDetails['Instructor Email Or Emails String']
                             , p1_shared_mailbox = emailDetails['Client Send/Recieve Email']
                             )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This function determines what course date related actions need to be taken for a specific term and performs them
def termDetermineAndPerformRelevantActions (p1_inputTerm
                                            , p1_targetDesignator
                                            ):
    functionName = "Term Determine And Send Relevant Communication"

    try:

        ## Retrieve the data for determining and sending out relevant communication
        completeActiveCanvasCoursesDF, auxiliaryDfDict = retrieveDataForRelevantCommunication(p2_inputTerm = p1_inputTerm
                                                                                              , p3_targetDesignator = p1_targetDesignator
                                                                                              )
                
        ## Define a list to hold the communication threads
        actionThreads = []
        
        ## For each row in the complete active canvas courses df
        for index, row in completeActiveCanvasCoursesDF.iterrows():
            
            ## If ENGR4250 in row long_name
            #if "WELL1000" in row["long_name"]:

                ## Define a variable to track whether the course is an outcome course
                isOutcomeCourse = True if row["long_name"] in auxiliaryDfDict["Active Outcome Courses DF"]["Course_name"].values else False

                ## Define a relevant auxillary DF dict with empty dataframes
                relevantAuxillaryDfDict = {}
            
                ## If the course is in the list of courses who do not have their outcome attached to a published assignment
                if not auxiliaryDfDict["Outcome Courses Without Attachments DF"].empty:
                    
                    ## Isolate the course's data in p1_outcomeCoursesWithoutAttachmentDF
                    relevantAuxillaryDfDict["Relevant Course Outcome Without Attachment Df"] = (
                        auxiliaryDfDict["Outcome Courses Without Attachments DF"][
                            auxiliaryDfDict["Outcome Courses Without Attachments DF"]["Course_name"] == row["long_name"]
                            ]
                        )
                    
                ## Otherwise
                else:

                    ## Create an empty dataframe for the courses without attached outcomes
                    relevantAuxillaryDfDict["Relevant Course Outcome Without Attachment Df"] = pd.DataFrame()

                ## If the course is in the list of courses who have no outcome results
                if not auxiliaryDfDict["Unassessed Outcome Courses DF"].empty:
                    
                    ## Isolate the course's data in p1_outcomeCoursesWithoutOutcomeData
                    relevantAuxillaryDfDict["Relevant Course Outcome Without Data Df"] = (
                        auxiliaryDfDict["Unassessed Outcome Courses DF"][
                            auxiliaryDfDict["Unassessed Outcome Courses DF"]["Course_name"] == row["long_name"]
                            ]
                        )
                    
                ## Otherwise
                else:
                    
                    ## Create an empty dataframe for the courses without outcome data
                    relevantAuxillaryDfDict["Relevant Course Outcome Without Data Df"] = pd.DataFrame()
            
                ## Define a variable to track what email, if any, needs to be sent to the instructors of the course
                relevantEmailList = []
            
                ## If it is the monday before the courses's week 0 and it is an outcome course
                if (row['Course Week'] == 0
                    and isOutcomeCourse
                    ):                
                    
                        ## Make a list of the unique outcomes that are not blank 
                        ## and a diMct to hold the course id of the course named after each outcome
                        uniqueOutcomes, outcomeCourseDict = getUniqueOutcomesAndOutcomeCoursesDict(p1_inputTerm, completeActiveCanvasCoursesDF, p1_targetDesignator)

                        ## Remove any outcomes that don't have corresponding courses
                        auxiliaryDfDict["Active Outcome Courses DF"] = removeMissingOutcomes (auxiliaryDfDict["Active Outcome Courses DF"], uniqueOutcomes, outcomeCourseDict)
                    
                        ## Start a thread to make sure the outcome has been added to the course
                        addOutcomeThread = threading.Thread(
                            target=addOutcomeToCourse
                            , args=(row
                                    , auxiliaryDfDict
                                    )
                            )

                        ## Start the thread
                        addOutcomeThread.start()

                        ## Add the thread to the list of communication threads
                        actionThreads.append(addOutcomeThread)
        
                ## If it is the Monday of week 0
                if (row['Course Week'] == 0
                    and localSetup.initialDateTime.weekday() == 0
                      ):

                    ## If the course is an Outcome course
                    if isOutcomeCourse:

                        ## Send the courses's instructors the Course Start email
                        relevantEmailList.append("Associated Course Outcomes: Course Start Information")
                        
                ## Otherwise, if it is the Monday of the week before the course's midpoint (e.g. week 7 in a 16 week course)
                elif (row['Course Week'] == (int(row["Course Final Week"] / 2) - 1)
                      and localSetup.initialDateTime.weekday() == 0
                      ): ## Casting the result of courseLength / 2 to int rounds the number down        
            
                    ## If the course is an Outcome course
                    if isOutcomeCourse:

                        ## If the course is an outcome course that does not have all of its outcomes attached to published assignments
                        if not relevantAuxillaryDfDict["Relevant Course Outcome Without Attachment Df"].empty:    
                
                            ## Send the courses's instructors the Midterm Reminder email
                            relevantEmailList.append("Associated Course Outcomes: Midterm Reminder")

                ## Otherwise, if it is the Monday of the week before its final week (e.g. week 15 in a 16 week course)
                elif (row['Course Week'] == (row["Course Final Week"] -1)
                      and localSetup.initialDateTime.weekday() == 0
                      ):

                    ## If the course is an Outcome course
                    if isOutcomeCourse:

                        ## If the course is an outcome course that does not have all of its outcomes attached to published assignments
                        if not relevantAuxillaryDfDict["Relevant Course Outcome Without Attachment Df"].empty: 
                
                            ## Send the courses's instructors the Finals Reminder email
                            relevantEmailList.append("Associated Course Outcomes: Finals Reminder")

                ## Otherwise, if it is the wednesday of the week after finals (e.g. week 17 from the start of a 16 week course)
                elif (row['Course Week'] == (row["Course Final Week"] + 1)
                      and localSetup.initialDateTime.weekday() == 2
                      ):
            
                    ## If the course is an Outcome course
                    if isOutcomeCourse:

                        ## If the course is in the list of courses who do not have all of their outcome data
                        if not relevantAuxillaryDfDict["Relevant Course Outcome Without Data Df"].empty:    
            
                            ## Send the courses's instructors the Missing Data email as the course's outcome data is past due
                            relevantEmailList.append("Associated Course Outcomes: Missing Required Data")

                ## For each determined relevant email
                for relevantEmail in relevantEmailList:
                
                    ## Define a target row variable
                    targetRow = None
                
                    ## If the relevant email contains the word "Outcome"
                    if "Outcome" in relevantEmail:
                    
                        ## Find the index of course in the active outcome courses df
                        courseIndex = auxiliaryDfDict["Active Outcome Courses DF"][
                            auxiliaryDfDict["Active Outcome Courses DF"]["Course_name"] == row["long_name"]
                            ].index[0]

                        ## Define the target row as the row in the active outcome courses df
                        targetRow = auxiliaryDfDict["Active Outcome Courses DF"].loc[courseIndex]
                    
                        
                    ## Create a thread to send the relevant outcome email
                    communicationThread = threading.Thread(
                        target=craftAndSendRelevantEmail
                        , args=(p1_inputTerm
                                , relevantEmail
                                , targetRow
                                , auxiliaryDfDict
                                )
                        )
                
                    ## Start the thread
                    communicationThread.start()
                
                    ## Add the thread to the list of communication threads
                    actionThreads.append(communicationThread)

        ## For each thread in the list of communication threads
        for thread in actionThreads:
            
            ## Wait for the thread to finish
            thread.join()

    except Exception as Error:
        errorHandler.sendError(functionName, Error)


## For testing
if __name__ == "__main__":
     
    # craftAndSendRelevantEmail (p2_relevantEmail= "Associated Course Outcomes: Missing Required Data"
    #                            ,p2_row = {'Term': 'GF25'
    #                                       , 'Outcome Area': 'G-EDUC'
    #                                       , 'Course_sis_id': 'GF2025_EDUC7575_1L'
    #                                       , 'Course_name': 'LEGAL/FIN ISSUES IN EDUCATION GF2025_EDUC7575_1L'
    #                                       , 'Account_id': 'Graduate Education'
    #                                       , 'Number_of_students': 7
    #                                       , 'Outcome 1': 'G-EDUC_CAEP: 1.3_1.0'
    #                                       , 'Outcome 2': 'G-EDUC_CAEP: 1.4_1.0'
    #                                       , 'Instructor_#1_ID': 63232
    #                                       , 'Instructor_#1_name': 'John Doe'
    #                                       , 'Instructor_#1_email': 'brycezmiller@nnu.edu'
    #                                       , 'Instructor_#2_name': 'John Doe'
    #                                       , 'Instructor_#2_email': 'brycezmiller@nnu.edu'
    #                                       },
    #                             p3_inputTerm="GF25")
    
    ## Get an input term and start the term outcome email function
    termDetermineAndPerformRelevantActions (
        p1_inputTerm = input("Enter the desired term in four character format (FA20, SU20, SP20): ")
        , p1_targetDesignator = input("Enter the desired target designator (GE, I-EDUC, U-ENGR): ")
        )

    input("Press enter to exit")

## ===========================================================================
## FILE: ActionModules\Delete_Listed_Courses.py
## ===========================================================================


import traceback, os, sys, logging, csv, threading, time, pandas as pd
from datetime import datetime

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Delete_Listed_Courses"

scriptPurpose = r"""
This script reads a CSV file containing Canvas course IDs and makes API calls to delete each course.
"""
externalRequirements = r"""
To function properly, this script requires a valid access header and URL, and a CSV file named "courses_to_delete.csv" located in the Canvas Resources directory.
"""

## Date Variables
currentDateTime = datetime.now()
currentMonth = currentDateTime.month
currentYear = currentDateTime.year

## Relative Path (this changes depending on the working directory of the main script)
PFRelativePath = r".\\"

## If the Canvas directory is not in the folder the relative path points to
## find the Canvas directory and set the relative path to its parent folder
while "Scripts TLC" not in os.listdir(PFRelativePath):
    PFRelativePath = f"..\\{PFRelativePath}"

## Change the relative path to an absolute path
absolutePath = f"{os.path.abspath(PFRelativePath)}\\"

## Local Path Variables
baseLogPath = f"{absolutePath}Logs\\{scriptName}\\"
baseLocalInputPath = f"{absolutePath}Canvas Resources\\"
configPath = f"{absolutePath}Configs TLC\\"

## If the base log path doesn't already exist, create it
if not os.path.exists(baseLogPath):
    os.makedirs(baseLogPath, mode=0o777, exist_ok=False)

## Add Input Modules to the sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ResourceModules")
sys.path.append(f"{absolutePath}Scripts TLC\\ActionModules")

## Import local modules
from Error_Email_API import errorEmailApi  ## Import errorEmailApi
from Make_Api_Call import makeApiCall  ## Import makeApiCall

## Canvas Instance Url
coreCanvasApiUrl = None
## Open the Core_Canvas_Url.txt from the config path
with open(f"{configPath}Core_Canvas_Url.txt", "r") as file:
    coreCanvasApiUrl = file.readlines()[0]

## If the script is run as main the folder with the access token is in the parent directory
canvasAccessToken = ""

## Open and retrieve the Canvas Access Token
with open(f"{configPath}Canvas_Access_Token.txt", "r") as file:
    canvasAccessToken = file.readlines()[0]

## Log configurations
logger = logging.getLogger(__name__)
rootFormat = ("%(asctime)s %(levelname)s %(message)s")
FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
logging.basicConfig(format=rootFormat, filemode="a", level=logging.INFO)

## Info Log Handler
infoLogFile = f"{baseLogPath}\\Info Log.txt"
logInfo = logging.FileHandler(infoLogFile, mode='a')
logInfo.setLevel(logging.INFO)
logInfo.setFormatter(FORMAT)
localSetup.logger.addHandler(logInfo)

## Warning Log handler
warningLogFile = f"{baseLogPath}\\Warning Log.txt"
logWarning = logging.FileHandler(warningLogFile, mode='a')
logWarning.setLevel(logging.WARNING)
logWarning.setFormatter(FORMAT)
localSetup.logger.addHandler(logWarning)

## Error Log handler
errorLogFile = f"{baseLogPath}\\Error Log.txt"
logError = logging.FileHandler(errorLogFile, mode='a')
logError.setLevel(logging.ERROR)
logError.setFormatter(FORMAT)
localSetup.logger.addHandler(logError)

## Setup the error handler
## an error email the first time the function triggers an error
errorHandler = errorEmailApi(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function handles function errors
def errorHandler(p1_ErrorLocation, p1_ErrorInfo, sendOnce=True):
    functionName = "## errorHandler.sendError"
    localSetup.logger.error(f"\nA script error occurred while running {p1_ErrorLocation}. Error: {str(p1_ErrorInfo)}")

    ## If the function with the error has not already been processed send an email alert
    if p1_ErrorLocation not in setOfFunctionsWithErrors:
        errorEmailApi.sendEmailError(p2_ScriptName=scriptName, p2_ScriptPurpose=scriptPurpose,
                                     p2_ExternalRequirements=externalRequirements,
                                     p2_ErrorLocation=p1_ErrorLocation, p2_ErrorInfo=p1_ErrorInfo)
        setOfFunctionsWithErrors.add(p1_ErrorLocation)
        localSetup.logger.error(f"\nError Email Sent")
    else:
        localSetup.logger.error(f"\nError email already sent")

## This function deletes a course given its Canvas course ID
def deleteCourse(p1_header, courseId):
    functionName = "deleteCourse"
    try:
        delete_url = f"{coreCanvasApiUrl}courses/{courseId}"
        payload = {"event": "delete"}
        response = makeApiCall(localSetup, 
            p1_header=p1_header
            , p1_apiUrl=delete_url
            , p1_payload=payload
            , p1_apiCallType="delete"
            )

        if response.status_code == 200:
            localSetup.logger.info(f"Successfully deleted course with ID: {courseId}")
        else:
            localSetup.logger.warning(f"Failed to delete course with ID: {courseId}. Status code: {response.status_code}")

    except Exception as Error:
        except(functionName, Error)

## This function reads the CSV file and deletes the listed courses
def deleteListedCourses():
    functionName = "deleteListedCourses"
    try:
        targetCoursesCsvFilePath = f"{baseLocalInputPath}Target_Canvas_Course_Ids.csv"
        header = {'Authorization': f"Bearer {canvasAccessToken}"}

        ## Define the necessary thread list
        ongoingDeleteThreads = []

        ## Read the CSV file using pandas
        rawTargetCoursesDf = pd.read_csv(targetCoursesCsvFilePath)

        ## Retain only rows that have a value in canvas_course_id
        targetCoursesDf = rawTargetCoursesDf[rawTargetCoursesDf["canvas_course_id"].notna()]

        ## Iterate over each row in the DataFrame
        for index, row in targetCoursesDf.iterrows():

            ## Get the course id from the row
            courseId = str(row["canvas_course_id"]).replace('.0', '')

            ## Create a thread to set the term for the course
            setTermThread = threading.Thread(target=deleteCourse, args=(header, courseId))

            ## Start the thread
            setTermThread.start()

            ## Add the thread to the ongoing set term threads list
            ongoingDeleteThreads.append(setTermThread)

            ## Sleep for a short time to avoid overloading the server
            time.sleep(0.1)

    except Exception as Error:
        except(functionName, Error)

if __name__ == "__main__":
    ## Set working directory
    os.chdir(os.path.dirname(__file__))

    ## Delete the listed courses
    deleteListedCourses()

    input("Press enter to exit")

## ===========================================================================
## FILE: ActionModules\Enroll_GPS_Students_In_Grad_Hub.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import necessary modules
import os, sys, pandas as pd, threading, time
from datetime import datetime, date

## Import necessary functions from local modules
## Add Script repository to syspath
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

## New resource modules
try:
    from Local_Setup import LocalSetup
    from TLC_Common import makeApiCall, isFileRecent
    from Canvas_Report import CanvasReport
    from Error_Email import errorEmail
except ImportError:
    from ResourceModules.Local_Setup import LocalSetup
    from ResourceModules.TLC_Common import makeApiCall, isFileRecent
    from ResourceModules.Canvas_Report import CanvasReport
    from ResourceModules.Error_Email import errorEmail

## Create the localsetup variable
localSetup = LocalSetup(datetime.now(), __file__)  ## sets cwd, paths, logs, date parts

## Import configs
from Common_Configs import coreCanvasApiUrl, canvasAccessToken, gradTermsWordsToCodesDict

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
This script reads a CSV file containing Canvas enrollment IDs and changes the role for each enrollment using the Canvas API.
"""
externalRequirements = r"""
To function properly, this script requires a valid access header and URL, and a CSV file named "Target_Canvas_Enrollment_Ids.csv" located in the Canvas Resources directory.
"""

## Setup the error handler
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function deletes an enrollment given its Canvas enrollment ID
def deleteEnrollment(p3_courseId, p1_enrollmentId):
    functionName = "deleteEnrollment"
    try:

        ## Define the API URL for deleting the enrollment
        ##deleteEnrollmentUrl = f"{coreCanvasApiUrl}courses/{p3_courseId}/enrollments/{p1_enrollmentId}"
        deleteEnrollmentUrl = f"{coreCanvasApiUrl}courses/{p3_courseId}/enrollments/{p1_enrollmentId}"

        ## Define the API URL for deleting the enrollment
        response = makeApiCall(localSetup, p1_apiUrl=deleteEnrollmentUrl, p1_apiCallType="delete")

        ## Make the API call to delete the enrollment
        if response.status_code == 200:
            localSetup.logger.info(f"Successfully deleted enrollment with ID: {p1_enrollmentId}")
        else:
            localSetup.logger.warning(f"Failed to delete enrollment with ID: {p1_enrollmentId}. Status code: {response.status_code}")

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This function enrolls a user with a new role given the Canvas user ID, course ID, role ID, and base role type
def reEnrollUser(p1_userId, p2_courseId, p3_roleId, p4_baseRoleType):
    functionName = "reEnrollUser"
    try:

        ## Define the API URL for enrolling the user
        reEnrollUrl = f"{coreCanvasApiUrl}courses/{p2_courseId}/enrollments"

        ## Define the API URL for enrolling the user
        payload = {"enrollment[user_id]": p1_userId
                   , "enrollment[type]": p4_baseRoleType
                   , "enrollment[role_id]": p3_roleId
                   , "enrollment[enrollment_state]": "active"
                   }

        ## Define the payload
        response = makeApiCall(localSetup, p1_apiUrl=reEnrollUrl, p1_payload=payload, p1_apiCallType="post")

        ## Make the API call to enroll the user
        if response.status_code == 200:
            localSetup.logger.info(f"Successfully enrolled user with ID: {p1_userId} in course with ID: {p2_courseId} with role ID: {p3_roleId}")
        else:
            localSetup.logger.warning(f"Failed to enroll user with ID: {p1_userId} in course with ID: {p2_courseId}. Status code: {response.status_code}")

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This function deletes the enrollment and enrolls the user with the new role
def deleteAndReenroll(p1_enrollmentId, p1_userId, p2_courseId, p3_roleId, p4_baseRoleType):
    reEnrollUser(p1_userId, p2_courseId, p3_roleId, p4_baseRoleType)
    deleteEnrollment(p2_courseId, p1_enrollmentId)

## This function reads the CSV file, deletes the enrollment, and enrolls the user with the new role
def enrollGPSStudentsInGrad_Hub(inputTerm):

    functionName = "enrollGPSStudentsInGrad_Hub"

    try:

        ## Get the term prefix
        termPrefix = inputTerm[:2]
        termYear = int(str(localSetup.dateDict['century']) + inputTerm[2:4])
        
        ## Define the grad term
        termName = localSetup._determineTermName(termPrefix)

        ## Get the grad term
        gradTermPrefix = gradTermsWordsToCodesDict[termName]
        gradTerm = gradTermPrefix + str(termYear)[2:4]

        ## Read the input term's GPS student csv into a df
        GPSStudentsDf = CanvasReport.getGpsStudentsDf(localSetup, gradTerm)

        ## Drop student rows without user_ids
        GPSStudentsDf = GPSStudentsDf.dropna(subset=['user_id'])

        ## Set studentRow['user_id'] to int
        GPSStudentsDf['user_id'] = GPSStudentsDf['user_id'].astype(int)

        ## Retrieve (and update if neccessary) the term relavent canvas courses file path
        ##Grad_HubCourseTermLocationDf = pd.read_csv(termGetCourses("All"))
        Grad_HubCourseTermLocationDf = CanvasReport.getCoursesDf(localSetup, "Default Term")

        ## Find the "canvas_course_id" for the Graduate & Professional Student Hub course by looking for the target Graduate & Professional Student Hub sis id in the course short name
        targetOrientationCanvasCourseId = Grad_HubCourseTermLocationDf.loc[Grad_HubCourseTermLocationDf['short_name'] == "Graduate & Professional Student Hub", 'canvas_course_id'].values[0]
         
        ## Define the Graduate & Professional Student Hub course's base api url
        Grad_HubCourseCoreApiUrl = f"{coreCanvasApiUrl}courses/{targetOrientationCanvasCourseId}"

        ## Define the Graduate & Professional Student Hub courses users api url
        Grad_HubCourseUsersApiUrl = f"{Grad_HubCourseCoreApiUrl}/users"

        ## Define the payload to get the course's students
        Grad_HubCourseUserPayload = {"enrollment_type[]":["student"], "include[]": "enrollments", "per_page": 100}

        ## Make the API call to get the course's details
        Grad_HubCourseEnrollmentObjectOrObjectList = makeApiCall(localSetup, p1_apiUrl = Grad_HubCourseUsersApiUrl, p1_payload = Grad_HubCourseUserPayload)

        ## Make a list to hold the target orientation students
        targetCourseEnrolledStudentsDict = {}
        
        ## Make List to hold all threads
        actionThreads = []

        ## If the Grad_HubCourseEnrollmentObjectOrObjectList is a list
        if isinstance(Grad_HubCourseEnrollmentObjectOrObjectList, list):

            ## For each json api object in the course's enrollment objects list
            for enrollmentsObject in Grad_HubCourseEnrollmentObjectOrObjectList:
                
                ## For each student within the text (dict) of the object
                for studentObject in enrollmentsObject.json():

                    ## Add the student's sis_user_id and the target student's Graduate & Professional Student Hub enrollment id to the targetCourseEnrolledStudentsDict
                    targetCourseEnrolledStudentsDict[studentObject["sis_user_id"]] = studentObject['enrollments'][0]["id"]
        
        ## If the Grad_HubCourseEnrollmentObjectOrObjectList is not a list, There was just one object returned
        else:
            
             ## For each student within the text (dict) of the object
                for studentObject in Grad_HubCourseEnrollmentObjectOrObjectList.json():

                    ## Define a variable to hold the student's enrollment id
                    targetStudentsGrad_HubEnrollmentId = None

                    ## For each enrollment in the student object's enrollments list
                    for enrollment in studentObject["enrollments"]:

                        ## If the course id of the enrollment matches the target orientation course id
                        if enrollment["course_id"] == targetOrientationCanvasCourseId:

                            ## Set the target student's Graduate & Professional Student Hub enrollment id to the enrollment's id
                            targetStudentsGrad_HubEnrollmentId = enrollment["id"]

                    ## Add the student's sis_user_id and the target student's Graduate & Professional Student Hub enrollment id to the targetCourseEnrolledStudentsDict
                    targetCourseEnrolledStudentsDict[studentObject["sis_user_id"]] = targetStudentsGrad_HubEnrollmentId

        ## For each student in the targetCourseEnrolledStudentsDict
        for studentId, enrollmentID in targetCourseEnrolledStudentsDict.items():

            ## If the student is not in the GPSStudentsDf
            if studentId.isdigit() and int(studentId) not in GPSStudentsDf['user_id'].values:
                
                ## Create the deletion api url by adding the enrollment id to the end of the stuCourseEnrollmentApiUrl
                stuCourseEnrollmentDeletionApiUrl = f"{coreCanvasApiUrl}courses/{targetOrientationCanvasCourseId}/enrollments/{enrollmentID}"

                ## Defeine the parameter to delete the enrollment
                stuCourseEnrollmentDeleteParams = {
                    "task": "delete"
                }

                ## Make a delete enrollment api call to remove the reactivated enrollment
                enrollmentDeletionApiOjbect = makeApiCall(localSetup, p1_apiUrl = stuCourseEnrollmentDeletionApiUrl, p1_payload = stuCourseEnrollmentDeleteParams, p1_apiCallType = "delete")

                ## Define a deletion attempt variable
                enrollmentDeletionAttempt = 1

                ## If the enrollment deletion api call was not successful
                while enrollmentDeletionApiOjbect.status_code != 200 and enrollmentDeletionAttempt != 5:

                    ## Sleep 3 seconds
                    time.sleep(3)

                    ## Log a warning that the enrollment deletion failed
                    localSetup.logger.warning(f"Enrollment deletion failed in the Graduate & Professional Student Hub course for student {studentId}")

                    ## try to remove the reactiviated enrollment again
                    enrollmentDeletionApiOjbect = makeApiCall(localSetup, p1_apiUrl = stuCourseEnrollmentDeletionApiUrl, p1_payload = stuCourseEnrollmentDeleteParams, p1_apiCallType = "delete")

                    ## Increment the attempt number
                    enrollmentDeletionAttempt += 1

        ## Define the Graduate & Professional Student Hub courses's enrollment API URL
        Grad_HubCourseUsersApiUrl = f"{Grad_HubCourseCoreApiUrl}/enrollments"

        ## For each student in the GPSStudentsDf
        for index, studentRow in GPSStudentsDf.iterrows():

            ## Define the payload to enroll the student in the Graduate & Professional Student Hub course
            reEnrollPayload = {
                "enrollment[user_id]": studentRow['canvas_user_id'],
                "enrollment[type]": "StudentEnrollment",
                "enrollment[enrollment_state]": "active"
            }

            ## If the student is not already enrolled in the Graduate & Professional Student Hub course
            if str(studentRow['user_id']) not in targetCourseEnrolledStudentsDict.keys():

                ## Make a post api call to enroll the student in the Graduate & Professional Student Hub course
                reEnrollApiObject = makeApiCall(localSetup, p1_apiUrl=Grad_HubCourseUsersApiUrl, p1_payload=reEnrollPayload, p1_apiCallType="post")

                ## If the enrollment was successful
                if reEnrollApiObject.status_code == 200:
                    localSetup.logger.info(f"Successfully enrolled student {studentRow['user_id']} in the Graduate & Professional Student Hub course")
                else:
                    localSetup.logger.warning(f"Failed to enroll student {studentRow['user_id']} in the Graduate & Professional Student Hub course. Status code: {reEnrollApiObject.status_code}")

        

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":
    ## Set working directory
    os.chdir(os.path.dirname(__file__))
    
    ## Change the role for the listed enrollments
    enrollGPSStudentsInGrad_Hub(inputTerm = input("Enter the desired term in \
four character format (FA20, SU20, SP20): "))

    ## Wait for user input to exit
    input("Press enter to exit")


## ===========================================================================
## FILE: ActionModules\Enroll_TUG_Students_In_SGA.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import necessary modules
import os, sys, threading, time, pandas as pd
from datetime import datetime

## Import necessary functions from local modules
## Add Script repository to syspath
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

## New resource modules
try:
    from Local_Setup import LocalSetup
    from TLC_Common import makeApiCall, isFileRecent
    from Canvas_Report import CanvasReport
    from Error_Email import errorEmail
except ImportError:
    from ResourceModules.Local_Setup import LocalSetup
    from ResourceModules.TLC_Common import makeApiCall, isFileRecent
    from ResourceModules.Canvas_Report import CanvasReport
    from ResourceModules.Error_Email import errorEmail

## Create the localsetup variable
localSetup = LocalSetup(datetime.now(), __file__)  ## sets cwd, paths, logs, date parts

## Import configs
from Common_Configs import coreCanvasApiUrl, canvasAccessToken, gradTermsWordsToCodesDict

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
This script reads a CSV file containing Canvas enrollment IDs and changes the role for each enrollment using the Canvas API.
"""
externalRequirements = r"""
To function properly, this script requires a valid URL, and a CSV file named "Target_Canvas_Enrollment_Ids.csv" located in the Canvas Resources directory.
"""

## Setup the error handler
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function deletes an enrollment given its Canvas enrollment ID
def deleteEnrollment(p3_courseId, p1_enrollmentId):
    functionName = "deleteEnrollment"
    try:

        ## Define the API URL for deleting the enrollment
        deleteEnrollmentUrl = f"{coreCanvasApiUrl}courses/{p3_courseId}/enrollments/{p1_enrollmentId}"

        ## Define the API URL for deleting the enrollment
        response = makeApiCall(localSetup, p1_apiUrl=deleteEnrollmentUrl, p1_apiCallType="delete")

        ## Make the API call to delete the enrollment
        if response.status_code == 200:
            localSetup.logger.info(f"Successfully deleted enrollment with ID: {p1_enrollmentId}")
        else:
            localSetup.logger.warning(f"Failed to delete enrollment with ID: {p1_enrollmentId}. Status code: {response.status_code}")

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This function enrolls a user with a new role given the Canvas user ID, course ID, role ID, and base role type
def reEnrollUser(p1_userId, p2_courseId, p3_roleId, p4_baseRoleType):
    functionName = "reEnrollUser"
    try:

        ## Define the API URL for enrolling the user
        reEnrollUrl = f"{coreCanvasApiUrl}courses/{p2_courseId}/enrollments"

        ## Define the API URL for enrolling the user
        payload = {"enrollment[user_id]": p1_userId
                   , "enrollment[type]": p4_baseRoleType
                   , "enrollment[role_id]": p3_roleId
                   , "enrollment[enrollment_state]": "active"
                   }

        ## Define the payload
        response = makeApiCall(localSetup, p1_apiUrl=reEnrollUrl, p1_payload=payload, p1_apiCallType="post")

        ## Make the API call to enroll the user
        if response.status_code == 200:
            localSetup.logger.info(f"Successfully enrolled user with ID: {p1_userId} in course with ID: {p2_courseId} with role ID: {p3_roleId}")
        else:
            localSetup.logger.warning(f"Failed to enroll user with ID: {p1_userId} in course with ID: {p2_courseId}. Status code: {response.status_code}")

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This function deletes the enrollment and enrolls the user with the new role
def deleteAndReenroll(p1_enrollmentId, p1_userId, p2_courseId, p3_roleId, p4_baseRoleType):
    reEnrollUser(p1_userId, p2_courseId, p3_roleId, p4_baseRoleType)
    deleteEnrollment(p2_courseId, p1_enrollmentId)

## This function reads the CSV file, deletes the enrollment, and enrolls the user with the new role
def enrollTugStudentsInSga(inputTerm):

    functionName = "enrollTugStudentsInSga"

    try:

        ## Determine and save the term's school year
        termName = localSetup._determineTermName(inputTerm[:2])
        startYear, endYear = localSetup._getSchoolYearRange(termName, int(str(localSetup.dateDict["century"]) + inputTerm[2:4]))
        termYear = localSetup._getYearForTerm(termName, startYear, endYear)

        
        ## Get TUG students from Canvas
        tugStudentsDf = CanvasReport.getTugStudentsDf(localSetup, inputTerm)

        ## Get SGA course info
        coursesDf = CanvasReport.getCoursesDf(localSetup, "Default Term")
        targetOrientationCanvasCourseId = coursesDf.loc[coursesDf['short_name'] == "SGA", 'canvas_course_id'].values[0]
         
        ## Define the SGA course's base api url
        SGACourseCoreApiUrl = f"{coreCanvasApiUrl}courses/{targetOrientationCanvasCourseId}"

        ## Define the SGA courses users api url
        SGACourseUsersApiUrl = f"{SGACourseCoreApiUrl}/users"

        ## Define the payload to get the course's students
        SGACourseUserPayload = {"enrollment_type[]":["student"], "include[]": "enrollments", "per_page": 100}

        ## Make the API call to get the course's details
        SGACourseEnrollmentObjectOrObjectList = makeApiCall(localSetup, p1_apiUrl = SGACourseUsersApiUrl, p1_payload = SGACourseUserPayload)

        ## Make a list to hold the target orientation students
        targetCourseEnrolledStudentsDict = {}

        ## If the SGACourseEnrollmentObjectOrObjectList is a list
        if isinstance(SGACourseEnrollmentObjectOrObjectList, list):

            ## For each json api object in the course's enrollment objects list
            for enrollmentsObject in SGACourseEnrollmentObjectOrObjectList:
                
                ## For each student within the text (dict) of the object
                for studentObject in enrollmentsObject.json():

                    ## Add the student's sis_user_id and the target student's SGA enrollment id to the targetCourseEnrolledStudentsDict
                    targetCourseEnrolledStudentsDict[studentObject["sis_user_id"]] = studentObject['enrollments'][0]["id"]
        
        ## If the SGACourseEnrollmentObjectOrObjectList is not a list, There was just one object returned
        else:
            
             ## For each student within the text (dict) of the object
                for studentObject in SGACourseEnrollmentObjectOrObjectList.json():

                    ## Define a variable to hold the student's enrollment id
                    targetStudentsSgaEnrollmentId = None

                    ## For each enrollment in the student object's enrollments list
                    for enrollment in studentObject["enrollments"]:

                        ## If the course id of the enrollment matches the target orientation course id
                        if enrollment["course_id"] == targetOrientationCanvasCourseId:

                            ## Set the target student's SGA enrollment id to the enrollment's id
                            targetStudentsSgaEnrollmentId = enrollment["id"]

                    ## Add the student's sis_user_id and the target student's SGA enrollment id to the targetCourseEnrolledStudentsDict
                    targetCourseEnrolledStudentsDict[studentObject["sis_user_id"]] = targetStudentsSgaEnrollmentId

        ## For each student in the targetCourseEnrolledStudentsDict
        for studentId, enrollmentID in targetCourseEnrolledStudentsDict.items():

            ## If the student is not in the tugStudentsDf
            if studentId.isdigit() and str(studentId) not in tugStudentsDf['user_id'].astype(str).values:
                
                ## Create the deletion api url by adding the enrollment id to the end of the stuCourseEnrollmentApiUrl
                stuCourseEnrollmentDeletionApiUrl = f"{coreCanvasApiUrl}courses/{targetOrientationCanvasCourseId}/enrollments/{enrollmentID}"

                ## Defeine the parameter to delete the enrollment
                stuCourseEnrollmentDeleteParams = {
                    "task": "delete"
                }

                ## Make a delete enrollment api call to remove the reactivated enrollment
                enrollmentDeletionApiOjbect = makeApiCall(localSetup, p1_apiUrl = stuCourseEnrollmentDeletionApiUrl, p1_payload = stuCourseEnrollmentDeleteParams, p1_apiCallType = "delete")

                ## Define a deletion attempt variable
                enrollmentDeletionAttempt = 1

                ## If the enrollment deletion api call was not successful
                while enrollmentDeletionApiOjbect.status_code != 200 and enrollmentDeletionAttempt != 5:

                    ## Sleep 3 seconds
                    time.sleep(3)

                    ## Log a warning that the enrollment deletion failed
                    localSetup.logger.warning(f"Enrollment deletion failed in the SGA course for student {studentId}")

                    ## try to remove the reactiviated enrollment again
                    enrollmentDeletionApiOjbect = makeApiCall(localSetup, p1_apiUrl = stuCourseEnrollmentDeletionApiUrl, p1_payload = stuCourseEnrollmentDeleteParams, p1_apiCallType = "delete")

                    ## Increment the attempt number
                    enrollmentDeletionAttempt += 1

        ## Define the SGA courses's enrollment API URL
        SGACourseUsersApiUrl = f"{SGACourseCoreApiUrl}/enrollments"

        ## For each student in the tugStudentsDf
        for index, studentRow in tugStudentsDf.iterrows():

            ## Define the payload to enroll the student in the SGA course
            reEnrollPayload = {
                "enrollment[user_id]": studentRow['canvas_user_id'],
                "enrollment[type]": "StudentEnrollment",
                "enrollment[enrollment_state]": "active"
            }

            ## If the student is not already enrolled in the SGA course
            if str(studentRow['user_id']) not in targetCourseEnrolledStudentsDict.keys():

                ## Make a post api call to enroll the student in the SGA course
                reEnrollApiObject = makeApiCall(localSetup, p1_apiUrl=SGACourseUsersApiUrl, p1_payload=reEnrollPayload, p1_apiCallType="post")

                ## If the enrollment was successful
                if reEnrollApiObject.status_code == 200:
                    localSetup.logger.info(f"Successfully enrolled student {studentRow['user_id']} in the SGA course")
                else:
                    localSetup.logger.warning(f"Failed to enroll student {studentRow['user_id']} in the SGA course. Status code: {reEnrollApiObject.status_code}")

        

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":
    ## Set working directory
    os.chdir(os.path.dirname(__file__))
    
    ## Change the role for the listed enrollments
    enrollTugStudentsInSga(inputTerm = input("Enter the desired term in \
four character format (FA20, SU20, SP20): "))

    ## Wait for user input to exit
    input("Press enter to exit")


## ===========================================================================
## FILE: ActionModules\Send_Catalog_To_Simple_Syllabus.py
## ===========================================================================

# =============================================================================
# FILE: ActionModules/Send_Catalog_To_Simple_Syllabus.py
# =============================================================================
# Author: Bryce Miller - brycezmiller@nnu.edu
# Last Updated by: Bryce Miller
#
# Downloads the GPS (Graduate) and TUG (Undergraduate) course catalogs from the
# CleanCatalog production (current year) and staging (next year) report URLs,
# builds a combined course list triplicated across all three terms
# (Fall / Spring / Summer) for both the current and next school year,
# resolves Parent Organization from Canvas sub-accounts using Smart Eval
# Organizations, merges requisite columns per Simple Syllabus requirements,
# and uploads the resulting CSVs to Simple Syllabus via SFTP.
#
# Graduate routing : course numbers >= 5000
# Undergraduate routing : course numbers < 5000
#
# Output term label conventions:
#   Graduate Fall    "GRADUATE FALL SEMESTER {year}"
#   Graduate Spring  "GRADUATE SPRING SEMESTER {year}"
#   Graduate Summer  "GRADUATE SUMMER SESSION {year}"
#   Undergrad Fall    "UNDERGRADUATE FALL SEMESTER {year}"
#   Undergrad Spring  "UNDERGRADUATE SPRING SEMESTER {year}"
#   Undergrad Summer  "UNDERGRADUATE SUMMER SEMESTER {year}"
# =============================================================================

import os
import sys
import re
import time
import traceback
import difflib

import paramiko
import pandas as pd
from datetime import datetime

# Add Script repository to sys.path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

#  Script metadata 
scriptName = __file__.replace(".py", "")
scriptPurpose = r"""
Downloads the GPS (Graduate) and TUG (Undergraduate) course catalogs from the
CleanCatalog production (current year) and staging (next year) report URLs,
builds a combined course list triplicated across all three terms
(Fall / Spring / Summer) for both the current and next school year,
resolves Parent Organization from Canvas sub-accounts using Smart Eval
Organizations, merges requisite columns per Simple Syllabus requirements,
and uploads the resulting CSVs to Simple Syllabus via SFTP.

Graduate routing : course numbers >= 5000
Undergraduate routing : course numbers < 5000

Output term label conventions:
 Graduate Fall    "GRADUATE FALL SEMESTER {year}"
 Graduate Spring  "GRADUATE SPRING SEMESTER {year}"
 Graduate Summer  "GRADUATE SUMMER SESSION {year}"
 Undergrad Fall    "UNDERGRADUATE FALL SEMESTER {year}"
 Undergrad Spring  "UNDERGRADUATE SPRING SEMESTER {year}"
 Undergrad Summer  "UNDERGRADUATE SUMMER SEMESTER {year}"
"""
externalRequirements = r"""
To function properly this script requires:
 - Network access to the CleanCatalog production and staging GPS and TUG report URLs
 - A Simple Syllabus SSH private key stored at:
   <configPath>/Simple_Syllabus_Private_Key.txt
 - Valid Canvas API credentials defined in Common_Configs
 - Smart Eval Organizations CSV in the Config folder:
   <configPath>/Smart Eval Organizations.csv
"""

#  Imports from the existing TLC resource stack 
try:
    from Local_Setup import LocalSetup
    from TLC_Common import downloadFile, makeApiCall
    from Canvas_Report import CanvasReport
    from Error_Email import errorEmail
except ImportError:
    from ResourceModules.Local_Setup import LocalSetup
    from ResourceModules.TLC_Common import downloadFile, makeApiCall
    from ResourceModules.Canvas_Report import CanvasReport
    from ResourceModules.Error_Email import errorEmail

# Initialise LocalSetup and error handler
localSetup = LocalSetup(datetime.now(), __file__)
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

#  CleanCatalog production & staging report URLs 
# Production (current catalog)
PROD_GPS_CATALOG_URL = (
    "https://gpscatalog.nnu.edu/admin/reports/gps-course-report/download?page&_format=csv"
)
PROD_TUG_CATALOG_URL = (
    "https://catalog.nnu.edu/admin/reports/tug-course-report/download?page&_format=csv"
)

# Staging (next catalog)
STAGING_GPS_CATALOG_URL = (
    "https://test-nnu-grad.cleancatalog.io/admin/reports/gps-course-report"
)
STAGING_TUG_CATALOG_URL = (
    "https://test-nnu-catalog.cleancatalog.io/admin/reports/tug-course-report"
)

#  Simple Syllabus SFTP connection settings (per SFTP_Documentation PDF) 
SS_HOST = "files.simplesyllabus.com"
SS_PORT = 22
SS_USERNAME = "nnu"
SS_KEY_PATH = os.path.join(localSetup.configPath, "Simple_Syllabus_Private_Key.txt")
SS_REMOTE_DIR = "/imports"

#  Local output directory for generated CSVs 
OUTPUT_DIR = os.path.join(
    localSetup.getInternalResourcePaths("Simple_Syllabus"),
    "Catalog_Export"
)
os.makedirs(OUTPUT_DIR, exist_ok=True)

#  Term label templates keyed by (level, term) 
TERM_LABELS = {
    ("graduate", "Fall"):   "GRADUATE FALL SEMESTER {year}",
    ("graduate", "Spring"): "GRADUATE SPRING SEMESTER {year}",
    ("graduate", "Summer"): "GRADUATE SUMMER SESSION {year}",
    ("undergraduate", "Fall"):   "UNDERGRADUATE FALL SEMESTER {year}",
    ("undergraduate", "Spring"): "UNDERGRADUATE SPRING SEMESTER {year}",
    ("undergraduate", "Summer"): "UNDERGRADUATE SUMMER SEMESTER {year}",
}

# Fall belongs to the START year of the school year (FA25 = school year 2025-26)
# Spring and Summer belong to the END year (SP26, SU26 = school year 2025-26)
TERM_YEAR_SIDE = {
    "Fall": "start",   # use schoolYearStart
    "Spring": "end",   # use schoolYearStart + 1
    "Summer": "end",   # use schoolYearStart + 1
}

TERM_ORDER = ["Fall", "Spring", "Summer"]

#  Helpers 

def splitCourseCode(rawTitle: str):
    """
    Split a catalog Title such as 'ACCT6000' into ('ACCT', '6000').
    Returns (None, None) if the format is not recognised.
    """
    match = re.match(r"([A-Za-z]+)(\d+)", str(rawTitle).strip())
    if match:
        return match.group(1).upper(), match.group(2)
    return None, None


def combineFields(*fields):
    """
    Merge multiple text fields into one semicolon-delimited string.
    Blank, NaN, and duplicate values are discarded.
    """
    seen = set()
    parts = []
    for field in fields:
        if pd.notna(field):
            val = str(field).strip()
            if val and val.lower() != "nan" and val not in seen:
                seen.add(val)
                parts.append(val)
    return "; ".join(parts)


def _normalize_name_for_match(name: str) -> str:
    """
    Normalize org/account names for matching:
    - lowercase
    - collapse non-alphanumeric characters to spaces
    - strip extra whitespace
    """
    if not isinstance(name, str):
        return ""
    cleaned = re.sub(r"[^a-z0-9]+", " ", name.lower())
    return cleaned.strip()


def _load_smart_eval_orgs():
    """
    Load Smart Eval Organizations from the Config folder and
    build a normalized-name  actual-name lookup plus a list of
    all normalized names for fuzzy matching.
    """
    smart_eval_path = os.path.join(localSetup.configPath, "Smart Eval Organizations.csv")
    if not os.path.exists(smart_eval_path):
        localSetup.logger.warning(f"Smart Eval Organizations file not found: {smart_eval_path}")
        return {}, []

    se_df = pd.read_csv(smart_eval_path)
    name_to_actual = {}
    normalized_names = []

    for _, row in se_df.iterrows():
        raw_name = str(row.get("name", "")).strip()
        if not raw_name:
            continue
        norm = _normalize_name_for_match(raw_name)
        if norm:
            name_to_actual[norm] = raw_name
            normalized_names.append(norm)

    localSetup.logger.info(
        f"Loaded {len(name_to_actual)} Smart Eval organizations from {smart_eval_path}"
    )
    return name_to_actual, normalized_names


def _map_account_to_smarteval_org(account_id: str,
                                  accounts_by_id: dict,
                                  se_name_map: dict,
                                  se_normalized_names: list) -> str:
    """
    Starting at the given Canvas account_id, walk up the account hierarchy.
    For each account encountered:
      1) Try an exact normalized-name match to Smart Eval orgs
      2) If none, pick the 'closest' Smart Eval org via difflib.get_close_matches
    Return the Smart Eval org name if found, else ''.
    """
    visited = set()
    current_id = str(account_id).strip()

    while current_id and current_id not in visited:
        visited.add(current_id)
        account = accounts_by_id.get(current_id)
        if not account:
            break

        acc_name = str(account.get("name", "")).strip()
        norm_acc_name = _normalize_name_for_match(acc_name)
        if norm_acc_name:
            # 1) Exact normalized match
            if norm_acc_name in se_name_map:
                return se_name_map[norm_acc_name]

            # 2) Fuzzy / likely match
            candidates = difflib.get_close_matches(
                norm_acc_name, se_normalized_names, n=1, cutoff=0.8
            )
            if candidates:
                matched_norm = candidates[0]
                return se_name_map.get(matched_norm, "")

        # ascend in the hierarchy
        parent_id = str(account.get("parent_account_id", "")).strip()
        if not parent_id or parent_id == current_id:
            break
        current_id = parent_id

    return ""


def buildSubjectOrgMap():
    """
    Build (subject, courseNumber)  Parent Organization mapping
    using Canvas accounts + Smart Eval Organizations.

    Steps:
      1. Load Canvas courses & accounts via CanvasReport
      2. Load Smart Eval orgs from Config/Smart Eval Organizations.csv
      3. For each course, use its account_id and walk up the account tree
         until we find a Canvas account whose name matches (exactly or
         closely) a Smart Eval org name.
      4. Store the resolved Smart Eval org name as Parent Organization.
    """
    localSetup.logger.info("Building subjectParentOrg map via Canvas + Smart Eval...")

    allCoursesDf = CanvasReport.getCoursesDf(localSetup, "All")
    accountsDf = CanvasReport.getAccountsDf(localSetup)

    # Smart Eval orgs (normalized)
    se_name_map, se_normalized_names = _load_smart_eval_orgs()

    # --- Build account_id  {name, parent_account_id} lookup ---
    accounts_by_id = {}
    if accountsDf is not None and not accountsDf.empty:
        for _, row in accountsDf.iterrows():
            acct_id = str(row.get("canvas_account_id", "")).strip()
            if not acct_id:
                continue
            accounts_by_id[acct_id] = {
                "name": str(row.get("name", "")).strip(),
                "parent_account_id": str(row.get("parent_account_id", "")).strip(),
            }

    # --- Build (subject, courseNum)  Smart Eval org name from course_id ---
    # Sample course_id values: FA2025_ACCT6000_01, SP2026_BIOL2210_1L
    courseIdPattern = re.compile(r"^[A-Z]{2}\d{2}_([A-Za-z]+)(\d+)_", re.IGNORECASE)
    subjectCourseToOrg = {}

    if allCoursesDf is not None and not allCoursesDf.empty:
        for _, row in allCoursesDf.iterrows():
            courseId = str(row.get("course_id", "")).strip()
            accountId = str(row.get("account_id", "")).strip()
            m = courseIdPattern.match(courseId)
            if not m or not accountId:
                continue

            key = (m.group(1).upper(), m.group(2))

            # First match wins; most schools have a consistent sub-account per course
            if key in subjectCourseToOrg:
                continue

            parent_org = _map_account_to_smarteval_org(
                accountId, accounts_by_id, se_name_map, se_normalized_names
            )

            if parent_org:
                subjectCourseToOrg[key] = parent_org

    localSetup.logger.info(
        f"SubjectParentOrg map complete  {len(subjectCourseToOrg)} "
        f"unique (subject, courseNumber) entries mapped."
    )
    return subjectCourseToOrg


def downloadCatalog(url: str, localPath: str) -> pd.DataFrame:
    """Download a CleanCatalog report CSV via downloadFile and return as DataFrame."""
    localSetup.logger.info(f"Downloading catalog: {url}  {localPath}")
    downloadFile(localSetup, url, localPath, "w")
    df = pd.read_csv(localPath)
    localSetup.logger.info(f"Catalog downloaded  {len(df)} rows, columns: {list(df.columns)}")
    return df


def expandSlashTitles(catalogDf: pd.DataFrame) -> pd.DataFrame:
    """
    Some catalog rows carry a slash-delimited Title such as 'MUSC2250/MUSC2254'.
    This function duplicates those rows  one per code  so that downstream
    logic sees each course code as its own independent row.
    """
    expanded = []
    for _, row in catalogDf.iterrows():
        rawTitle = str(row.get("Title", "")).strip()
        if "/" in rawTitle:
            codes = [c.strip() for c in rawTitle.split("/") if c.strip()]
            for code in codes:
                newRow = row.copy()
                newRow["Title"] = code
                expanded.append(newRow)
            localSetup.logger.info(
                f"Expanded slash title '{rawTitle}' into {len(codes)} rows: {codes}"
            )
        else:
            expanded.append(row)
    return pd.DataFrame(expanded).reset_index(drop=True)


def buildOutputRows(catalogDf: pd.DataFrame,
                    isGraduate: bool,
                    schoolYearStart: int,
                    subjectOrgMap: dict) -> list:
    """
    For every course in catalogDf that belongs to the requested level (grad / undg),
    produce three rows  one per term (Fall / Spring / Summer)  for the given
    school year.

    Slash-delimited titles (e.g. 'MUSC2250/MUSC2254') are expanded into
    individual rows before processing so each code gets its own entries.

    Column merging rules
    
    Output Prerequisites  Prerequisites + Prerequisite Courses
    Output Corequisites  Corequisites + Corequisite Courses + Concurrent + Concurrent Requisite
    """
    # Expand any slash-delimited titles before processing
    catalogDf = expandSlashTitles(catalogDf)

    level = "graduate" if isGraduate else "undergraduate"
    rows = []

    for _, catalogRow in catalogDf.iterrows():
        #  Parse course code 
        subject, courseNum = splitCourseCode(catalogRow.get("Title", ""))
        if subject is None:
            localSetup.logger.warning(
                f"Could not parse course code from Title='{catalogRow.get('Title')}'  skipping."
            )
            continue

        #  Route by course level 
        try:
            courseIsGrad = int(courseNum) >= 5000
        except ValueError:
            localSetup.logger.warning(
                f"Non-numeric course number '{courseNum}' from Title='{catalogRow.get('Title')}'  skipping."
            )
            continue

        if courseIsGrad != isGraduate:
            continue  # This row belongs to the other output file

        #  Parent Organisation from Canvas+SmartEval map 
        parentOrg = subjectOrgMap.get((subject, courseNum), "")

        #  Merge requisite columns (new rules) 
        #   Prerequisites  Prerequisites + Prerequisite Courses
        prereqs = combineFields(
            catalogRow.get("Prerequisites", ""),
            catalogRow.get("Prerequisite Courses", ""),
        )
        #   Corequisites  Corequisites + Corequisite Courses + Concurrent + Concurrent Requisite
        coreqs = combineFields(
            catalogRow.get("Corequisites", ""),
            catalogRow.get("Corequisite Courses", ""),
            catalogRow.get("Concurrent", ""),
            catalogRow.get("Concurrent Requisite", ""),
        )

        #  Emit one row per term in this school year 
        for termName in TERM_ORDER:
            calYear = (
                schoolYearStart
                if TERM_YEAR_SIDE[termName] == "start"
                else schoolYearStart + 1
            )
            termLabel = TERM_LABELS[(level, termName)].format(year=calYear)

            rows.append({
                "Term": termLabel,
                "Subject": subject,
                "Course Number": courseNum,
                "Title": str(catalogRow.get("Name", "")).strip(),
                "Parent Organization": parentOrg,
                "Class Program": str(catalogRow.get("Class Program", "")).strip(),
                "Description": str(catalogRow.get("Description", "")).strip(),
                "Credits": catalogRow.get("Credits", ""),
                "Prerequisites": prereqs,
                "Corequisites": coreqs,
            })

    return rows


def uploadToSimpleSyllabus(localFilePath: str, remoteFileName: str):
    """
    Upload a single CSV to the Simple Syllabus SFTP server.
    Uses SSH key authentication following the same pattern as the existing
    Slate SFTP upload (key_filename from configPath).
    Retries up to 3 times with a 5-second pause between attempts.
    """
    functionName = "uploadToSimpleSyllabus"
    attempt = 0    # noqa: F841 (kept for clarity)
    maxRetries = 3
    connected = False

    ssh_client = paramiko.SSHClient()
    ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

    while not connected and attempt < maxRetries:
        try:
            localSetup.logger.info(
                f"Connecting to Simple Syllabus SFTP  attempt {attempt + 1} "
            )
            ssh_client.connect(
                hostname=SS_HOST,
                port=SS_PORT,
                username=SS_USERNAME,
                key_filename=SS_KEY_PATH,
            )
            connected = True
            localSetup.logger.info("SFTP connection established.")
        except Exception as err:
            attempt += 1
            localSetup.logger.error(f"SFTP connect attempt {attempt} failed: {err}")
            if attempt < maxRetries:
                localSetup.logger.info("Retrying in 5 seconds ")
                time.sleep(5)
            else:
                localSetup.logger.error(
                    f"Could not connect to Simple Syllabus SFTP after {maxRetries} attempts."
                )
                raise

    sftp = ssh_client.open_sftp()
    remotePath = f"{SS_REMOTE_DIR}/{remoteFileName}"

    try:
        localSetup.logger.info(f"Uploading {localFilePath}  {remotePath}")
        sftp.put(localFilePath, remotePath)
        localSetup.logger.info(f"Upload complete: {remoteFileName}")
    finally:
        sftp.close()
        ssh_client.close()


#  Main 

def sendCatalogToSimpleSyllabus():
    functionName = "sendCatalogToSimpleSyllabus"
    try:
        #  Determine current and next school year 
        # LocalSetup encodes NNU's school-year logic:
        # Fall (Aug-Dec)  "current-next" (startYear = that calendar year)
        # Spring/Summer  "previous-current" (startYear = prior calendar year)
        currentMonth = localSetup.dateDict["month"]
        currentYear = localSetup.dateDict["year"]
        currentTermName = localSetup._determineCurrentTerm(currentMonth)
        startYear, _ = localSetup._getSchoolYearRange(currentTermName, currentYear)

        currentSchoolYearStart = startYear
        nextSchoolYearStart = startYear + 1

        localSetup.logger.info(
            f"Generating Simple Syllabus catalog for school years "
            f"{currentSchoolYearStart}-{currentSchoolYearStart + 1} and "
            f"{nextSchoolYearStart}-{nextSchoolYearStart + 1}"
        )

        #  Step 1: Build (subject, course)  ParentOrg lookup 
        subjectOrgMap = buildSubjectOrgMap()

        #  Step 2: Download production (current) and staging (next) catalogs 
        prodGpsCsvPath = os.path.join(OUTPUT_DIR, "prod_gps_catalog_raw.csv")
        prodTugCsvPath = os.path.join(OUTPUT_DIR, "prod_tug_catalog_raw.csv")
        stagingGpsCsvPath = os.path.join(OUTPUT_DIR, "staging_gps_catalog_raw.csv")
        stagingTugCsvPath = os.path.join(OUTPUT_DIR, "staging_tug_catalog_raw.csv")

        prodGpsDf = downloadCatalog(PROD_GPS_CATALOG_URL, prodGpsCsvPath)
        prodTugDf = downloadCatalog(PROD_TUG_CATALOG_URL, prodTugCsvPath)
        stagingGpsDf = downloadCatalog(STAGING_GPS_CATALOG_URL, stagingGpsCsvPath)
        stagingTugDf = downloadCatalog(STAGING_TUG_CATALOG_URL, stagingTugCsvPath)

        #  Step 3: Build output rows for both school years 
        allGradRows: list = []
        allUndgRows: list = []

        # Current school year  production catalogs
        for catalogDf in [prodGpsDf, prodTugDf]:
            allGradRows.extend(
                buildOutputRows(
                    catalogDf,
                    isGraduate=True,
                    schoolYearStart=currentSchoolYearStart,
                    subjectOrgMap=subjectOrgMap
                )
            )
            allUndgRows.extend(
                buildOutputRows(
                    catalogDf,
                    isGraduate=False,
                    schoolYearStart=currentSchoolYearStart,
                    subjectOrgMap=subjectOrgMap
                )
            )

        # Next school year  staging catalogs
        for catalogDf in [stagingGpsDf, stagingTugDf]:
            allGradRows.extend(
                buildOutputRows(
                    catalogDf,
                    isGraduate=True,
                    schoolYearStart=nextSchoolYearStart,
                    subjectOrgMap=subjectOrgMap
                )
            )
            allUndgRows.extend(
                buildOutputRows(
                    catalogDf,
                    isGraduate=False,
                    schoolYearStart=nextSchoolYearStart,
                    subjectOrgMap=subjectOrgMap
                )
            )

        #  Step 4: Write output CSVs 
        OUTPUT_COLUMNS = [
            "Term", "Subject", "Course Number", "Title",
            "Parent Organization", "Class Program",
            "Description", "Credits", "Prerequisites", "Corequisites",
        ]

        gradDf = pd.DataFrame(allGradRows, columns=OUTPUT_COLUMNS)
        undgDf = pd.DataFrame(allUndgRows, columns=OUTPUT_COLUMNS)

        # De-duplicate in case the same course appears in multiple catalogs
        gradDf = gradDf.drop_duplicates(subset=["Term", "Subject", "Course Number"])
        undgDf = undgDf.drop_duplicates(subset=["Term", "Subject", "Course Number"])

        # Sort for readability: by Term, then Subject, then Course Number
        gradDf = gradDf.sort_values(["Term", "Subject", "Course Number"]).reset_index(drop=True)
        undgDf = undgDf.sort_values(["Term", "Subject", "Course Number"]).reset_index(drop=True)

        # File names span both school years for clarity
        endYear = nextSchoolYearStart + 1
        gradFileName = f"Graduate_Catalog_{currentSchoolYearStart}-{endYear}.csv"
        undgFileName = f"Undergraduate_Catalog_{currentSchoolYearStart}-{endYear}.csv"

        gradLocalPath = os.path.join(OUTPUT_DIR, gradFileName)
        undgLocalPath = os.path.join(OUTPUT_DIR, undgFileName)

        gradDf.to_csv(gradLocalPath, index=False)
        undgDf.to_csv(undgLocalPath, index=False)

        localSetup.logger.info(
            f"Graduate CSV written: {len(gradDf)} rows  {gradLocalPath}"
        )
        localSetup.logger.info(
            f"Undergraduate CSV written: {len(undgDf)} rows  {undgLocalPath}"
        )

        #  Step 5: Upload both CSVs to Simple Syllabus via SFTP 
        uploadToSimpleSyllabus(gradLocalPath, gradFileName)
        uploadToSimpleSyllabus(undgLocalPath, undgFileName)

        localSetup.logger.info(
            "sendCatalogToSimpleSyllabus completed successfully."
        )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)


#  Entry point 

if __name__ == "__main__":
    sendCatalogToSimpleSyllabus()

## ===========================================================================
## FILE: ActionModules\Test.py
## ===========================================================================

import os
import sys
from datetime import datetime

# Make ResourceModules importable when running from ActionModules
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

from Local_Setup import LocalSetup
from TLC_Common import downloadFile   # <-- uses your existing helper

# Initialize LocalSetup (for logging/paths if you want them)
localSetup = LocalSetup(datetime.now(), __file__)

def main():
    # URL you provided
    download_url = (
    )

    # Where to save it  adjust as you like
    # Example: put it in the SIS external resource path if configured,
    # otherwise fall back to current working directory.
    try:
        base_path = localSetup.getExternalResourcePath("SIS")
    except Exception:
        base_path = os.getcwd()

    os.makedirs(base_path, exist_ok=True)
    output_path = os.path.join(r'C:\Users\brycezmiller\desktop', "gps-course-report.csv")

    # Use your download function
    # Third argument is the file mode; "w" is consistent with your other usage
    downloadFile(localSetup, download_url, output_path, "w")

    localSetup.logger.info(f"Downloaded GPS course report to: {output_path}")
    print(f"Downloaded GPS course report to: {output_path}")

if __name__ == "__main__":
    main()

## ===========================================================================
## FILE: ActionModules\Turn_Off_Disallow_Threaded_Replies_In_Discussions.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Moduels
from __future__ import print_function
import traceback, os, sys, logging, requests, os, os.path, threading, time
from datetime import datetime
from datetime import date
import pandas as pd

## Set working directory
os.chdir(os.path.dirname(__file__))

## Add Script repository to syspath
sys.path.append(f"{os.getcwd()}\ResourceModules")

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Turn off disallow threaded discussions"

## Script file identifier
scriptRequirementMissingFolderIdentifier = "Missing_Syllabi"

scriptPurpose = r"""
The Outcome Exporter script is to copy the most recent relative outcome/s into the c ourses that need them.
"""
externalRequirements = r"""
To function properly this script requires a spreadsheet of the most recent outcomes and the courses they are assigned to.
"""

## Date Variables
currentDateTime = datetime.now()
currentMonth = currentDateTime.month
currentYear = currentDateTime.year
century = str(currentYear)[:2]
decade = str(currentYear)[2:]

## Time variables
currentDateTime = date.today()
current_year = currentDateTime.year
lastYear = current_year - 1
nextYear = current_year + 1
century = str(current_year)[:2]
decade = str(current_year)[2:]

## Set working directory
fileDir = os.path.dirname(__file__)
os.chdir(fileDir)

## The relative path is used to provide a generic way of finding where the Scripts TLC folder has been placed
## This provides a non-script specific manner of finding the vaiours related modules
PFRelativePath = r".\\"

## If the Scripts TLC folder is not in the folder the PFRelative path points to
## look for it in the next parent folder
while "Scripts TLC" not in os.listdir(PFRelativePath):

    PFRelativePath = f"..\\{PFRelativePath}"

## Change the relative path to an absolute path
absolutePath = f"{os.path.abspath(PFRelativePath)}\\"

## Add Input Modules to the sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ResourceModules")

## Import local modules
from Error_Email_API import errorEmailApi

## Local Path Variables
baseLogPath = f"{absolutePath}Logs\\{scriptName}\\"
configPath = f"{absolutePath}\\Configs TLC\\"
baseLocalInputPath = f"{absolutePath}Canvas Resources\\"

## Canvas Instance Url
coreCanvasApiUrl = None
## Open the Core_Canvas_Url.txt from the config path
with open (f"{configPath}Core_Canvas_Url.txt", "r") as file:
    coreCanvasApiUrl = file.readlines()[0]

## If the script is run as main the folder with the access token is in the parent directory
canvasAccessToken = ""

## Open and retrieve the Canvas Access Token
with open (fr"{configPath}Canvas_Access_Token.txt", "r") as file:
    canvasAccessToken = file.readlines()[0]

## Begin localSetup.logger set up

## If the base log path doesn't already exist, create it
if not (os.path.exists(baseLogPath)):
    os.makedirs(baseLogPath, mode=0o777, exist_ok=False)

## Log configurations
logger = logging.getLogger(__name__)
rootFormat = ("%(asctime)s %(levelname)s %(message)s")
FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
logging.basicConfig(format=rootFormat, filemode = "a", level=logging.INFO)

## Info Log Handler
infoLogFile = f"{baseLogPath}\\Info Log.txt"
logInfo = logging.FileHandler(infoLogFile, mode = 'a')
logInfo.setLevel(logging.INFO)
logInfo.setFormatter(FORMAT)
localSetup.logger.addHandler(logInfo)

## Warning Log handler
warningLogFile = f"{baseLogPath}\\Warning Log.txt"
logWarning = logging.FileHandler(warningLogFile, mode = 'a')
logWarning.setLevel(logging.WARNING)
logWarning.setFormatter(FORMAT)
localSetup.logger.addHandler(logWarning)

## Error Log handler
errorLogFile = f"{baseLogPath}\\Error Log.txt"
logError = logging.FileHandler(errorLogFile, mode = 'a')
logError.setLevel(logging.ERROR)
logError.setFormatter(FORMAT)
localSetup.logger.addHandler(logError)

## This variable enables the except function to only send

## by tracking what functions have already been recorded as having errors
errorHandler = errorEmailApi(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function handles function errors
def errorHandler.sendError (p1_ErrorLocation, p1_ErrorInfo, sendOnce = True):
    functionName = "## errorHandler.sendError"

    ## Log the error
    localSetup.logger.error (f"     \nA script error occured while running {p1_ErrorLocation}. " +
                     f"Error: {str(p1_ErrorInfo)}")

    ## If the function with the error has not already been processed send an email alert
    if (p1_ErrorLocation not in setOfFunctionsWithErrors):
        errorEmailApi.sendEmailError(p2_ScriptName = scriptName, p2_ScriptPurpose = scriptPurpose, 
                                     p2_ExternalRequirements = externalRequirements, 
                                     p2_ErrorLocation = p1_ErrorLocation, p2_ErrorInfo = f"{p1_ErrorInfo}: \n\n {traceback.format_exc()}")
        
        ## Add the function name to the set of functions with errors
        setOfFunctionsWithErrors.add(p1_ErrorLocation)
        
        ## Note that an error email was sent
        localSetup.logger.error (f"     \nError Email Sent")
    
    ## Otherwise log the fact that an error email as already been sent
    else:
        localSetup.logger.error (f"     \nError email already sent")

## This function processes the rows of the CSV file and sends on the relavent data to process_course
def addOutcomeToCourse (row, p2_inputTerm, p1_header, p1_outcomeCourseDict):
    functionName = "Add Outcome/s to courses"

    try:
        
        ## If the row's course_sis_id is empty skip it
        if pd.isna(row['Course_sis_id']):
            return

        ## For each row in our CSV file pull the course sis id column and outcome column names
        ## Sample sess values: FA2022_PHIL2030_01
        ## Sample outcome value: GE_CF4_V1.0
        targetCourseSisId = row['Course_sis_id']
        outcomeKeys = [col for col in row.keys() if "Outcome" in col and "Area" not in col]
            
        ## Log the start of the process
        localSetup.logger.info("\n     Course:" + targetCourseSisId)

        ## Create the URL the API call will be made to
        course_API_url = coreCanvasApiUrl + "courses/sis_course_id:" + targetCourseSisId + "/course_copy"
        
        ## For each outcome in the row
        for outcome in outcomeKeys:
            
            ## If the outcome is empty skip it
            if pd.isna(row[outcome]):
                continue
            
            ## Get the canvas course id from the outcomeCourseDict
            canvasCourseId = p1_outcomeCourseDict[row[outcome]]

            ## Create the API Payload from the outcome sis id
            payload = {'source_course': canvasCourseId, 'only[]': ['outcomes']}
                
            ## Make the API call and save the result as course_object
            course_object = requests.post(course_API_url, headers = p1_header, params = payload)
                
            ## If the API status code is anything other than 200 it is an error, so log it and skip
            if (course_object.status_code != 200):
                localSetup.logger.error("\nCourse Error: " + str(course_object.status_code))
                localSetup.logger.error(course_API_url)
                localSetup.logger.error(course_object.url)
            else:
                ## Successfully made the API call
                localSetup.logger.info("\nOutcome copy successful for : " + targetCourseSisId)

    except Exception as Error:
    errorHandler.sendError (functionName, Error)
        
## This function makes a makes an api call to Canvas to set a course's discussion topic to allow threaded replies
def allowThreadedReplies (p1_row, p1_header, p1_canvasCourseUnthreadedDiscussions):
    
    functionName = "allowThreadedReplies"

    try:

            ## Define the course vaables
            canvasCourseId = int(p1_row['canvas_course_id'])
            sisCourseID = p1_row['course_id']

            ## Define the payload that will be sent to each course discussion topics end point
            discussionTopicsPayload = {"per_page": 100}
        
            ## Define the payload that will be sent to each course discussion end point
            discussionTopicPayload = {"discussion_type": "threaded"}
            
            ## Make a url to get the the courses's discussions
            courseDiscussionTopicsApiUrl = coreCanvasApiUrl + "courses/" + str(canvasCourseId) + "/discussion_topics"

            ## Make the API call
            courseDiscussionTopicsObject = requests.get(courseDiscussionTopicsApiUrl, headers = p1_header, params = discussionTopicsPayload)

            ## If the api status code is 403
            if (courseDiscussionTopicsObject.status_code == 403):

                ## So long as the API status code is 403, wait 2 seconds and try again
                while (courseDiscussionTopicsObject.status_code == 403):
                    
                    ## Log that the course has been rate limited
                    localSetup.logger.warning("\nRate limited for course: " + str(canvasCourseId))
                    
                    ## Wait 2 seconds
                    time.sleep(5) 

                    ## Make the API call again
                    courseDiscussionTopicsObject = requests.get(courseDiscussionTopicsApiUrl, headers = p1_header, params = discussionTopicsPayload)

            ## If the API status code is anything other than 200 it is an error, so log it and skip
            if (courseDiscussionTopicsObject.status_code != 200):
                localSetup.logger.error("\nCourse Error: " + str(courseDiscussionTopicsObject.status_code))
                localSetup.logger.error(courseDiscussionTopicsApiUrl)
                localSetup.logger.error(courseDiscussionTopicsObject.url)

            ## Otherwise
            else:
                
                ## Get the course object as a json
                courseDiscussionTopicsDict = courseDiscussionTopicsObject.json()

                ## If the course object is empty
                if not courseDiscussionTopicsDict:
                    
                    ## Log that the course has no discussion topics
                    localSetup.logger.info("\nNo discussion topics for course: " + str(canvasCourseId))
                
                ## Otherwise
                else:

                    ## For each discussion topic
                    for topic in courseDiscussionTopicsDict:

                        ## if the discussion isn't already threaded
                        if topic['discussion_type'] not in ["threaded", "side_comment"]:

                            ## Get the discussion title and url
                            discussionTitle = topic['title']
                            discussionUrl = topic['html_url']

                            ## Add the course's information to the canvasCourseUnthreadedDiscussions dict
                            p1_canvasCourseUnthreadedDiscussions["canvas_sis_id"].append(sisCourseID)
                            p1_canvasCourseUnthreadedDiscussions["canvas_course_id"].append(canvasCourseId)
                            p1_canvasCourseUnthreadedDiscussions["discussion title"].append(discussionTitle)
                            p1_canvasCourseUnthreadedDiscussions["discussion url"].append(discussionUrl)

            localSetup.logger.info (f"Course {canvasCourseId} processed")
                            
    except Exception as Error:
    errorHandler.sendError (functionName, Error)

## This function opens the CSV file, the save locations json file, sends the information on, and closes both files
def allowThreadedDiscussions():
    functionName = "outcome_exporter"
    
    try:

        ## Define the API Call header using the retreived Canvas Token
        header = {'Authorization' : f"Bearer {canvasAccessToken}"}

        ## Open the relevant Active_GE_Course.csv as a df
        canvasCourses = pd.read_csv(f"{baseLocalInputPath}Target_Canvas_Courses.csv")

        ## Remove any rows that area all blank
        canvasCourses.dropna(how = "all", inplace = True)

        ## Create a dict with canvas_sis_id, canvas_course_id, discussion title, and discussion url, each with an empty list as the value
        canvasCourseUnthreadedDiscussions = {"canvas_sis_id": []
                                                , "canvas_course_id": []
                                                , "discussion title": []
                                                , "discussion url": []
                                                }
        

        ## Make a list of ongoing course discussion conversion threads
        ongoingThreads = []
        
        ## For each row in the Canvas Courses DF
        for index, row in canvasCourses.iterrows():

            ## If the row's course_sis_id is empty skip it
            if pd.isna(row['canvas_course_id']):
                continue

            ##if row["course_id"] == "FA2024_ACCT2060_01":

            ## Create a threaded allow threaded replies object
            threadCourseDiscussionsAllowThreading = threading.Thread(target=allowThreadedReplies, args=(row, header, canvasCourseUnthreadedDiscussions))

            ## Start the thread
            threadCourseDiscussionsAllowThreading.start()
            
            ## For every 100 threads
            if (len(ongoingThreads) % 400 == 0):
                
                ## wait 2 seconds
                time.sleep(2)
            
            ## Add the thread to the ongoing threads list
            ongoingThreads.append(threadCourseDiscussionsAllowThreading)
            
        ## Wait for all the threads to finish
        for thread in ongoingThreads:
            thread.join()

        ## Create a df from the canvasCourseUnthreadedDiscussions dict
        canvasCourseUnthreadedDiscussionsDF = pd.DataFrame(canvasCourseUnthreadedDiscussions)
        
        ## Save the df to a csv
        canvasCourseUnthreadedDiscussionsDF.to_csv(f"{baseLocalInputPath}Canvas_Course_Unthreaded_Discussions.csv", index = False)
     
    except Exception as Error:
    errorHandler.sendError (functionName, Error)

if __name__ == "__main__":

    ## Start and download the Canvas reportz
    allowThreadedDiscussions ()

    input("Press enter to exit")

## ===========================================================================
## FILE: ActionModules\Uncomment Out Error Handling.py
## ===========================================================================

import os
import re


def uncomment_keywords_in_py_files(directory):
    ## List of (compiled_pattern, replacement) pairs
    patterns = [
        ## Uncomment "## try:" -> "    try:"
        (re.compile(r'^\s*##\s*(try\s*:)', re.MULTILINE), r'    \1'),

        ## Uncomment "## except ...:" -> "    except ...:"
        (re.compile(r'^\s*##\s*(except\b.*:\s*)', re.MULTILINE), r'    \1'),

        ## Uncomment "functionName" -> "    functionName"
        (re.compile(r'^\s*##\s*(    functionName\b)', re.MULTILINE), r'\1'),

        ## Uncomment "## errorHandler.sendError" -> "errorHandler.sendError"
        (re.compile(r'^\s*##\s*(errorHandler\.sendError\b)', re.MULTILINE), r'\1'),
    ]

    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)

                with open(file_path, 'r') as f:
                    lines = f.readlines()

                modified_lines = []
                for line in lines:
                    modified_line = line
                    for pattern, replacement in patterns:
                        if pattern.search(modified_line):
                            modified_line = pattern.sub(replacement, modified_line)
                            ## You can break here if you guarantee only one pattern per line
                    modified_lines.append(modified_line)

                with open(file_path, 'w') as f:
                    f.writelines(modified_lines)

if __name__ == "__main__":
    target_directory = input("Enter the path to the target directory: ").strip()
    if os.path.isdir(target_directory):
        uncomment_keywords_in_py_files(target_directory)
        print(f"Reversion complete for directory: {target_directory}")
    else:
        print("Invalid directory path. Please try again.")
    input("Press Enter to exit...")

## ===========================================================================
## FILE: ActionModules\Update_Grading_Standard_For_Listed_Courses.py
## ===========================================================================


# Author: Bryce Miller - brycezmiller@nnu.edu
# Last Updated by: Bryce Miller (refactored to update grading standards via Courses API)

import os, threading, time, pandas as pd, sys
from datetime import datetime

## Add the resource modules path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

# Try direct imports if run as main, else relative for package usage
    try:
    from Local_Setup import LocalSetup
    from TLC_Common import makeApiCall
    from Error_Email import errorEmail
    from Common_Configs import coreCanvasApiUrl, canvasAccessToken
except ImportError:  # When imported as a package/module
    from .Local_Setup import LocalSetup
    from .TLC_Common import makeApiCall
    from .Error_Email import errorEmail
    from .Common_Configs import coreCanvasApiUrl, canvasAccessToken

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Change_Grading_Standard_For_Listed_Courses"
scriptPurpose = r"""
This script reads a CSV file containing Canvas course IDs and grading standard IDs
and updates the grading standard for each listed course using the Canvas Courses API
(Update a course - course[grading_standard_id]).
"""
externalRequirements = r"""
To function properly, this script requires:
- Valid Canvas API configuration in Common_Configs (coreCanvasApiUrl, canvasAccessToken).
- A CSV file located in the Canvas internal resources directory
  (LocalSetup.getInternalResourcePaths("Canvas")) with:
    - canvas_course_id
    - grading_standard_id  (or grading_scheme_id)
"""

## Initialize the local setup object and error handler
localSetup = LocalSetup(datetime.now(), __file__)
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## Change the grading standard for the target course
def changeCourseGradingStandard(
    courseId: str,
    gradingStandardId: str,
) -> None:
    """
    Change the grading standard for a Canvas course given its course ID and
    target grading standard ID.

    Uses the Courses "Update a course" endpoint:
    PUT /api/v1/courses/:id
    with course[grading_standard_id].
    """
    functionName = "changeCourseGradingStandard"
    try:
        updateCourseUrl = f"{coreCanvasApiUrl}courses/{courseId}"
        # Build payload using nested course object, matching Rails-style parameters
        payload = {
            "course": {
                "grading_standard_id": int(gradingStandardId)
            }
        }

        response = makeApiCall(
            localSetup=localSetup,
            p1_apiUrl=updateCourseUrl,
            p1_payload=payload,
            p1_apiCallType="put",
        )

        # makeApiCall may return a Response or a list; handle the primary case.
        statusCode = getattr(response, "status_code", None)

        if statusCode == 200:
            localSetup.logger.info(
                f"Successfully changed grading_standard_id for course with ID: "
                f"{courseId} to {gradingStandardId}"
            )
        else:
            localSetup.logger.warning(
                f"Failed to change grading_standard_id for course with ID: {courseId}. "
                f"Status code: {statusCode}"
            )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## Change the grading standard for listed courses from a CSV file
def changeListedCoursesGradingStandard(
    csvFileName: str = "Target_Canvas_Course_Ids.csv",
    threadSleep: float = 0.1,
) -> None:
    """
    Read a CSV file of course/grading standard IDs and change each course's grading standard.

    Expected columns in CSV:
      - canvas_course_id
      - grading_standard_id  (preferred)
        or grading_scheme_id (alias, will be treated as grading_standard_id)
    """
    functionName = "changeListedCoursesGradingStandard"
    try:
        ## Get the internal canvas resource path
        canvasResourcePath =  = localSetup.getInternalResourcePaths("Canvas")

        targetCoursesCsvFilePath = os.path.join(
            canvasResourcePath,
            csvFileName,
        )

        localSetup.logger.info(
            f"Starting {functionName}. Input file: {targetCoursesCsvFilePath}"
        )

        if not os.path.exists(targetCoursesCsvFilePath):
            raise FileNotFoundError(
                f"Target courses CSV not found: {targetCoursesCsvFilePath}"
            )

        ## Thread tracking
        ongoingThreads = []

        ## Load CSV
        rawTargetCoursesDf = pd.read_csv(targetCoursesCsvFilePath)

        ## Keep rows that have a value in canvas_course_id
        if "canvas_course_id" not in rawTargetCoursesDf.columns:
            raise KeyError(
                "Expected column 'canvas_course_id' not found in CSV."
            )

        ## Support either grading_standard_id (Canvas term) or grading_scheme_id (your wording)
        gradingColumnName = None
        if "grading_standard_id" in rawTargetCoursesDf.columns:
            gradingColumnName = "grading_standard_id"
        elif "grading_scheme_id" in rawTargetCoursesDf.columns:
            gradingColumnName = "grading_scheme_id"
        else:
            raise KeyError(
                "Expected column 'grading_standard_id' or 'grading_scheme_id' "
                "not found in CSV."
            )

        targetCoursesDf = rawTargetCoursesDf[
            rawTargetCoursesDf["canvas_course_id"].notna()
        ]

        localSetup.logger.info(
            f"Found {len(targetCoursesDf)} target course rows with non-null canvas_course_id."
        )

        ## Iterate and spawn threads
        for _, row in targetCoursesDf.iterrows():
            courseId = str(row["canvas_course_id"]).replace(".0", "")
            gradingStandardId = str(row[gradingColumnName]).replace(".0", "")

            # Skip if either is empty
            if not courseId or not gradingStandardId:
                localSetup.logger.warning(
                    f"Skipping row with courseId='{courseId}' "
                    f"{gradingColumnName}='{gradingStandardId}'"
                )
                continue

            changeGradingThread = threading.Thread(
                target=changeCourseGradingStandard,
                args=(courseId, gradingStandardId),
                name=f"change_grading_standard_{courseId}",
                daemon=True,
            )
            changeGradingThread.start()
            ongoingThreads.append(changeGradingThread)

            ## Sleep for a short time to avoid overloading the server
            time.sleep(threadSleep)

        ## Check if all ongoing change grading standard threads have completed
        for thread in ongoingThreads:
            thread.join()

        localSetup.logger.info(
            f"{functionName} completed. Processed {len(targetCoursesDf)} courses."
        )

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":
    localSetup.logger.info(
        f"Starting script: {scriptName} | Purpose: {scriptPurpose.strip()}"
    )

    ## Change the grading standard for the listed courses
    changeListedCoursesGradingStandard()

    localSetup.logger.info(f"Script {scriptName} completed.")
    input("Press Enter to exit...")


## ===========================================================================
## FILE: ActionModules\__init__.py
## ===========================================================================




## ===========================================================================
## FILE: IDT_Canvas_Primary.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Moduels
from datetime import datetime
import os, sys, threading, time
import pandas as pd

## Set working directory
os.chdir(os.path.dirname(__file__))


## Add the resource modules path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

## Import local modules
from ResourceModules.Local_Setup import LocalSetup
from ResourceModules.Canvas_Report import CanvasReport
from ResourceModules.Error_Email import errorEmail
from ReportModules.Incoming_Student_Report import termGetIncomingStudentsInfo
from ReportModules.Outcome_Attachment_Report import termOutcomeAttachmentReport
from ReportModules.Nighthawk_360_Canvas_Report import Nighthawk360CanvasReport
from ReportModules.Outcome_Results_Report import termProcessOutcomeResults
from ActionModules.Enroll_TUG_Students_In_SGA import enrollTugStudentsInSga
from ActionModules.Enroll_GPS_Students_In_Grad_Hub import enrollGPSStudentsInGrad_Hub
from ActionModules.Course_Date_Related_Actions import termDetermineAndPerformRelevantActions
from ActionModules.Change_Syllabus_Tab import updateCourseSyllabusTab

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
Run all IDT Canvas related scripts. Including but not limited to Get_Terms, Get_TUG_Students, Get_Courses, Get_Enrollments, Get_Outcome_Results, Retrieve_University_Syllabi, Check_Syllabi_For_Syllabus_Addendum, List_Gathered_Syllabi, Create_Active_GE_Course_List, Outcome_Exporter, Check_GE_Outcome_Attachment, and GE_Data_SSIS.
"""
externalRequirements = r"""
The full contents of the repository found at https://github.com/NNU-IDT-Scripts/NNU-Canvas-Scripts.
"""

## Initialize the local setup object and error handler
localSetup = LocalSetup(datetime.now(), __file__)
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

from Common_Configs import undgTermsCodesToWordsDict

## Define time variables
currentHour = localSetup.dateDict["hour"]
currentMonth = localSetup.dateDict["month"]
decade = localSetup.dateDict["decade"]


## Testing variables
## currentDay = 1 ## First week of the month testing value
## currentWeekDay = 4 ## Day of the week testing value 
## currentHour = 1 ## First run of the day testing value
## currentHour = 16 ## Last run of the day testing value

        
## Run Outcome Related Scripts
def outcomeReportsAndActions (p1_relaventTerm):
    
    functionName = "Outcome Reports and Actions"
    
    try:
    
        ## Retrieve the Automated Outcome Tool Variables excel file as a df    
        automatedOutcomeToolVariablesDf = pd.read_excel(os.path.join(localSetup.getExternalResourcePath("SIS"), "Internal Tool Files\\Automated Outcome Tool Variables.xlsx"))
        
        ## Define the output threading objects
        ongoingOutcomeOutput1Threads = []

        ## Define a variable to track whether the term is a grad term
        gradTerm = False

        ## If the term is a grad term
        if p1_relaventTerm[:2].upper() in ["GS", "SG", "GF"]:
            gradTerm = True
        
        ## For each Target Designator and Course Level in the Automated Outcome Tool Variables
        for targetDesignator, courseLevel in zip(
            automatedOutcomeToolVariablesDf["Target Designator"],
            automatedOutcomeToolVariablesDf["Course Level"]
        ):


            ## If the courseLevel is Undergraduate
            if courseLevel == "Undergraduate":

                ## If the term is a grad term
                if gradTerm:

                    ## Continue
                    continue

            ## Otherwise if the courseLevel is Graduate
            elif courseLevel == "Graduate":

                ## If the term is not a grad term
                if not gradTerm:

                    ## Continue
                    continue

            ## Define the outcome attachment and outcome result report threads
            threadOutcomeAttachment = threading.Thread(target=termOutcomeAttachmentReport, args=(p1_relaventTerm, targetDesignator))
            
            ## Start the threads
            threadOutcomeAttachment.start()
            
            ## Add the threads to the ongoingOutcomeOutputThreads list
            ongoingOutcomeOutput1Threads.append(threadOutcomeAttachment)
    
        ## Wait until all ongoingOutcomeOutputThreads threads have completed
        for thread in ongoingOutcomeOutput1Threads:
            thread.join()

        ## Define the output threading objects
        ongoingOutcomeOutput2Threads = []

        ## For each Target Designator in the Automated Outcome Tool Variables
        for targetDesignator, courseLevel in zip(
            automatedOutcomeToolVariablesDf["Target Designator"],
            automatedOutcomeToolVariablesDf["Course Level"]
        ):

            ## If the courseLevel is Undergraduate
            if courseLevel == "Undergraduate":

                ## If the term is a grad term
                if gradTerm:

                    ## Continue
                    continue

            ## Otherwise if the courseLevel is Graduate
            elif courseLevel == "Graduate":

                ## If the term is not a grad term
                if not gradTerm:

                    ## Continue
                    continue

            ## Define the outcome attachment and outcome result report threads
            threadOutcomeResult = threading.Thread(target=termProcessOutcomeResults, args=(p1_relaventTerm, targetDesignator))
            
            ## Start the threads
            threadOutcomeResult.start()
            
            ## Add the threads to the ongoingOutcomeOutputThreads list
            ongoingOutcomeOutput2Threads.append(threadOutcomeResult)
    
        ## Wait until all ongoingOutcomeOutputThreads threads have completed
        for thread in ongoingOutcomeOutput2Threads:
            thread.join()
            
        ## Define the action threading objects
        ongoingOutcomeActionThreads = []
        
        ## For each Target Designator in the Automated Outcome Tool Variables
        for targetDesignator, courseLevel in zip(
            automatedOutcomeToolVariablesDf["Target Designator"],
            automatedOutcomeToolVariablesDf["Course Level"]
        ):

            ## If the courseLevel is Undergraduate
            if courseLevel == "Undergraduate":

                ## If the term is a grad term
                if gradTerm:

                    ## Continue
                    continue

            ## Otherwise if the courseLevel is Graduate
            elif courseLevel == "Graduate":

                ## If the term is not a grad term
                if not gradTerm:

                    ## Continue
                    continue
            
            ## Define the outcome action threads
            threadOutcomeAction = threading.Thread(target=termDetermineAndPerformRelevantActions, args=(p1_relaventTerm, targetDesignator))
            
            ## Start the threads
            threadOutcomeAction.start()
            
            ## Add the threads to the ongoingOutcomeActionThreads list
            ongoingOutcomeActionThreads.append(threadOutcomeAction)
            
        ## Wait until all ongoingOutcomeActionThreads threads have completed
        for thread in ongoingOutcomeActionThreads:
            thread.join()
 
    except Exception as Error:
        errorHandler.sendError (functionName, Error)
        

## This function creates course and enrollment CSVs for the given term
def createPartialCanvasInputs_Threaded (p3_RelaventTerm):
    
    ## Create a list for ongoing threads
    activeThreads = []

    ## Define the primary threading objects and add them to the ongoingThreads list
    activeThreads.append(threading.Thread(target=CanvasReport.getCoursesDf, args=(localSetup, p3_RelaventTerm)))
    activeThreads.append(threading.Thread(target=CanvasReport.getSectionsDf, args=(localSetup, p3_RelaventTerm)))
    activeThreads.append(threading.Thread(target=CanvasReport.getEnrollmentsDf, args=(localSetup, p3_RelaventTerm)))
    activeThreads.append(threading.Thread(target=CanvasReport.getUnpublishedCoursesDf, args=(localSetup, p3_RelaventTerm)))

        
    ## Start threading objects 
    for thread in activeThreads:
        thread.start()
        time.sleep(1)

    ## Wait for the threading to complete
    for thread in activeThreads:
        thread.join()

    ## Make sure the users file is recent
    CanvasReport.getUsersDf(localSetup)
    



## This function creates term, user, course, and account CSVs for the given term
## Term and User CSVs are not term specific and so only need to be created once
def createCompleteCanvasInputs_Threaded(p2_RelaventTerm):
    ## Define a list for ongoing threads
    activeThreads = []

    ## Define Canvas instance wholistic threading objects
    activeThreads.append(threading.Thread(target=CanvasReport.getCoursesDf, args=(localSetup, "All")))
    activeThreads.append(threading.Thread(target=CanvasReport.getSectionsDf, args=(localSetup, "All")))
    activeThreads.append(threading.Thread(target=CanvasReport.getCoursesDf, args=(localSetup, p2_RelaventTerm)))
    activeThreads.append(threading.Thread(target=CanvasReport.getTermsDf, args=(localSetup,)))
    activeThreads.append(threading.Thread(target=CanvasReport.getUsersDf, args=(localSetup,)))
    activeThreads.append(threading.Thread(target=CanvasReport.getAccountsDf, args=(localSetup,)))
    activeThreads.append(threading.Thread(target=CanvasReport.getCanvasUserLastAccessDf, args=(localSetup,)))

    ## Define the term specific threading object
    activeThreads.append(threading.Thread(target=createPartialCanvasInputs_Threaded, args=(p2_RelaventTerm,)))

    ## Start threading objects 
    for thread in activeThreads:
        thread.start()
        time.sleep(1)

    ## Wait for the threading to complete
    for thread in activeThreads:
        thread.join()

    ## Retrieve the Automated Outcome Tool Variables excel file as a df    
    automatedOutcomeToolVariablesDf = pd.read_excel(os.path.join(localSetup.getExternalResourcePath("SIS"), "Internal Tool Files\\Automated Outcome Tool Variables.xlsx"))
    
    ## For each Target Designator in the Automated Outcome Tool Variables
    for targetDesignator in automatedOutcomeToolVariablesDf["Target Designator"]:
        ## Retrieve the lists of active outcome courses for the given term
        CanvasReport.getActiveOutcomeCoursesDf(localSetup, p2_RelaventTerm, targetDesignator)

## This function determines the target term(s) using TLC_Common helper
def determineTargetTerms():
    functionName = "Determine Target Terms"

    try:

        ## Get the current term codes
        targetTermSet = localSetup.getCurrentTermCodes()

        ## Get weekday and day info
        currentWeekDay = localSetup.dateDict["weekDay"]  ## 0=Monday, 4=Friday
        currentDay = localSetup.dateDict["day"]

        ## If today is Friday
        if currentWeekDay == 4:
            ## Add current school year, most recent term, and next term
            targetTermSet.update(localSetup.getCurrentSchoolYearTermCodes())
            targetTermSet.update(localSetup.getMostRecentCompletedTermCodes())
            targetTermSet.update(localSetup.getNextTermCodes())

            ## If this is the first or third Friday of the month
            if (1 <= currentDay <= 7) or (15 <= currentDay <= 21):
                ## Also add previous school year terms
                targetTermSet.update(localSetup.getPreviousSchoolYearTermCodes())

        ## Convert set to list for return
        targetTermList = list(targetTermSet)

        localSetup.logger.info(f"\nRelevant Terms set as {targetTermList}.")
        return targetTermList

    except Exception as Error:
        errorHandler.sendError(functionName, p1_ErrorInfo=Error)

## This function retrives the data neccessary to run the four times daily processes and runs them
def fourTimesDaily (p1_relaventTerm):
    functionName = "Four Times Daily"

    try:

        ## get and open the courses.csv from the external input path
        sisImportFilesList = os.listdir(localSetup.getExternalResourcePath("SIS"))
        if "canvas_course.csv" in sisImportFilesList:
            sisCoursesDf = pd.read_csv(f"{localSetup.getExternalResourcePath('SIS')}canvas_course.csv", dtype=str)
            sisCoursesDf.fillna("", inplace=True)

            ## Filter out any that have 2025 in the course_id
            sisCoursesDf = sisCoursesDf[~sisCoursesDf["course_id"].str.contains("2025")]

            ## Filter out any deleted courses
            sisCoursesDf = sisCoursesDf[sisCoursesDf["status"] != "deleted"]
            
            ## For each row in the sis courses df
            ongoingSyllabusUpdateThreads = []
            for index, row in sisCoursesDf.iterrows():
                ## Get the sis id
                sisCourseId = row["course_id"]

                ## IF the row isn't status active, skip it
                if row["status"] != "active":
                    continue

                ## Define and start thread to update the syllabus tab for the course
                thread = threading.Thread(target=updateCourseSyllabusTab, args=(sisCourseId,))
                thread.start()
                ongoingSyllabusUpdateThreads.append(thread)

                ## Small gap between thread starts to avoid hammering APIs
                time.sleep(1)

            ## Wait until all syllabus update threads have completed
            for thread in ongoingSyllabusUpdateThreads:
                thread.join()
        
        ## Get the primary term data
        createCompleteCanvasInputs_Threaded(p1_relaventTerm)

        ## If relavent term is a summer term
        if p1_relaventTerm[:2].upper() == "SU":

            ## Get the fall future partial canvas inputs
            createPartialCanvasInputs_Threaded(p1_relaventTerm.replace("SU", "FA"))
            
            ## Run the get incoming student info for the future undg fall term
            termGetIncomingStudentsInfo(p1_relaventTerm.replace("SU", "FA"))

            ## If it is july
            if currentMonth == 7:

                ## Run the partial on the upcoming undg and grad school year terms
                createPartialCanvasInputs_Threaded(p1_relaventTerm.replace("SU", "GF"))

                ## Run the incoming student info for the future grad school year
                termGetIncomingStudentsInfo(p1_relaventTerm.replace("SU", "GF"))

            ## Otherwise
            else:

                ## Run get incoming student infor for the current grad school year
                termGetIncomingStudentsInfo(p1_relaventTerm.replace("SU", "SG"))
            
        ## Otherwise
        else:

            ## If it is december
            if currentMonth == 12:
                
                ## Run the partial on the upcoming undg and grad spring tgerms
                createPartialCanvasInputs_Threaded(f"SP{int(decade) + 1}")
                createPartialCanvasInputs_Threaded(f"GS{int(decade) + 1}")

                ## Run the get incoming student info for the future spring terms
                termGetIncomingStudentsInfo(f"SP{int(decade) + 1}")
                termGetIncomingStudentsInfo(f"GS{int(decade) + 1}")
                
            ## Otherwise
            else:    
            
                ## Run the get incoming student info for the current terms
                termGetIncomingStudentsInfo(p1_relaventTerm)
                termGetIncomingStudentsInfo(p1_relaventTerm.replace("SP", "GS").replace("FA", "GF"))

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function runs the one time daily processes
def oneTimeDaily (p1_currentTerm, p1_relaventTerms):
    functionName = "One Time Daily"

    try:

        ## Define the neccessary thread lists
        ongoingInputThreads = []
        ongoingOutcomeThreads = []
        ongoingReportThreads = []
        
        ## Define input threading objects for every term but the first 
        ## (The first term was already run through the process by the four times daily script)
        for term in p1_relaventTerms:

            ## For the first term run the four times daily function as it is run for the first time in the same
            ## time frame as the once daily function
            if term == p1_currentTerm:
                
                ## Define the term related Canvas input thread to get the complete
                ## Canvas input and run the four times a day script for the first time of the day
                inputThread = threading.Thread(target=fourTimesDaily, args=(p1_currentTerm,))

            ## Otherwise just get the partial canvas account input for each additional term
            else:

                ## Define the term related Canvas input thread
                inputThread = threading.Thread(target=createPartialCanvasInputs_Threaded, args=(term,))

            ## Start the term related input thread
            inputThread.start()

            ## Add the term related input thread to the list of ongoing threads 
            ongoingInputThreads.append(inputThread)
            time.sleep(1)
            
        ## Check if all ongoing input threads have completed
        for thread in ongoingInputThreads:
            thread.join()

        ## Get the current, most recent completed, and next term codes
        currentTermCodes = localSetup.getCurrentTermCodes()
        mostRecentCompletedTermCodes = localSetup.getMostRecentCompletedTermCodes()
        nextTermCodes = localSetup.getNextTermCodes()

        ## Define a set of all the current, most recent completed, and next term codes
        currentMostRecentNextTerms = list(
            currentTermCodes.union(mostRecentCompletedTermCodes).union(nextTermCodes)
            )
            
        ## For each term in the relavent terms
        for term in currentMostRecentNextTerms:
            
            ## for each of the first three terms
            ## if term == "GF25":

                ## Define a outcome reports and actions thread
                outcomeReportsAndActionsThread = threading.Thread(target=outcomeReportsAndActions, args=(term,))
                
                ## Start the outcome reports and actions thread
                outcomeReportsAndActionsThread.start()
                
                ## Add the outcome reports and actions thread to the list of ongoing threads
                ongoingOutcomeThreads.append(outcomeReportsAndActionsThread)
                
                ## Wait a second to ensure there is a gap before the next thread
                time.sleep(1)
        
        ## Check if all ongoing outcome threads have completed
        for thread in ongoingOutcomeThreads:
            thread.join()

        ########   Required Canvas Data Retrieved   ########
            
        ## If the term is the summer term, change it to fall for the purpose of enrolling TUG students in SGA
        enrollTugStudentsInSgaThread = threading.Thread(target=enrollTugStudentsInSga, args=(p1_currentTerm.replace("SU","FA"),))

        ## Start the term related enrollTugStudentsInSga thread
        enrollTugStudentsInSgaThread.start()

        ## Add the term related enrollTugStudentsInSga thread to the list of ongoing report threads
        ongoingReportThreads.append(enrollTugStudentsInSgaThread)

        ## Define a term related enrollGPSStudentsInGrad_Hub thread
        ## If the term is the summer term, change it to fall for the purpose of enrolling TUG students in SGA
        enrollGPSStudentsInGrad_HubThread = threading.Thread(target=enrollGPSStudentsInGrad_Hub, args=(p1_currentTerm.replace("SG|FA","GF").replace("SP","GS"),))

        ## Start the term related enrollGPSStudentsInGrad_Hub thread
        enrollGPSStudentsInGrad_HubThread.start()

        ## Add the term related enrollGPSStudentsInGrad_Hub thread to the list of ongoing report threads
        ongoingReportThreads.append(enrollGPSStudentsInGrad_HubThread)       

        ## Wait until all ongoing threads have completed
        for thread in ongoingReportThreads:
            thread.join()

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

def main ():
    functionName = "Main"

    try:
        
        ## Determine the target terms
        targetTerms = determineTargetTerms()
        ## Find which ever term code is in the undgTermsCodesToWordsDict
        currentTermCodes = localSetup.getCurrentTermCodes()
        currentTerm = None
        for term in currentTermCodes:
            if term[:2].upper() in undgTermsCodesToWordsDict.keys():
                currentTerm = term
                break
        
        ## If it is the first run of the day
        if currentHour < 6:

            ## Run the onetime daily function with the list of target terms
            ## This function includes the four times daily function
            oneTimeDaily(currentTerm, targetTerms)
        
        ## If it is the last run of the day (determined by being after 3:00 pm)
        elif currentHour > 15:

            ## Run the fourTimesDaily script with the 1st (and should be only) target term
            fourTimesDaily (p1_relaventTerm = currentTerm)

            ## Fetch the current Nighthawk 360 data
            Nighthawk360CanvasReport()

        ## If it is the second or third run of the day
        else:

            ## Run the fourTimesDaily script with the 1st (and should be only) target term
            fourTimesDaily (p1_relaventTerm = targetTerms[0])

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

        

if __name__ == "__main__":
    main()
    #input("Press enter to exit")

## ===========================================================================
## FILE: ReportModules\Inactive_Enrollments_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller


from datetime import datetime
import paramiko, traceback,  os, logging, sys, requests, json, re, threading, time
import pandas as pd ##External Download from https://pypi.org/project/pandas/

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Conclude Inactive Student's Enrollments"

scriptPurpose = r"""
This script (Inactive_Enrollments_Report) makes a special enrollments call to get all
enrollments from every term and turns it into a Pandas Dataframe. It then retrieves the list of 
students currently being imported to Canvas from the institution'a SIS and saves it as a Dataframe as
well. It then removes any enrollments from enrollment dataframe whose id's match the userlist, as well
as all teacher enrollments, and saves whats left in sis import csv format with conclude set to true.

Thus, the enrollments of all non-active students are concluded, ensuring they don't get global 
announcement notifications.
"""
externalRequirements = r"""
To function properly this script requires access to the institution's Canvas and a list of active 
students.
"""

## Date Variables
currentDateTime = datetime.now()
currentMonth = currentDateTime.month
currentYear = currentDateTime.year
century = str(currentYear)[:2]
decade = str(currentYear)[2:]
currentTerms = []
nearFutureTerms = []
currentAndNearFutureTerms = []
currentSchoolYear = None

## January through May is the Spring Term
if currentMonth >= 1 and currentMonth <= 5:
    ## Current semester's three active terms
    currentTerms.append(f"SP{str(currentYear)}")
    currentTerms.append(f"GS{str(currentYear)}")
    currentTerms.append(f"AS{str(currentYear)}")
    ## Next semester's six active terms
    nearFutureTerms.append(f"SU{str(currentYear)}")
    nearFutureTerms.append(f"SG{str(currentYear)}")
    nearFutureTerms.append(f"SA{str(currentYear)}")
    nearFutureTerms.append(f"FA{str(currentYear)}")
    nearFutureTerms.append(f"GF{str(currentYear)}")
    nearFutureTerms.append(f"AF{str(currentYear)}")

## June through August is the Summer Term
elif currentMonth >= 6 and currentMonth <= 8:
    ## Current semester's three active terms
    currentTerms.append(f"SU{str(currentYear)}")
    currentTerms.append(f"SG{str(currentYear)}")
    currentTerms.append(f"SA{str(currentYear)}")
    ## Next semester's six active terms
    nearFutureTerms.append(f"FA{str(currentYear)}")
    nearFutureTerms.append(f"GF{str(currentYear)}")
    nearFutureTerms.append(f"AF{str(currentYear)}")
    nearFutureTerms.append(f"SP{str(currentYear+1)}")
    nearFutureTerms.append(f"GS{str(currentYear+1)}")
    nearFutureTerms.append(f"AS{str(currentYear+1)}")

## The other months (September through December) is the Fall Term
else:
    ## Current semester's three active terms
    currentTerms.append(f"FA{str(currentYear)}")
    currentTerms.append(f"GF{str(currentYear)}")
    currentTerms.append(f"AF{str(currentYear)}")
    ## Next semester's six active terms
    nearFutureTerms.append(f"SP{str(currentYear+1)}")
    nearFutureTerms.append(f"GS{str(currentYear+1)}")
    nearFutureTerms.append(f"AS{str(currentYear+1)}")
    nearFutureTerms.append(f"SU{str(currentYear+1)}")
    nearFutureTerms.append(f"SG{str(currentYear+1)}")
    nearFutureTerms.append(f"SA{str(currentYear+1)}")

currentAndNearFutureTerms.extend(currentTerms)
currentAndNearFutureTerms.extend(nearFutureTerms)

## Define the current school year by whether it is before or during/after september
if f"FA{str(currentYear)}" in currentTerms:
    ## Fall terms are the first terms of a new school year so FA20 is part of the 2020-21 school year.
    currentSchoolYear = f"{currentYear}-{currentYear + 1}"
else:
    ## Spring and Summer terms belong in the same school year as the fall terms before them, so SP21 is part of the same 2020-21 school year as FA20.
    currentSchoolYear = f"{currentYear - 1}-{currentYear}"

## Relative Path (this changes depending on the working directory of the main script)
PFRelativePath = r".\\"

## If the Canvas directory is not in the folder the relative path points to
## find the Canvas directory and set the relative path to its parent folder
while "Scripts TLC" not in os.listdir(PFRelativePath):

    PFRelativePath = f"..\\{PFRelativePath}"

## Change the relative path to an absolute path
absolutePath = f"{os.path.abspath(PFRelativePath)}\\"

## Add Input Modules to the sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ResourceModules")

## Import local modules
from Error_Email_API import errorEmailApi
from Get_Enrollments import termGetEnrollments

## Local Path Variables
baseLogPath = f"{absolutePath}Logs\\{scriptName}\\"
baseLocalInputPath = f"{absolutePath}Canvas Resources\\{str(currentYear)}\\"  ## This is only the base path as the real path requires the requested term
baseLocalInputPathWithoutYear = f"{absolutePath}Canvas Resources\\"
outputPath = f"{absolutePath}Canvas Resources\\"
configPath = f"{absolutePath}Configs TLC\\"

## External Path Variables

## Define a variable to hold the base external input path which is where the sis input files are stored
SISResourcePath = None 
## Open External_Resource_Paths.json from the config path and get the SISResourcePath value
with open (f"{configPath}External_Resource_Paths.json", "r") as file:
    fileJson = json.load(file)
    SISResourcePath = fileJson["SISResourcePath"]

## If the base log path doesn't already exist, create it
if not (os.path.exists(baseLogPath)):
    os.makedirs(baseLogPath, mode=0o777, exist_ok=False)

## Final length of relative Path
relPathLen = len(PFRelativePath)

## Canvas Instance Url
coreCanvasApiUrl = None
## Open the Core_Canvas_Url.txt from the config path
with open (f"{configPath}Core_Canvas_Url.txt", "r") as file:
    coreCanvasApiUrl = file.readlines()[0]

## If the script is run as main the folder with the access token is in the parent directory
canvasAccessToken = ""

## Open and retrieve the Canvas Access Token
with open (f"{configPath}\Canvas_Access_Token.txt", "r") as file:
    canvasAccessToken = file.readlines()[0]

## Log configurations
logger = logging.getLogger(__name__)
rootFormat = ("%(asctime)s %(levelname)s %(message)s")
FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
logging.basicConfig(format=rootFormat, filemode = "a", level=logging.INFO)

## Info Log Handler
infoLogFile = f"{baseLogPath}\\Info Log.txt"
logInfo = logging.FileHandler(infoLogFile, mode = 'a')
logInfo.setLevel(logging.INFO)
logInfo.setFormatter(FORMAT)
localSetup.logger.addHandler(logInfo)

## Warning Log handler
warningLogFile = f"{baseLogPath}\\Warning Log.txt"
logWarning = logging.FileHandler(warningLogFile, mode = 'a')
logWarning.setLevel(logging.WARNING)
logWarning.setFormatter(FORMAT)
localSetup.logger.addHandler(logWarning)

## Error Log handler
errorLogFile = f"{baseLogPath}\\Error Log.txt"
logError = logging.FileHandler(errorLogFile, mode = 'a')
logError.setLevel(logging.ERROR)
logError.setFormatter(FORMAT)
localSetup.logger.addHandler(logError)

## Setup the error handler

errorHandler = errorEmailApi(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function handles function errors
def errorHandler.sendError (p1_ErrorLocation, p1_ErrorInfo, sendOnce = True):
    functionName = "errorHandler.sendError"
    localSetup.logger.error (f"     \nA script error occured while running {p1_ErrorLocation}. " +
                     f"Error: {str(p1_ErrorInfo)}")
    ## If the function with the error has not already been processed send an email alert
    if (p1_ErrorLocation not in setOfFunctionsWithErrors):
        errorEmailApi.sendEmailError(p2_ScriptName = scriptName, p2_ScriptPurpose = scriptPurpose, 
                                     p2_ExternalRequirements = externalRequirements, 
                                     p2_ErrorLocation = p1_ErrorLocation, p2_ErrorInfo = f"{p1_ErrorInfo}: \n\n {traceback.format_exc()}")
        setOfFunctionsWithErrors.add(p1_ErrorLocation)
        ## Note that an error email was sent
        localSetup.logger.error (f"     \nError Email Sent")
    ## Otherwise log the fact that an error email as already been sent
    else:
        localSetup.logger.error (f"     \nError email already sent")

def concludeEnrollments():
    functionName = "Conclude Enrollments"

    try:
        ## Define the header for all subsequent canvas api calls
        header = {'Authorization' : 'Bearer ' + canvasAccessToken}

        ## Open the instance level enrollment file
        enrollmentsDF = pd.read_csv(baseLocalInputPathWithoutYear + "Canvas_Enrollments.csv", dtype={"user_id": str,})

        ## Open the current sis to Canvas user file
        activeUsersDf = pd.read_csv(rf"{SISResourcePath}canvas_user.csv", dtype={"user_id": str,})

        ## Create a list of active user sis ids
        activeUsersSisIDList = []
        activeUsersSisIDList.extend(["697670", "509993", "60947", "405720", "389669","706696", "520094"])
        for index, row in activeUsersDf.iterrows():
            activeUsersSisIDList.append(str(row['user_id']))

        ## Save a list of the uncessary columnns in the enrollmentsDF
        enrollmentCsvColumnsToDrop = ["canvas_associated_user_id", "associated_user_id", "created_by_sis", "base_role_type", "limit_section_privileges"]
        
        ## Parse the enrollmentsDF and create an inactiveEnrollmentsDF that only has the records whose id's are not among the activeUsersIDList list
        moddedEnrollmentsDF = enrollmentsDF.drop(columns = enrollmentCsvColumnsToDrop, inplace=False)

        ## Remove enrollment records where Status is anything other than "active"
        moddedEnrollmentsDF = moddedEnrollmentsDF[moddedEnrollmentsDF["status"] == "active"]
        
        ## Create a list to hold the indexes of active user enrollments and those that have blank course ids
        inactiveCourseIndexList = []

        ## Create a dict to hold the canvas course ids and canvas user ids of enrollments with blank course sis ids
        blankCourseIDInactiveEnrollmentsList = []

        ## Define the current orientation course names to count their enrollments as active
        activeUndgOrientation = None
        if "SU" in currentTerms[0]:
            ## Summer does not have an active undg orientation so use the coming Fall orientation
            activeUndgOrientation = f"{nearFutureTerms[0][:2]}{currentYear}_TUG_Orientation"
        else:
            activeUndgOrientation = f"{currentTerms[0][:2]}{currentYear}_TUG_Orientation"
        ## The grad orientation is set by school year
        activeGradOrientation = f"{currentSchoolYear}_GPS_Orientation"
        undgTechOrientation = "NNU_IT_TECH_ORIENTATION"
        gradTechOrientation = "NNU_IT_Tech_Orientation_For_GPS_Students"

        ## Iterate through the enrollmentDF 
        for index, row in moddedEnrollmentsDF.iterrows():

            ## Save the row specific variables
            userID = row["user_id"]
            courseID = str(row["course_id"])
            enrollmentID = row["canvas_enrollment_id"]
            canvasCourseID = row["canvas_course_id"]

            ## Save a variable to track if the enrollment is in a current or future course
            currentOrFutureCourse = False

            for term in currentAndNearFutureTerms:
                if term in courseID:
                    currentOrFutureCourse = True
                    break

            if not currentOrFutureCourse:
                ## Check if the row's user id is in the active userSIS id List or if the target course is an active orientation
                ActiveUserEnrollment = userID in activeUsersSisIDList
                activeOrientationEnrollment = (
                    activeUndgOrientation in courseID
                    or activeGradOrientation in courseID
                    or undgTechOrientation in courseID
                    or gradTechOrientation in courseID
                )

                if not (ActiveUserEnrollment or activeOrientationEnrollment):
                
                    ## If the user is not active, check if the course_id is blank
                    if pd.isna(row["course_id"]) or pd.isna(row["user_id"]):

                        ##  If the course_id is blank, create a list with the canvas course id and user id, and append that list to the blank Course ID Inactive Enrollments List
                        blankCourseIDInactiveEnrollment = [canvasCourseID, enrollmentID]
                        blankCourseIDInactiveEnrollmentsList.append(blankCourseIDInactiveEnrollment)
                
                    else:

                        ##  If the course_id is not blank, add the index to the inactiveCourseIndexList
                        inactiveCourseIndexList.append(index)
        
        ## Create a inactive enrollment DF by dropping the enrollments for active users
        inactiveEnrollmentsDF = moddedEnrollmentsDF.loc[inactiveCourseIndexList]

        ## Set the status of all inactive enrollments to completed (concluded)
        inactiveEnrollmentsDF["status"] = "Completed"

        ## Save the inactive Enrollments DF as a csv file
        inactiveEnrollmentsDF.to_csv(f"{outputPath}Inactive_Enrollments.csv", index=False)

        ## Save the conclude enrollment SIS upload API URL
        concludeEnrollmentSisUploadApiUrl = f"{coreCanvasApiUrl}accounts/1/sis_imports"
        
        ##Save the conclude enrollment SIS upload payload
        concludeEnrollmentSisUploadPayload = {"attachment":f"{outputPath}Inactive_Enrollments.csv", "extension":"csv"}

        ## Make an API call to conclude the enrollment
        concludeEnrollmentSisUploadSectionObject = requests.post(concludeEnrollmentSisUploadApiUrl, headers = header)

        for enrollment in blankCourseIDInactiveEnrollmentsList:
            ## Save the specific course and user id
            canvasCourseId = enrollment[0]
            canvasEnrollmentId = enrollment[1]

            ## Save the conclude enrollment API URL
            concludeEnrollmentApiUrl = f"{coreCanvasApiUrl}courses/{canvasCourseId}/enrollments/{canvasEnrollmentId}"

            ## Make an API call to conclude the enrollment
            concludeEnrollmentSectionObject = requests.delete(concludeEnrollmentApiUrl, headers = header)





    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":

    ## Start and download the Canvas report
    concludeEnrollments ()

    input("Press enter to exit")

else:
    ## If an argument was given use that as the input term
    
    if len(sys.argv) == 1:

        ## Start and download the Canvas report
        concludeEnrollments(inputTerm = "")


## ===========================================================================
## FILE: ReportModules\Incoming_Student_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

from datetime import datetime
import paramiko, traceback,  os, logging, sys, requests, json, re, threading, time
import pandas as pd ##External Download from https://pypi.org/project/pandas/
import numpy as np

## Add ResourceModules to the system path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

## New resource modules
from Local_Setup import LocalSetup
from TLC_Common import makeApiCall
from Canvas_Report import CanvasReport
from Common_Configs import coreCanvasApiUrl, canvasAccessToken, undgTermsCodesToWordsDict, gradTermsCodesToWordsDict
from Error_Email import errorEmail
from Get_Slate_Info import getSlateInfo

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
This script (Incoming_Student_Report) connects to the NNU's primary Canvas instance and gets the last login date
for the students on Slates Incoming student list (retrieved through the Get_Slate_Info script)
"""
externalRequirements = r"""
To function properly this script requires access to the institutions Canvas instance via an Active Canvas Bearer Token
"""

## Create the localsetup variable
localSetup = LocalSetup(datetime.now(), __file__)  ## sets cwd, paths, logs, date parts

## Setup the error handler
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function gets the incoming student info for a given row in the slate data df
def getTargetIncomingStudentInfo (row
                            , rowIndex
                            , p2_inputTerm
                            , p1_targetOrientation
                            , p1_targetOrientationStudents
                            , p1_targetOrientationSections
                            , p1_targetOrientationFinalQuizSubmissionDatesAndIds
                            , p1_orientationCourseApiUrl
                            , p1_header
                            , targetSlateDataDF
                            , p1_sisFeedCoursesDf
                            , p1_sisFeedEnrollmentDf
                            , p1_enrollmentDataActivityDF
                            ):
    functionName = "Get Incoming Student Info"

    try:
        
        indivigualOrientationDepartments = ["Business", "Education", "Theology", "Social Work", "Accounting", "Divinity", "Pastoral", "Spiritual", "Missional", "Family Ministry:"]
        indivigualOrientationDepartmentExceptions = ["Christian Ministry:", " AA", "Liberal Studies", "Nursing"]
    
        ## Create a variable to track whether the user is already enrolled in a orientation course
        userEnrolledInOrientation = False
        
        ## Get the student ID and major from the row
        studentSisId = row['StudentID']
        studentMajor = row['Major_Name']
        studentSectionSisId = f"{p1_targetOrientation}: {studentMajor}"
        studentOrientationSectionSisId = f"{p1_targetOrientation}: {p2_inputTerm}"

        ## Define a variable to hold the legacy departmentException
        departmentException = False

        ## Check if the user is has a major that has its own orientation
        if "GPS" in p1_targetOrientation and p2_inputTerm in ["SP25", "GS25", "SU25", "SG25"]:
            for major in indivigualOrientationDepartmentExceptions:
                if major in studentMajor:
                    departmentException = True
            for major in indivigualOrientationDepartments:
                if major in studentMajor and not departmentException:
                    userEnrolledInOrientation = True
                    break

        ## Get the user's username, email, and last login date
        ## Define the url to get the user data
        userApiUrl = f"{coreCanvasApiUrl}users/sis_user_id:{studentSisId}"

        ## Define the playload for the user payload
        userPayload = {"include[]":["last_login"]}

        ## Define a variable to hold the user's Canvas id
        userCanvasId = None

        ## Make a user api call
        userObject = requests.get(userApiUrl, headers = p1_header, params = userPayload)

        if (userObject.status_code == 200):

            ## Turn the user api result into a dictionary
            user_jsonString = userObject.text
            user_jsonObject = json.loads(user_jsonString)

            ## Save the users canvas id
            userCanvasId = user_jsonObject["id"]

            ## Save the user's email
            userEmail = user_jsonObject["email"]

            ## If there is not a user email but the login_id has @ in it
            if not userEmail and "@" in user_jsonObject["login_id"]: 

                ## Record the login_id as the email
                userEmail = user_jsonObject["login_id"]

            ## If they have an nnu email, record their username, and their last login date if it isn't blank
            if userEmail and "nnu.edu" in userEmail:
                userUsername = user_jsonObject["login_id"]
                userLastLoginDate = user_jsonObject["last_login"]

                targetSlateDataDF.loc[rowIndex, "NNU Username"] = userUsername
                targetSlateDataDF.loc[rowIndex, "Last Login Date"] = userLastLoginDate
                if userLastLoginDate:
                    targetSlateDataDF.loc[rowIndex, "Last Login Date Yes/No"] = "Yes"

                localSetup.logger.info (f"{studentSisId} data saved")

            ## Otherwise
            else:

                ## The user does not have a valid nnu email/username, so return
                localSetup.logger.info (f"{studentSisId} does not have a valid NNU email/username")
                return

        else:
            localSetup.logger.info (f"{studentSisId} not in Canvas")
            return

        ## Define a variable to track whether the user is already enrolled in the target orientation
        if str(studentSisId) in p1_targetOrientationStudents:
            userEnrolledInOrientation = True

        ## Enroll the student in the relavent orientation if they are not already enrolled in one
        if userEnrolledInOrientation == False:

            ## Define a variable to track whether the section for the student's orientation section already exists
            orientationSectionExists = False

            ## Define a variable to track whether the section for the student's major already exists
            majorSectionExists = False

            ## For each section in the target orientation sections
            for section in p1_targetOrientationSections:

                ## If not section["sis_section_id"]
                if not section["sis_section_id"]:

                    ## Skip to the next section
                    continue

                ## If the student's major is in the section's name
                if studentSectionSisId in section["sis_section_id"]:

                    ## If the section's sis_section_id matches the student's section sis id
                    majorSectionExists = True

                ## If the section's sis_section_id matches the student's orientation section sis id
                if studentOrientationSectionSisId == section["sis_section_id"]:

                    ## Set the orientation section exists variable to true
                    orientationSectionExists = True

                ## If both the orientation section and the major section already exist, break the loop
                if orientationSectionExists and majorSectionExists:
                    break

            ## If the orientation section doesn't already exist
            if not orientationSectionExists:

                ## Create the api url for creating a new section
                createOrientationSectionApiUrl = f"{p1_orientationCourseApiUrl}/sections"

                ## Define the payload to create the new section
                createOrientationSectionPayload = {"course_section[name]": [studentOrientationSectionSisId], "course_section[sis_section_id]": [studentOrientationSectionSisId]}

                ## Make the api call to create the new section
                createOrientationSectionObject = requests.post(createOrientationSectionApiUrl, headers = p1_header, params = createOrientationSectionPayload)
                
            ## If it a section for that major doesn't already exists
            if not majorSectionExists:
                createSectionApiUrl = f"{p1_orientationCourseApiUrl}/sections"

                createSectionPayload = {"course_section[name]": [studentMajor], "course_section[sis_section_id]": [studentSectionSisId]}

                createSectionObject = requests.post(createSectionApiUrl, headers = p1_header, params = createSectionPayload)
        
            ## Create the URLs for the API call will be made to
            enrollApiUrl = f"{p1_orientationCourseApiUrl}/enrollments"
            enrollOrientationSectionApiUrl = f"{coreCanvasApiUrl}/sections/sis_section_id:{studentOrientationSectionSisId}/enrollments"
            enrollMajorSectionApiUrl = f"{coreCanvasApiUrl}sections/sis_section_id:{studentSectionSisId}/enrollments"


            ## Define the canvas api viarables
            enrollPayload = {"enrollment[user_id]":f"sis_user_id:{studentSisId}", "enrollment[type]":"StudentEnrollment", "enrollment[enrollment_state]":"active"}

            ## Make the API call to enroll the student Error
            enrollObject = requests.post(enrollApiUrl, headers = p1_header, params = enrollPayload)
            enrollOrientationSectionObject = requests.post(enrollOrientationSectionApiUrl, headers = p1_header, params = enrollPayload)
            enrollMajorSectionObject = requests.post(enrollMajorSectionApiUrl, headers = p1_header, params = enrollPayload)

            ## If the enrollment was successful
            if enrollObject.status_code == 200 and enrollOrientationSectionObject.status_code == 200 and enrollMajorSectionObject.status_code == 200:

                ## Log the successful enrollment
                localSetup.logger.info (f"{studentSisId} enrolled in {p1_targetOrientation}")

            ## Otherwise, if the enrollment failed
            else:

                ## If the first enrollment attempt failed, log the error and return
                if enrollObject.status_code != 200:
                    localSetup.logger.error (f"{studentSisId} enrollment in {p1_targetOrientation} failed: {enrollObject.text}")

                ## If the second enrollment attempt failed, log the error and return
                if enrollOrientationSectionObject.status_code != 200:
                    localSetup.logger.error (f"{studentSisId} enrollment in {p1_targetOrientation} failed: {enrollOrientationSectionObject.text}")
                
                ## If the third enrollment attempt failed, log the error and return
                if enrollMajorSectionObject.status_code != 200:
                    localSetup.logger.error (f"{studentSisId} enrollment in {p1_targetOrientation} failed: {enrollMajorSectionObject.text}")

                ## Send out an error email
                errorHandler.sendError(f"{scriptName} - {functionName}", f"Error enrolling {studentSisId} in {p1_targetOrientation}", sendOnce = True)

                return

        ## If the user has been enrolled in their orientation 
        else:
            ## And exists in the target oriention
            if studentSisId in p1_targetOrientationFinalQuizSubmissionDatesAndIds:
                ## Check if they took the final quiz and record the date it was taken if possible
                if p1_targetOrientationFinalQuizSubmissionDatesAndIds[studentSisId]:
                    targetSlateDataDF.loc[rowIndex, "Final Quiz Date Taken"] = p1_targetOrientationFinalQuizSubmissionDatesAndIds[studentSisId]
                    targetSlateDataDF.loc[rowIndex, "Final Quiz Date Taken Yes/No"] = "Yes"

            ## Create a target enrollment df by filtering by the student's sis id and the status of the enrollment
            targetEnrollmentsDF = p1_sisFeedEnrollmentDf[(p1_sisFeedEnrollmentDf['user_id'] == studentSisId) & (p1_sisFeedEnrollmentDf['status'] == "active")]        
            
            ## Create a target course df by filtering by the list of course sis ids within the target enrollment df
            targetCoursesDF = p1_sisFeedCoursesDf[p1_sisFeedCoursesDf['course_id'].isin(targetEnrollmentsDF['course_id'])]
            
            ## Convert the 10 day point to a date
            pd.to_datetime(targetCoursesDF['10_day_point']).dt.date
            
            ## Make a list of the unique tenth day point values
            tenthDayPointList = targetCoursesDF['10_day_point'].unique()

            ## Define a variable to hold the most recent tenth day point
            mostRecentTenthDayPoint = None
            
            ## For each tenth day point
            for tenthDayPoint in tenthDayPointList:

                ## Convert tenthDayPoint to a date if it's a Timestamp
                if isinstance(tenthDayPoint, pd.Timestamp):
                    tenthDayPoint = tenthDayPoint.date()
    
                ## Check if the tenth day point has passed
                if tenthDayPoint <= localSetup.initialDateTime.date():
        
                    ## If the most recent tenth day point is None or the current tenth day point is greater than the most recent
                    if mostRecentTenthDayPoint is None or tenthDayPoint > mostRecentTenthDayPoint:
            
                        ## Set the most recent tenth day point to the current tenth day point
                        mostRecentTenthDayPoint = np.datetime64(tenthDayPoint)
                        
            ## Make a df of the courses whose tenth day point matches the most recent tenth day point
            mostRecentTenthDayCoursesDF = targetCoursesDF[targetCoursesDF['10_day_point'] == mostRecentTenthDayPoint]
            
            ## Create a target data activity df by filtering by the student's sis id
            targetDataActivityDF = p1_enrollmentDataActivityDF[p1_enrollmentDataActivityDF['Student ID'] == studentSisId]

            ## Create a yes/no variable to track whether the student has on or after the most recent tenth day of a course they are enrolled in
            hasParticipatedAfterTenthDay = ""

            ## If the targetDataActivityDF is not empty
            if not targetDataActivityDF.empty:

                ## For each course in the most recent tenth day courses df
                for index, row in mostRecentTenthDayCoursesDF.iterrows():

                    ## Create a target data activity df by filtering by the course id
                    targetDataActivityCourseDF = targetDataActivityDF[targetDataActivityDF['Course Number'] == row['course_id'].replace('_', '-')]

                    ## If the targetDataActivityCourseDF is not empty and the row's activity date is not NaT
                    if not targetDataActivityCourseDF.empty and not pd.isnull(targetDataActivityCourseDF['Last Course Participation'].values[0]):

                        ## Convert the last course participation date to a date
                        targetCourseLastParticipationDate = datetime.strptime(f"{str(localSetup.dateDict['year'])}-{targetDataActivityCourseDF['Last Course Participation'].values[0]}", '%Y-%m-%d').date()

                        ## If the row's activity date is equal to or after the most recent tenth day point
                        if targetCourseLastParticipationDate >= mostRecentTenthDayPoint:

                            ## Set the has participated after tenth day variable to yes
                            hasParticipatedAfterTenthDay = "Yes"
                            break

            ## If the has participated after tenth day variable is still blank and the mostRecentTenthDayPoint is not None
            if hasParticipatedAfterTenthDay == "" and mostRecentTenthDayPoint is not None:

                ## If the targetDataActivityDF not empty
                if not targetDataActivityDF.empty:
                    
                    ## Set the has participated after tenth day variable to no
                    hasParticipatedAfterTenthDay = "No"

            ## Set the Student Participated On Or After 10 Days (Y/N) value in the target slate data df to the has participated after tenth day value
            targetSlateDataDF.loc[rowIndex, "Student Participated On Or After 10 Days (Y/N)"] = hasParticipatedAfterTenthDay        

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

def studentTypeGetIncomingStudentsInfo(p1_targetOrientation, p1_slateFile, p1_inputTerm):
    functionName = "Term Get Incoming Undergrad Student Info"

    try:

        ## Define the current slateFileName and slateFilePath
        slateFileName = p1_slateFile.split('\\')[-1]
        slateFilePath = p1_slateFile.replace(slateFileName, "")

        ## Define the target file ougoing output path
        outgoingTermInputPath = slateFilePath.replace("Incoming", "Outgoing")

        
 
        ## If the outgoingTermInputPath doesn't already exist, create it
        if not (os.path.exists(outgoingTermInputPath)):
            os.makedirs(outgoingTermInputPath, mode=0o777, exist_ok=False)
 
        ## Define the updated slate file name and path with name
        updatedFileName = slateFileName.replace(".csv", "") + '_canvas_data.csv'
        updatedSlateFilePathWithName = outgoingTermInputPath + updatedFileName
        
    
        ## If the file exists
        if os.path.exists(updatedSlateFilePathWithName):
            
            ## Get its last moddifed timestamp
            targetFileTimestamp = os.path.getmtime(updatedSlateFilePathWithName)

            ## Convert the timestamp to datetime
            targetFileDateTime = datetime.fromtimestamp(targetFileTimestamp)

            ## Subtract the file's datetime from the current datetime
            targetFileHoursOld = int((localSetup.initialDateTime - targetFileDateTime).total_seconds() // 3600)

            ## If it has been less than 3 and a half hours since the target was updated
            if targetFileHoursOld < 3.5:

                ## localSetup.logger.info that the file is up to date and return
                localSetup.logger.info (f"     \n {updatedSlateFilePathWithName} is up to date")
                return

        ## Define the p1_header for all subsequent canvas api calls
        header = {'Authorization' : 'Bearer ' + canvasAccessToken}

        ## Retrieve (and update if neccessary) the term relavent canvas courses file path
        orientationCourseTermLocationDf = CanvasReport.getCoursesDf(localSetup, "All")

        nameTarget = 'name'
        ## If neither column nor index has 'name' set the name target to long_name
        if 'name' not in orientationCourseTermLocationDf.columns and 'name' not in orientationCourseTermLocationDf.index.names:
            nameTarget = 'long_name'


        ## Find the "canvas_course_id" by looking for the target orientation sis id in "course_id"targetCourseLastParticipationDate = datetime.strptime(f"{str(localSetup.dateDict[
        targetOrientationCanvasCourseId = None
        try: ## Irregular try clause, do not comment out in testing
            targetOrientationCanvasCourseId = orientationCourseTermLocationDf.loc[orientationCourseTermLocationDf[nameTarget] == p1_targetOrientation, 'canvas_course_id'].values[0]
        except: ## Irregular except clause, do not comment out in testing
            localSetup.logger.error(f"Could not find Canvas Course ID for orientation course with SIS ID: {p1_targetOrientation}")
         
        ## Define the orientation course's base api url
        orientationCourseApiUrl = f"{coreCanvasApiUrl}courses/{targetOrientationCanvasCourseId}"
        
        ## Define the url to get the course's students
        orientationCourseUserApiUrl = f"{orientationCourseApiUrl}/users"
         
        ## Define the payload to get the course's students
        orientationCourseUserPayload = {"enrollment_type[]":["student"], "per_page": 100}

        ## Make the course enrollment list
        orientationCourseEnrollmentObject = requests.get(orientationCourseUserApiUrl, headers = header, params = orientationCourseUserPayload)

        ## Save the result as a list of dicts for each student enrolled
        p1_targetOrientationStudentObjects = orientationCourseEnrollmentObject.json()

        ## If there are more pages to the enrollment response get them as well
        while "next" in orientationCourseEnrollmentObject.links:
            nextOrientationPageUrl = orientationCourseEnrollmentObject.links["next"]["url"]
            orientationCourseEnrollmentObject = requests.get(nextOrientationPageUrl, headers=header)  ## Fetch the next page
            nextOrientationPage_jsonObject = orientationCourseEnrollmentObject.json()
            p1_targetOrientationStudentObjects.extend(nextOrientationPage_jsonObject)  ## Collect students and add them to the first orientationCourse_jsonObject

        ## Record the student's ids
        p1_targetOrientationStudents = []

        for studentObject in p1_targetOrientationStudentObjects:
            try: ## Irregular except clause, don't comment out in testing
                p1_targetOrientationStudents.append(studentObject["sis_user_id"])
            except: ## Irregular except clause, don't comment out in testing
                ## Primary exception is when the sis_user_id isn't an int 
                #which indicts they aren't a regular incoming student and so can be skipped
                continue 

        localSetup.logger.info ("Target Orientation Students recorded")

        ## Define the api url to get the target's sections
        orientationCourseSectionApiUrl = f"{orientationCourseApiUrl}/sections"

        ## Make the target section call
        orientationCourseSectionObject = requests.get(orientationCourseSectionApiUrl, headers = header)

        ## Define a variable to hold the target orientation's sections
        p1_targetOrientationSections = orientationCourseSectionObject.json()

        localSetup.logger.info ("Target Orientation Sections recorded")

        ## Make an api call to get a list of user sis ids for those that have submitted the final quiz and when they took it
        ## This marks the completion of the orientation
        p1_targetOrientationFinalQuizSubmissionDatesAndIds ={}

        ## Define the core new quiz url to get a list of the courses quizzes
        newQuizCoreUrl = coreCanvasApiUrl.replace("api/v1", "api/quiz/v1")

        ## Define the course specific api new quiz url
        quizListApiUrl = f"{coreCanvasApiUrl}courses/{targetOrientationCanvasCourseId}/quizzes"

        ## Make the new quiz list api call
        quizzListObject = requests.get(quizListApiUrl, headers = header)

        ## Turn the quizzes list api result into a dictionary
        quizzList_jsonString = quizzListObject.text
        quizzList_jsonObject = json.loads(quizzList_jsonString)

        ## Find the orientation quiz id and assignment id if they exist
        targetQuizID = None
        targetQuizAssignmentId = None
        for quiz in quizzList_jsonObject:
            if "orientation" in quiz["title"].lower() or "student hub" in quiz["title"].lower():
                targetQuizID = quiz["id"]
                targetQuizAssignmentId = quiz["assignment_id"] if quiz["assignment_id"] else quiz["id"]
                break

        ## If the orientation quiz still hasn't been found
        if not targetQuizID:
    
            ## : again with the new quiz url
            quizListApiUrl = f"{newQuizCoreUrl}/courses/{targetOrientationCanvasCourseId}/quizzes"

        ## Make the new quiz list api call
        quizzListObject = requests.get(quizListApiUrl, headers = header)
    
        ## Turn the quizzes list api result into a dictionary
        quizzList_jsonString = quizzListObject.text
        quizzList_jsonObject = json.loads(quizzList_jsonString)
    
        ## Find the orientation quiz id if it exists
        for quiz in quizzList_jsonObject:
            if "orientation" in quiz["title"].lower():
                targetQuizID = quiz["id"]
                targetQuizAssignmentId = quiz["id"]
                break

        ## Get the submissions for the quiz
        if targetQuizID:
    
            ## Create a variable to hold the api url for the quiz submission list
            quizSubmissionListApiUrl = None

            ## If api/quiz/v1 was used to get the quiz id
            if "api/quiz/v1" in quizListApiUrl:

                ## Set the submissin list api url to use the assignments path
                quizSubmissionListApiUrl = f"{coreCanvasApiUrl}courses/{targetOrientationCanvasCourseId}/assignments/{targetQuizAssignmentId}/submissions"

            ## Otherwise 
            else:
        
                ## Use the quizzes path
                quizSubmissionListApiUrl = f"{coreCanvasApiUrl}courses/{targetOrientationCanvasCourseId}/quizzes/{targetQuizID}/submissions"

        ## Define the playload for the submission list
        quizSubmissionPayload = {"include[]":["user"], "per_page": 100}

        ## Make the submission list api call
        quizzSubmissionsObject = requests.get(quizSubmissionListApiUrl, headers = header, params = quizSubmissionPayload)

        ## Turn the quizzes list api result into a dictionary
        quizzSubmissionsList_jsonString = quizzSubmissionsObject.text
        quizzSubmissionsList_jsonObject = json.loads(quizzSubmissionsList_jsonString)

        ## If there are more pages to the submission response get them as well
        while "next" in quizzSubmissionsObject.links:
            nextSubmissionPageUrl = quizzSubmissionsObject.links["next"]["url"]
            quizzSubmissionsObject = requests.get(nextSubmissionPageUrl, headers=header)  ## Fetch the next page
            nextSubmissionsPage_jsonObject = quizzSubmissionsObject.json()
            
            ## Iterate through the keys and values of nextSubmissionsPage_jsonObject
            for key, value in nextSubmissionsPage_jsonObject.items():
                
                ## If the key exists in the original json object
                if key in quizzSubmissionsList_jsonObject:
                    
                    ## If both values are lists
                    if isinstance(quizzSubmissionsList_jsonObject[key], list) and isinstance(value, list):

                        ## Extend the list to include the new values
                        quizzSubmissionsList_jsonObject[key].extend(value)
                
                ## Otherwise
                else:
                    
                    ## If the key does not exist in both, add the key-value pair
                    quizzSubmissionsList_jsonObject[key] = value


        ## If quiz_submissions and users are both inthe json object's keys
        if "quiz_submissions" in quizzSubmissionsList_jsonObject.keys() and "users" in quizzSubmissionsList_jsonObject.keys():

            ## for each user and submission in a zipped list of the two dicts
            for user, submission in zip(quizzSubmissionsList_jsonObject["users"], quizzSubmissionsList_jsonObject["quiz_submissions"]):

                ## If the user has a sis_user_id
                if user["sis_user_id"]:

                    ## attempt to save the user's sis_user_id and the submission's submitted_at date
                    try: ## Irregular try clause, do not comment out in testing
                
                        p1_targetOrientationFinalQuizSubmissionDatesAndIds[int(user["sis_user_id"])] = submission['finished_at']
                    
                    ## If there wasn't a finished at value
                    except: ## Irregular except clause, do not comment out in testing
                    
                        ## Set the value as "Ongoing"
                        p1_targetOrientationFinalQuizSubmissionDatesAndIds[int(user["sis_user_id"])] = "Ongoing"
                    

        ## Otherwise
        else:         
            ## Just get both from the submission list
            for submission in quizzSubmissionsList_jsonObject:
                if submission["user"]["sis_user_id"]:
                    p1_targetOrientationFinalQuizSubmissionDatesAndIds[int(submission["user"]["sis_user_id"])] = submission['submitted_at']

        localSetup.logger.info ("Target Orientation Submissions recorded")
 
        ## Read the current Slate 
        slateDataDF = pd.read_csv(p1_slateFile, converters = {"SlateID": str, "SlateAppID": str})
 
        ## Add columns for the username, last login date, and final quiz taken date
        slateDataDF["NNU Username"] = ""
        slateDataDF["Last Login Date"] = pd.NaT
        slateDataDF["Last Login Date Yes/No"] = "No"
        slateDataDF["Final Quiz Date Taken"] = pd.NaT
        slateDataDF["Final Quiz Date Taken Yes/No"] = "No"

        ## Open the current SIS Feed Enrollment and Course CSVs
        rawSisFeedEnrollmentDf = pd.read_csv(f"{localSetup.getExternalResourcePath('SIS')}canvas_enroll.csv")
        rawSisFeedCourseDf = pd.read_csv(f"{localSetup.getExternalResourcePath('SIS')}canvas_course.csv")
        
        ## Filter the SIS Feed Enrollment DF to only contain students
        sisFeedEnrollmentDf = rawSisFeedEnrollmentDf[rawSisFeedEnrollmentDf['role'] == "student"]

        ## Define the target term as undergrad or grad according to the target orientation
        targetTerm = p1_inputTerm if "TUG" in p1_targetOrientation else p1_inputTerm.replace('FA', 'GF').replace('SP', 'GS')

        ## Filter the SIS Feed Course DF to only contain the input term and the grad version of the input term
        sisFeedCourseDf = rawSisFeedCourseDf[(rawSisFeedCourseDf['term_id'] == targetTerm)]
        
        ## Add a start/end combination column to the target course df
        sisFeedCourseDf['start/end'] = sisFeedCourseDf['start_date'] + "/" + sisFeedCourseDf['end_date']

        ## Add a 10 day point column to the target course df by adding 31 days to the start date (start dates are always set 3 weeks before the official start date)
        sisFeedCourseDf['10_day_point'] = pd.to_datetime(sisFeedCourseDf['start_date']) + pd.DateOffset(days=31)
        
        ## Make a dict with the unique start/end values as the keys and a list with the start_at and end_at values as the values
        startEndDict = sisFeedCourseDf.groupby('start/end').agg({'start_date': 'first', 'end_date': 'first'}).to_dict(orient='index')

        ## Open up the enrollment data activity file
        enrollmentDataActivityDF = pd.read_csv(f"{localSetup.getExternalResourcePath('SIS')}output\\pharos\\Enrollment_Data_Activity.csv", delimiter='|')
 
        ongoingStudentThreads = []

        ## Define input threading objects
        for index, row in slateDataDF.iterrows():

            ##if row['StudentID'] == 190996:

                newThread = threading.Thread(target=getTargetIncomingStudentInfo
                                             , args=(row
                                                     , index
                                                     , p1_inputTerm
                                                     , p1_targetOrientation
                                                     , p1_targetOrientationStudents
                                                     , p1_targetOrientationSections
                                                     , p1_targetOrientationFinalQuizSubmissionDatesAndIds
                                                     , orientationCourseApiUrl
                                                     , header
                                                     , slateDataDF
                                                     , sisFeedCourseDf
                                                     , sisFeedEnrollmentDf
                                                     , enrollmentDataActivityDF
                                                     )
                                             )
                newThread.start()
                ongoingStudentThreads.append(newThread)
                time.sleep(1)
 
        ## Check if all ongoing input threads have completed
        for thread in ongoingStudentThreads:
            thread.join()

        ## Save the updated slate undergrad data DF
        slateDataDF.to_csv(updatedSlateFilePathWithName, index=False)

        ## Define a veriable to hold the slate creds json file
        slateCreds = None

        ## Open the slate creds json file from the localSetup.configPath
        with open(os.path.join(localSetup.configPath, "Slate_Creds.json"), "r") as file:

            ## Load the json file
            slateCreds = json.load(file)

        ## Define the slate creds
        ASHost = slateCreds["ASHost"]
        ASPort = slateCreds["ASPort"]
        ASUsername = slateCreds["ASUsername"]
        ASPassword = slateCreds["ASPassword"]
        ASPublicKeyPath = os.path.join(localSetup.configPath, "Slate_Public_Key.txt")
 
        ## Create an SSH client
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        ## Define an attempt counter
        attemptCounter = 0

        ## Define a variable to hold the connection status
        connected = False

        ## While the connection is not established
        while not connected:
            ## try to connect to the SFTP server
            try: ## Irregular except clause, do not comment out in testing
                ## Connect to the SFTP server
                ssh_client.connect(hostname=ASHost, port=ASPort, username=ASUsername, password=ASPassword, key_filename=ASPublicKeyPath)##, command=ASCommandLine)
                connected = True
            ## If the connection fails
            except Exception as Error: ## Irregular except clause, do not comment out in testing
                ## Log the error
                localSetup.logger.error (f"     \nError connecting to SFTP server: {Error}")
                ## Increment the attempt counter
                attemptCounter += 1
                ## If the attempt counter is greater than 3
                if attemptCounter > 3:
                    ## Log the fact that the connection failed
                    localSetup.logger.error (f"     \nFailed to connect to SFTP server after 3 attempts")
                    ## Break the loop
                    break
                ## Otherwise
                else:
                    ## Log that the connection will be attempted again
                    localSetup.logger.error (f"     \nAttempting to connect to SFTP server again")
                    ## Wait 5 seconds
                    time.sleep(5)
 
        ## Create an SFTP client from the SSH client
        sftp_client = ssh_client.open_sftp()
 
        updatedSlateDataFile_remote_file_path = None
 
        ## Specific the path for the file to be saved to
        if "prof" in p1_slateFile:
            updatedSlateDataFile_remote_file_path = f'./Incoming//Canvas//Prof_progs_canvas_data.csv'
        elif "grad" in p1_slateFile:
            updatedSlateDataFile_remote_file_path = f'./Incoming//Canvas//Graduate_canvas_data.csv'
        else:
            updatedSlateDataFile_remote_file_path = f'./Incoming//Canvas//Undergrad_canvas_data.csv'

        try: ## Irregular try clause, do not comment out in testing
            ## Upload the file
            sftp_client.put(updatedSlateFilePathWithName, updatedSlateDataFile_remote_file_path)
            localSetup.logger.info("File uploaded successfully.")
        finally:
            ## Close the SFTP client and SSH connection
            sftp_client.close()
            ssh_client.close()
 
    except Exception as Error:
        errorHandler.sendError(functionName, Error)

def termGetIncomingStudentsInfo(inputTerm = ""):
    functionName = "Term Get Incoming Student Information"

    try:
        ## Extract term code prefix and decade
        termCodePrefix = inputTerm[:2]  ## ## e.g., "FA", "SP", "SU"

        ## Convert term code to word using your new dictionary
        termWord = gradTermsCodesToWordsDict[termCodePrefix] if termCodePrefix in gradTermsCodesToWordsDict.keys() else undgTermsCodesToWordsDict[termCodePrefix]

        ## Use LocalSetup to get the school year dynamically
        targetSchoolYear = localSetup.getSchoolYear(termWord, int(str(localSetup.dateDict['century']) + str(inputTerm[2:])))

        ## Define the incoming School Year input path
        incomingSchoolYearInputPath = os.path.join(localSetup.getInternalResourcePaths("Slate"), targetSchoolYear)

        ## If the term is Summer, change it to Spring (orientation logic)
        if termCodePrefix == "SU":
            inputTerm = inputTerm.replace("SU", "SP")
   
        ## Define a variable to hold the target orientation course name
        targetOrientation = None

        ## If the input term is undg
        if termCodePrefix in undgTermsCodesToWordsDict.keys():
            
            ## Set the target orientation to the undergraduate orientation course    
            targetOrientation = f"{termWord} {str(localSetup.dateDict['year'])} - NNU Pre-Launch Orientation"

        ## Otherwise
        else:
            
            ## Set the target orientation to the graduate/professional orientation course
            targetOrientation = f"Graduate & Professional Student Hub"

        ## Define the term specific output path
        incomingTermInputPath = os.path.join(incomingSchoolYearInputPath, inputTerm, "Incoming")

        ## If the incomingTermInputPath doesn't already exist, create it
        if not (os.path.exists(incomingTermInputPath)):
            os.makedirs(incomingTermInputPath, mode=0o777, exist_ok=False)

        ## Get a list of the files from slate and work through them
        slateFiles = getSlateInfo(inputTerm)

        ## If there are no files in slate files list
        if not slateFiles:

            ## Log that there are no files in the slate files list
            localSetup.logger.info ("No files in slate files to process")
            return

        ## Define a list to hold the subsequent threads used to work through the files from slate
        ongoingReportThreads = []

        ## For each file from slate
        for slateFile in slateFiles:

            ##studentTypeGetIncomingStudentsInfo (targetGradOrientation, slateFile, inputTerm)
           
            ## Define the get student info report thread
            getStudentInfoThread = None
            
            ## If the target slate file contains graduate students or professional students and the target orientation is a graduate or professional course
            if ("grad" in slateFile or "prof" in slateFile) and ("Grad" in targetOrientation or "GPS" in targetOrientation):
                
                ## Target the graduate orientation course/s
                getStudentInfoThread = threading.Thread(target=studentTypeGetIncomingStudentsInfo, args=(targetOrientation, slateFile, inputTerm))

            ## If the target slate file contains undergraduate students and the target orientation is an undergraduate course
            elif "conf" in slateFile and "Launch" in targetOrientation:

                ## Target the undergraduate orientation course
                getStudentInfoThread = threading.Thread(target=studentTypeGetIncomingStudentsInfo, args=(targetOrientation, slateFile, inputTerm))

            ## If a threading object was created
            if getStudentInfoThread:

                ## Start the get student info report thread
                getStudentInfoThread.start()

                ## Add the get student info report thread to the ongoingReportThreads list
                ongoingReportThreads.append(getStudentInfoThread)

        ## Wait for all of the ongoingReportThreads to finish
        for thread in ongoingReportThreads:
            thread.join()

        ## Define the outgoing term input path
        outgoingTermInputPath = incomingTermInputPath.replace("Incoming", "Outgoing")
        os.makedirs(outgoingTermInputPath, mode=0o777, exist_ok=True)

        ## Define a verible to hold the names of the ougoing term input files
        outgoingTermInputFiles = os.listdir(outgoingTermInputPath)

        ## For each file in the outgoing term input path
        for slateFile in outgoingTermInputFiles:

            ## If the file is not contained in any of the slate file paths
            if not any(slateFile.replace('_canvas_data', '') in filePath.split('\\')[-1] for filePath in slateFiles):

                ## Delete the file
                os.remove(os.path.join(outgoingTermInputPath,slateFile))


    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":

    ## Start and download the Canvas report
    termGetIncomingStudentsInfo (inputTerm = input("Enter the desired term in \
four character format (FA20, SU20, SP20): "))

    input("Press enter to exit")


## ===========================================================================
## FILE: ReportModules\Nighthawk_360_Canvas_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## External libraries
import os, sys, json, pandas as pd, shutil, time, threading
from datetime import datetime, timedelta

## Add ResourceModules to the system path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

## New resource modules
from Local_Setup import LocalSetup
from TLC_Common import makeApiCall
from Canvas_Report import CanvasReport
from Common_Configs import coreCanvasApiUrl, canvasAccessToken
from Error_Email import errorEmail

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
Retrieve enrolled student's course level grade and activity information
"""
externalRequirements = r"""
To function properly, this script requires access to NNU's current enrollment list, the the corresponding Canvas enrollment list, Canvas API
and the "{SISResourcePath}\\output\\pharos" folder
"""

## Create the localsetup variable
localSetup = LocalSetup(datetime.now(), __file__)  ## sets cwd, paths, logs, date parts

## Setup the error handler
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function recursively parses discussion post replies to search for a particular user's latest reply
def getStuMostRecentGradedDiscussionPostDateRecursive(p2_stuCanvasId, p1_stuLastGradedDiscussionPostDate, p1_post):
    functionName = "Get a Student's Most Recent Graded Discussion Post Date Recursive"
    if "replies" in p1_post:
        for reply in p1_post["replies"]:
            if reply.get("user_id") == p2_stuCanvasId:
                if not p1_stuLastGradedDiscussionPostDate or p1_stuLastGradedDiscussionPostDate < reply["updated_at"]:
                    p1_stuLastGradedDiscussionPostDate = reply["updated_at"]
                getStuMostRecentGradedDiscussionPostDateRecursive(p2_stuCanvasId, p1_stuLastGradedDiscussionPostDate, reply)

## This function returns the user's most recent graded discussion post date
def getStuMostRecentGradedDiscussionPostDate(p1_stuDiscussionListAPIUrl, p1_stuCanvasId):
    functionName = "Get a Student's Most Recent Graded Discussion Post Date"
    stuDiscussionListObject = makeApiCall(localSetup, p1_apiUrl=p1_stuDiscussionListAPIUrl)

    if stuDiscussionListObject.status_code == 200:
        stuDiscussionList = json.loads(stuDiscussionListObject.text)
        stuDiscussionListObject.close()
        stuLastGradedDiscussionPostDate = None

        for discussion in stuDiscussionList:
            if "assignment" in discussion:
                discussionCanvasId = discussion["id"]
                viewUrl = f"{p1_stuDiscussionListAPIUrl}/{discussionCanvasId}/view"
                viewObject = makeApiCall(localSetup, p1_apiUrl=viewUrl)

                if viewObject.status_code == 200:
                    viewDict = json.loads(viewObject.text)
                    viewObject.close()
                    for post in viewDict.get("view", []):
                        if post.get("user_id") == p1_stuCanvasId:
                            if not stuLastGradedDiscussionPostDate or stuLastGradedDiscussionPostDate < post["updated_at"]:
                                stuLastGradedDiscussionPostDate = post["updated_at"]
                            getStuMostRecentGradedDiscussionPostDateRecursive(p1_stuCanvasId, stuLastGradedDiscussionPostDate, post)

        return stuLastGradedDiscussionPostDate

## This function updates the end date of a Canvas course to unconclude or reconclude it
## and returns the original end date before the update
def updateCourseEndDate(courseId, newEndDate):
    functionName = "Update Course End Date"

    ## Make the API call to retrieve the current course object
    courseObject = makeApiCall(localSetup, p1_apiUrl=f"{coreCanvasApiUrl}/courses/{courseId}")

    ## If retrieval fails, log and return None
    if courseObject.status_code != 200:
        localSetup.logger.warning(
            f"Failed to retrieve course {courseId} before updating end date. "
            f"Status Code: {courseObject.status_code}, Message: {courseObject.text}"
        )
        return None, None

    ## Parse the current course data
    courseData = json.loads(courseObject.text)
    courseObject.close()

    ## Extract the original end date
    originalEndDate = courseData.get("end_at", "")

    ## Define the payload with the new end date
    payload = {
        "course": {
            "end_at": newEndDate
        }
    }

    ## Make the API call to update the course end date
    updateResponse = makeApiCall(localSetup,
        p1_apiUrl=f"{coreCanvasApiUrl}/courses/{courseId}",
        p1_payload=payload,
        p1_apiCallType="put",
    )

    ## Log the result of the update
    if updateResponse.status_code == 200:
        localSetup.logger.info(f"Successfully updated end date for course {courseId} to {newEndDate}")
    else:
        localSetup.logger.warning(
            f"Failed to update end date for course {courseId}. "
            f"Status Code: {updateResponse.status_code}, Message: {updateResponse.text}"
        )

    ## Return the original end date and the update response
    return originalEndDate, updateResponse

## This function retrieves the Canvas enrollment object for a student
## and returns the enrollment object and original course end date if the course was concluded
def getEnrollmentApiObject(enrollmentId, courseId, parentCourseId, stuId, enrollmentDeleted):
    functionName = "Get Enrollment API Object"
    try:
        ## If the enrollment was previously deleted
        if enrollmentDeleted:
            ## Determine target course and section
            targetCourseId = parentCourseId or courseId
            enrollmentApiUrl = f"{coreCanvasApiUrl}/courses/sis_course_id:{targetCourseId}/enrollments"

            payload = {
                "enrollment[user_id]": f"sis_user_id:{stuId}",
                "enrollment[type]": "StudentEnrollment",
                "enrollment[enrollment_state]": "active"
            }

            ## If parent course exists, ## try to find matching section
            if parentCourseId:
                sectionApiUrl = f"{coreCanvasApiUrl}/courses/sis_course_id:{parentCourseId}/sections"
                sectionResponse = makeApiCall(localSetup, p1_apiUrl=sectionApiUrl)

                if sectionResponse.status_code != 200:
                    localSetup.logger.warning(f"Failed to retrieve sections for parent course {parentCourseId}")
                    errorHandler.sendError(functionName, f"Section retrieval failed for parent course {parentCourseId}")
                    return None, None

                sectionData = json.loads(sectionResponse.text)
                sectionResponse.close()

                crosslistedSectionId = None
                for section in sectionData:
                    if courseId in section.get("name", ""):
                        crosslistedSectionId = section.get("id")
                        break

                if crosslistedSectionId:
                    payload["enrollment[course_section_id]"] = crosslistedSectionId

            ## Attempt to re-enroll the student
            enrollmentObject = makeApiCall(localSetup, 
                p1_apiUrl=enrollmentApiUrl,
                p1_payload=payload,
                p1_apiCallType="post",
            )

            ## If course is concluded, update end date temporarily
            if enrollmentObject.status_code == 400:
                error400Message = json.loads(enrollmentObject.content.decode('utf-8')).get('message', '')
                if error400Message == "Can't add an enrollment to a concluded course.":
                    futureEndDate = (
                        datetime.combine(
                            datetime.utcnow().date() + timedelta(days=1)
                            , datetime.min.time()) + timedelta(hours=23, minutes=59)
                        ).strftime("%Y-%m-%dT%H:%M:%SZ")
                    originalEndDate, _ = updateCourseEndDate(f"sis_course_id:{targetCourseId}", futureEndDate)

                    ## Retry enrollment after unconcluding
                    enrollmentObject = makeApiCall(localSetup, 
                        p1_apiUrl=enrollmentApiUrl,
                        p1_payload=payload,
                        p1_apiCallType="post",
                    )

                    ## Return enrollment object and original end date
                    return enrollmentObject, originalEndDate

            ## Return enrollment object and None if no end date update was needed
            return enrollmentObject, None

        ## If enrollment is not deleted, retrieve it normally
        else:
            enrollmentApiUrl = f"{coreCanvasApiUrl}/accounts/1/enrollments/{enrollmentId}"
            enrollmentObject = makeApiCall(localSetup, 
                p1_apiUrl=enrollmentApiUrl,
            )
            return enrollmentObject, None

    except Exception as Error:
        errorHandler.sendError(functionName, Error)
        return None, None

## This function retrieves assignment analytics for a student and returns:
## - last submission date
## - number of missed assignments
## - number of assignments graded 0
def getStudentAssignmentAnalytics(courseApiUrl, stuId):
    functionName = "Get Student Assignment Analytics"
    stuLastSubmissionDateTime = ""
    stuNumOfMissedAssignments = 0
    stuNumOfAssignmentsGradedZero = 0

    analyticsUrl = f"{courseApiUrl}analytics/users/sis_user_id:{stuId}/assignments"
    analyticsObject = makeApiCall(localSetup, p1_apiUrl=analyticsUrl)

    if analyticsObject.status_code == 200:
        analyticsDict = json.loads(analyticsObject.text)
        analyticsObject.close()

        for submission in analyticsDict:
            if "submission" not in submission:
                continue

            submittedAt = submission["submission"].get("submitted_at")
            if submittedAt:
                currentSubmissionDate = datetime.strptime(submittedAt, "%Y-%m-%dT%H:%M:%SZ")
                if not stuLastSubmissionDateTime or stuLastSubmissionDateTime < currentSubmissionDate:
                    stuLastSubmissionDateTime = currentSubmissionDate

            if submission.get("status") == "missing":
                stuNumOfMissedAssignments += 1

            if submission["submission"].get("score") == 0:
                stuNumOfAssignmentsGradedZero += 1

    return stuLastSubmissionDateTime, stuNumOfMissedAssignments, stuNumOfAssignmentsGradedZero

## This function retrieves the student's last participation date from Canvas analytics
def getStudentParticipationDate(courseApiUrl, stuId):
    functionName = "Get Student Participation Date"
    participationDate = ""
    activityUrl = f"{courseApiUrl}analytics/users/sis_user_id:{stuId}/activity"
    activityObject = makeApiCall(localSetup, p1_apiUrl=activityUrl)

    if activityObject.status_code == 200:
        activityDict = json.loads(activityObject.text)
        activityObject.close()
        participations = activityDict.get("participations", [])
        if participations:
            _, rawDate = list(participations[-1].items())[0]
            participationDate = datetime.strptime(rawDate, "%Y-%m-%dT%H:%M:%SZ")

    return participationDate

## This function determines the final course activity and participation dates
def resolveFinalActivityAndParticipationDates(
    lastSubmissionDate,
    lastActivityDate,
    lastGradedDiscussionDate
):
    functionName = "Resolve Final Activity and Participation Dates"
    convertedActivityDate = ""
    convertedParticipationDate = ""

    if lastSubmissionDate and lastGradedDiscussionDate:
        if lastSubmissionDate >= lastGradedDiscussionDate:
            convertedParticipationDate = lastSubmissionDate.strftime("%m-%d")
        else:
            convertedParticipationDate = lastGradedDiscussionDate.strftime("%m-%d")
    elif lastSubmissionDate:
        convertedParticipationDate = lastSubmissionDate.strftime("%m-%d")

    if convertedParticipationDate and lastActivityDate:
        if lastSubmissionDate and lastSubmissionDate >= lastActivityDate:
            convertedActivityDate = lastSubmissionDate.strftime("%m-%d")
        else:
            convertedActivityDate = lastActivityDate.strftime("%m-%d")
    elif lastActivityDate:
        convertedActivityDate = lastActivityDate.strftime("%m-%d")

    return convertedActivityDate, convertedParticipationDate

## This function updates the student's course data dictionary with final values
def updateStudentCourseData(
    stuCoursesData,
    targetCourseSisId,
    convertedActivityDate,
    convertedParticipationDate,
    missedAssignments,
    zeroGrades
):
    functionName = "Update Student Course Data"
    stuCoursesData[targetCourseSisId]["Last Course Activity"] = convertedActivityDate
    stuCoursesData[targetCourseSisId]["Last Course Participation"] = convertedParticipationDate
    stuCoursesData[targetCourseSisId]["Number of Missed Assignments"] = str(missedAssignments)
    stuCoursesData[targetCourseSisId]["Number of Assignments graded 0"] = str(zeroGrades)


## This function deletes a reactivated enrollment if needed
## and restores the original course end date if it was temporarily changed
def handleEnrollmentDeletion(stuId, enrollmentId, courseId, originalEndDate=""):
    functionName = "Handle Enrollment Deletion"
    try:
        ## Construct the deletion API URL
        deletionUrl = f"{coreCanvasApiUrl}/accounts//enrollments/{enrollmentId}"
        payload = {"task": "delete"}

        ## Attempt to delete the enrollment
        deletionResponse = makeApiCall(localSetup, 
            p1_apiUrl=deletionUrl,
            p1_payload=payload,
            p1_apiCallType="delete",
        )
        
        ## Restore original end date if provided
        if originalEndDate:
            _, restoreResponse = updateCourseEndDate(f"sis_course_id:{courseId}", originalEndDate)
            if restoreResponse.status_code == 200:
                localSetup.logger.info(f"Successfully restored original end date for course {courseId} to {originalEndDate}")
            else:
                localSetup.logger.warning(
                    f"Failed to restore original end date for course {courseId}. "
                    f"Status Code: {restoreResponse.status_code}, Message: {restoreResponse.text}"
                )

        ## If deletion is successful
        if deletionResponse and deletionResponse.status_code == 200:
            localSetup.logger.info(f"Successfully deleted enrollment {enrollmentId} for student {stuId} in course {courseId}")

            return True

        ## If deletion failed
        localSetup.logger.warning(
            f"Enrollment deletion failed for {enrollmentId} in course {courseId} for student {stuId}. "
            f"Status Code: {deletionResponse.status_code if deletionResponse else 'No response'}"
        )
        return False

    except Exception as Error:
        errorHandler.sendError(functionName, Error)
        return False

## This function determines whether the course is published or not
def determineCoursePublicationStatus(targetCourseSisId, parentCourseId, unpublishedCoursesList):
    functionName = "Determine Course Publication Status"
    if targetCourseSisId not in unpublishedCoursesList:
        return "Yes"
    elif parentCourseId and parentCourseId not in unpublishedCoursesList:
        return "Yes"
    return "No"

## This function checks if the student is enrolled in the target course and returns enrollment data or a skip signal
def validateStudentEnrollment(stuId, targetCourseSisId, canvasEnrollmentsDf):
    functionName = "Validate Student Enrollment"
    ## Look for a match of the SIS enrollment within the student's Canvas enrollment list
    enrollmentDf = canvasEnrollmentsDf[
        (canvasEnrollmentsDf["course_id"] == targetCourseSisId) &
        (canvasEnrollmentsDf["user_id"] == stuId)
    ]
    return enrollmentDf

## This function gets the student's most recent course specific activity and grade data
def getStuCourseData(
    p2_stuId,
    p1_sisCourseIds,
    p2_stuCoursesData,
    p1_canvasEnrollmentsDf,
    p1_canvasUserId,
    p1_targetCourseId,
    p2_unpublishedCoursesList
):
    functionName = "Get Stu Course Data"
    try:

        ## Validate enrollment
        enrollmentDf = validateStudentEnrollment(p2_stuId, p1_targetCourseId, p1_canvasEnrollmentsDf)

        ## Skip if already processed
        if p1_targetCourseId in p2_stuCoursesData and "Published" in p2_stuCoursesData[p1_targetCourseId]:
            return "Completed Unenrolled Entry"

        ## Initialize course data
        p2_stuCoursesData[p1_targetCourseId] = {
            "Published": "No",
            "Current Grade": "",
            "Number of Missed Assignments": "",
            "Number of Assignments graded 0": "",
            "Last Course Activity": "",
            "Last Course Participation": ""
        }

        ## Determine publication status
        parentCourseId = ""
    
        ## Check for crosslisting by looking for parent course ID
        if enrollmentDf.empty:
            for secondaryCourseId in p1_canvasEnrollmentsDf["course_id"].unique():
                if not parentCourseId:
                    sectionApiUrl = f"{coreCanvasApiUrl}/courses/sis_course_id:{secondaryCourseId}/sections"
                    sectionResponse = makeApiCall(localSetup, p1_apiUrl=sectionApiUrl)
                    if sectionResponse.status_code == 200:
                        sectionData = json.loads(sectionResponse.text)
                        for section in sectionData:
                            if p1_targetCourseId in section.get("name"):
                                parentCourseId = secondaryCourseId
                                break
                else:
                    enrollmentDf = validateStudentEnrollment(p2_stuId, parentCourseId, p1_canvasEnrollmentsDf)
                    break
    
        ## If not enrolled, skip
        if enrollmentDf.empty:
            localSetup.logger.warning(f"Student {p2_stuId} is not enrolled in course {p1_targetCourseId}")
            del p2_stuCoursesData[p1_targetCourseId]
            return "Remove"

        ## Get enrollment ID
        enrollmentId = enrollmentDf["canvas_enrollment_id"].values[0]
        p2_stuCoursesData[p1_targetCourseId]["canvas_enrollment_id"] = enrollmentId

        ## Check if enrollment is deleted
        enrollmentDeleted = enrollmentDf["status"].values[0].lower() == "deleted"

        ## Get enrollment object
        enrollmentObject, oldCourseEndDate = getEnrollmentApiObject(enrollmentId, p1_targetCourseId, parentCourseId,  p2_stuId, enrollmentDeleted)

        ## If failed
        if not enrollmentObject or enrollmentObject.status_code != 200:
            return "Incomplete"

        ## Retrieve the publication status
        publicationStatus = determineCoursePublicationStatus(p1_targetCourseId, parentCourseId, p2_unpublishedCoursesList)

        ## Set the publication status to "Unenrolled" if enrollment was deleted, otherwise set to actual status
        if enrollmentDeleted:
            p2_stuCoursesData[p1_targetCourseId]["Published"] = "Unenrolled"
        else:
            p2_stuCoursesData[p1_targetCourseId]["Published"] = publicationStatus

        ## If unpublished, skip
        if publicationStatus == "No":
            return "Completed"

        ## Get enrollment data
        enrollmentData = json.loads(enrollmentObject.text)
        enrollmentObject.close()

        ## Get grade
        if "grades" in enrollmentData and enrollmentData["grades"]:
            p2_stuCoursesData[p1_targetCourseId]["Current Grade"] = str(enrollmentData["grades"].get("current_score", ""))

        ## Get last activity date
        lastActivityRaw = enrollmentData.get("last_activity_at")
        lastActivityDate = datetime.strptime(lastActivityRaw, "%Y-%m-%dT%H:%M:%SZ") if lastActivityRaw else ""

        ## Determine course API URL
        courseApiUrl = f"{coreCanvasApiUrl}/courses/sis_course_id:{parentCourseId or p1_targetCourseId}/"

        ## Get assignment analytics
        lastSubmissionDate, missedAssignments, zeroGrades = getStudentAssignmentAnalytics(courseApiUrl, p2_stuId)

        ## Get participation date
        participationDate = getStudentParticipationDate(courseApiUrl, p2_stuId)

        ## Get graded discussion post date
        discussionListUrl = f"{courseApiUrl}discussion_topics"
        lastGradedDiscussionDateRaw = getStuMostRecentGradedDiscussionPostDate(discussionListUrl, p1_canvasUserId)
        lastGradedDiscussionDate = datetime.strptime(lastGradedDiscussionDateRaw, "%Y-%m-%dT%H:%M:%SZ") if lastGradedDiscussionDateRaw else ""

        ## Resolve final activity and participation dates
        convertedActivityDate, convertedParticipationDate = resolveFinalActivityAndParticipationDates(
            lastSubmissionDate,
            lastActivityDate,
            lastGradedDiscussionDate
        )

        ## Update course data
        updateStudentCourseData(
            p2_stuCoursesData,
            p1_targetCourseId,
            convertedActivityDate,
            convertedParticipationDate,
            missedAssignments,
            zeroGrades
        )

        ## Update global last canvas activity if needed
        if p2_stuCoursesData.get("Last Canvas Activity", "") < convertedActivityDate:
            p2_stuCoursesData["Last Canvas Activity"] = convertedActivityDate

        ## Handle re-deletion if enrollment was reactivated
        if enrollmentDeleted:
            handleEnrollmentDeletion(p2_stuId, enrollmentId, parentCourseId or p1_targetCourseId, oldCourseEndDate)

    except Exception as Error:
         errorHandler.sendError("functionName", error)

## This threaded function gets each student's course data related to each of their enrollments for the current term
def getStuCurrentCoursesData(
    p1_stuId,
    p1_stuCoursesDataDict,
    p1_filteredCanvasEnrollmentsDf,
    p1_unpublishedCoursesList,
    p1_filteredSisEnrollmentsDf,
    p1_deletedSisCourseIds
):
    functionName = "Get Stu Current Course Data"
    try:

        ## Retrieve the student's SIS course enrollment list
        sisCourseIdsDf = p1_filteredSisEnrollmentsDf[
            p1_filteredSisEnrollmentsDf["user_id"] == p1_stuId
        ]["course_id"]
        sisCourseIdsDf = list(set(sisCourseIdsDf))  ## Remove duplicates

        ## Retrieve the student's Canvas course enrollment list but exclude any courses that are deleted in SIS
        canvasEnrollmentsDf = p1_filteredCanvasEnrollmentsDf[
            (p1_filteredCanvasEnrollmentsDf["user_id"] == str(p1_stuId)) &
            (~p1_filteredCanvasEnrollmentsDf["course_id"].isin(p1_deletedSisCourseIds))
        ]

        loopCounter = 0

        ## While there are still course entries missing "Published" and loop count is under limit
        while (
            not all(
                "Published" in courseData
                for courseData in p1_stuCoursesDataDict.values()
                if isinstance(courseData, dict)
            )
            and loopCounter < 10
        ):
            loopCounter += 1
            ongoingThreads = []

            ## For each SIS-enrolled course
            for targetCourseId in sisCourseIdsDf:
                if (targetCourseId in p1_stuCoursesDataDict.keys() 
                    and "Published" not in p1_stuCoursesDataDict[targetCourseId].keys()):
                    ## Create and start thread to fetch course data
                    courseDataThread = threading.Thread(
                        target=getStuCourseData,
                        args=(
                            p1_stuId,
                            sisCourseIdsDf,
                            p1_stuCoursesDataDict,
                            canvasEnrollmentsDf,
                            p1_stuCoursesDataDict["stuCanvasId"],
                            targetCourseId,
                            p1_unpublishedCoursesList,
                        ),
                    )
                    courseDataThread.start()
                    ongoingThreads.append(courseDataThread)

            ## Wait for all threads to complete
            for thread in ongoingThreads:
                thread.join()

            ## Remove any entries that are not dicts or missing "Published"
            p1_stuCoursesDataDict = {
                key: value
                for key, value in p1_stuCoursesDataDict.items()
                if not isinstance(value, dict) or "Published" in value
            }

        ## Log completion
        localSetup.logger.info(f"{p1_stuId} completed")

    except Exception as Error:
         errorHandler.sendError("functionName", error)

## This function retrieves and returns a dict of students' ids and last Canvas access report data points
def getStuLastCanvasAccessPoints(p1_stuIdsList):
    functionName = "Retrieve List of Student Last Canvas Access Report Data Points"

    try:

        ## Load the last Canvas access report
        lastCanvasAccessDf = CanvasReport.getCanvasUserLastAccessDf(localSetup)

        ## Initialize a dictionary to hold the last Canvas access data for each student
        lastCanvasAccessData = {}

        ## Iterate through the list of student IDs
        for p1_stuId in p1_stuIdsList:

            ## Retrieve the user's most recent Canvas Activity Date
            stuLastActivityDf = lastCanvasAccessDf[
                lastCanvasAccessDf["user sis id"] == str(p1_stuId)
            ]["last access at"]

            ## Convert the DataFrame to a list
            stuLastActivityList = stuLastActivityDf.tolist()

            ## Initialize the converted last canvas activity date
            convertedLastCanvasActivity = ""

            ## If the student doesn't have any last activity dates
            if not stuLastActivityList or str(stuLastActivityList[0]) == "nan":
                lastCanvasAccessData[p1_stuId] = ""
            else:
                ## Convert the last activity date to a datetime object
                rawLastActivity = datetime.strptime(str(stuLastActivityList[0]), "%Y-%m-%dT%H:%M:%S%z")

                ## Convert the last activity date to a month-day format
                convertedLastCanvasActivity = rawLastActivity.strftime("%m-%d")

                ## Add the converted last activity date to the dictionary
                lastCanvasAccessData[p1_stuId] = convertedLastCanvasActivity

        ## Return the last Canvas access data
        return lastCanvasAccessData

    except Exception as Error:
        errorHandler.sendError(functionName, Error)

## This threaded function gets each student's courses and adds them as keys with empty dicts to the student's course data dict
def getStuCoursesData(
    p1_stuId,
    p1_stuCoursesData,
    p1_filteredCanvasEnrollmentsDf,
    p1_filteredSisEnrollmentsDf
):
    functionName = "Get Stu Courses"
    try:

        ## Get Canvas user ID for the student
        ## Robustly handle user_id values that can be numeric strings or emails/non-numeric values
        numericUserIds = pd.to_numeric(p1_filteredCanvasEnrollmentsDf["user_id"], errors="coerce")
        maskNumeric = numericUserIds == pd.to_numeric(p1_stuId, errors="coerce")

        if maskNumeric.any():
            canvasIdDf = p1_filteredCanvasEnrollmentsDf.loc[maskNumeric, "canvas_user_id"]
        else:
            ## Fallback: compare string equality (safe when user_id is stored as string)
            canvasIdDf = p1_filteredCanvasEnrollmentsDf.loc[
                p1_filteredCanvasEnrollmentsDf["user_id"].astype(str) == str(p1_stuId),
                "canvas_user_id"
            ]

        ## If Canvas ID is found, store it
        if not canvasIdDf.empty:
            p1_stuCoursesData["stuCanvasId"] = canvasIdDf.values[0]

        ## If no Canvas ID is found, skip
        if (
            not p1_stuCoursesData
            or "stuCanvasId" not in p1_stuCoursesData
            or not p1_stuCoursesData["stuCanvasId"]
            ):
            return

        ## Retrieve SIS course enrollment list and filter out the deleted
        p2_sisCourseIds = p1_filteredSisEnrollmentsDf[
            (p1_filteredSisEnrollmentsDf["user_id"] == p1_stuId) &
            (p1_filteredSisEnrollmentsDf["status"] != "deleted")
        ]["course_id"]
        p2_sisCourseIds = list(set(p2_sisCourseIds))  ## Remove duplicates

        ## For each SIS-enrolled course
        for p2_targetCourseId in p2_sisCourseIds:
            ## Skip if already added or if it's a chapel course
            if p2_targetCourseId in p1_stuCoursesData or "CHPL1000_01" in p2_targetCourseId:
                continue

            ## Create a placeholder for parent course ID (if crosslisted)
            parentCourseId = ""

            ## Initialize course entry
            p1_stuCoursesData[p2_targetCourseId] = {}

    except Exception as Error:
         errorHandler.sendError("functionName", error)

## This function takes a list of current NNU enrollments and gets their Canvas enrollment related activity and grade information
def getNighthawk360Data(p1_oldEnrollmentDataDf):
    functionName = "Get NightHawk 360 Data"
    try:

        currentTerms = list(localSetup.getCurrentTerms())
        currentTermCodes = list(localSetup.getCurrentTermCodes())

        completeStudentEnrollmentDataDict = {}

        ## Retrieve the sis courses from the external input path that have a status of deleted
        sisCourseIdsDf = pd.read_csv(os.path.join(localSetup.getExternalResourcePath("SIS"), "canvas_course.csv"))
        deletedSisCourseIds = sisCourseIdsDf[
            sisCourseIdsDf["status"] == "deleted"
            ]["course_id"].tolist()


        ## Load Canvas enrollments
        undgCanvasEnrollmentsDf = CanvasReport.getEnrollmentsDf(localSetup, term=currentTermCodes[0], includeDeleted=True)
        gradCanvasEnrollmentsDf = CanvasReport.getEnrollmentsDf(localSetup, term=currentTermCodes[1], includeDeleted=True)
        combinedCanvasEnrollmentsDf = pd.concat([undgCanvasEnrollmentsDf, gradCanvasEnrollmentsDf], ignore_index=True)

        filteredCanvasEnrollmentsDf = combinedCanvasEnrollmentsDf[
            (combinedCanvasEnrollmentsDf["role"] == "student") &
            (~combinedCanvasEnrollmentsDf["course_id"].str.contains("CHPL1000_01", na=False)) &
            (
                combinedCanvasEnrollmentsDf["course_id"].str.contains(currentTerms[0]) |
                combinedCanvasEnrollmentsDf["course_id"].str.contains(currentTerms[1])
            )
        ]


        ## Load unpublished courses
        undgUnpublishedCoursesDf = CanvasReport.getUnpublishedCoursesDf(localSetup, term=currentTermCodes[0])
        gradUnpublishedCoursesDf = CanvasReport.getUnpublishedCoursesDf(localSetup, term=currentTermCodes[1])
        combinedUnpublishedCoursesDf = pd.concat([undgUnpublishedCoursesDf, gradUnpublishedCoursesDf], ignore_index=True)
        unpublishedCoursesList = combinedUnpublishedCoursesDf["sis id"].tolist()

        ## Load SIS enrollments
        sisEnrollmentsDf = pd.read_csv(f"{localSetup.getExternalResourcePath('SIS')}canvas_enroll.csv")
        filteredSisEnrollmentsDf = sisEnrollmentsDf[
            (sisEnrollmentsDf["role"] == "student") &
            (~sisEnrollmentsDf["course_id"].str.contains("CHPL1000_01")) &
            (
                sisEnrollmentsDf["course_id"].str.contains(currentTerms[0]) |
                sisEnrollmentsDf["course_id"].str.contains(currentTerms[1])
            )
        ].drop_duplicates(subset=["course_id", "user_id"])

        ## Set the user_id to string type to avoid mismatches
        filteredSisEnrollmentsDf["user_id"] = filteredSisEnrollmentsDf["user_id"].astype(str)

        ## Get unique student IDs
        uniqueStuIds = filteredSisEnrollmentsDf["user_id"].unique()

        ## Get last Canvas access data
        stuLastCanvasAccessData = getStuLastCanvasAccessPoints(uniqueStuIds.tolist())

        ## Initialize student data dict
        studentDataDict = {
            stuId: {"Last Canvas Activity": stuLastCanvasAccessData.get(stuId, "")}
            for stuId in uniqueStuIds
        }

        ## Seperate deleted enrollments
        deletedEnrollmentsDf = filteredSisEnrollmentsDf[filteredSisEnrollmentsDf["status"] == "deleted"].copy()

        if not p1_oldEnrollmentDataDf.empty:

            ## Make sure oldEnrollmentDataDf keys are strings
            p1_oldEnrollmentDataDf["Student ID"]   = p1_oldEnrollmentDataDf["Student ID"].astype(str).str.strip()
            p1_oldEnrollmentDataDf["Course Number"] = p1_oldEnrollmentDataDf["Course Number"].astype(str).str.strip()

            ## If your old files might use dashes, normalize to underscores
            p1_oldEnrollmentDataDf["Course Number"] = p1_oldEnrollmentDataDf["Course Number"].str.replace("-", "_", regex=False)

            ## Normalize course_id to underscores as expected in left keys
            deletedEnrollmentsDf["course_id"] = deletedEnrollmentsDf["course_id"].str.replace("-", "_", regex=False)

            ## Make sure deletedEnrollmentsDf keys are strings
            deletedEnrollmentsDf["user_id"]  = deletedEnrollmentsDf["user_id"].astype(str).str.strip()
            deletedEnrollmentsDf["course_id"] = deletedEnrollmentsDf["course_id"].astype(str).str.strip()

            ## Merge
            unEnrolledStudentData = p1_oldEnrollmentDataDf.merge(
                deletedEnrollmentsDf[["user_id", "course_id"]],
                left_on=["Student ID", "Course Number"],
                right_on=["user_id", "course_id"],
                how="inner"
            ).drop(columns=["user_id", "course_id"])

            unEnrolledStudentData.fillna("", inplace=True)

            for p2_stuId in unEnrolledStudentData["Student ID"].astype(str).unique():
                stuDataDf = unEnrolledStudentData[unEnrolledStudentData["Student ID"] == p2_stuId]
                for p2_courseId in stuDataDf["Course Number"].unique():
                    studentDataDict[p2_stuId][p2_courseId] = {}
                    courseData = stuDataDf[stuDataDf["Course Number"] == p2_courseId].iloc[0]
                    for column in stuDataDf.columns:
                        if column == "Published":
                            studentDataDict[p2_stuId][p2_courseId][column] = "Unenrolled"
                        else:
                            studentDataDict[p2_stuId][p2_courseId][column] = courseData[column]

        ## Initialize course data for each student
        for stuId, coursesData in studentDataDict.items():
            ##if stuId ==	"132104": ## Test student value
                if "Published" not in coursesData:
                    getStuCoursesData(
                        p1_stuId=stuId,
                        p1_stuCoursesData=coursesData,
                        p1_filteredCanvasEnrollmentsDf=filteredCanvasEnrollmentsDf,
                        p1_filteredSisEnrollmentsDf=filteredSisEnrollmentsDf
                    )

        ## Threaded course data collection
        loopCounter = 0
        ongoingThreads = []

        while (
            not all(
                "Published" in courseData
                for stuData in studentDataDict.values()
                for courseData in stuData.values()
                if isinstance(courseData, dict)
            )
            and loopCounter < 100
        ):
            loopCounter += 1
            ongoingThreads.clear()
            threadCounter = 0
            batchCounter = 0

            for stuId, coursesData in studentDataDict.items():
                if not all(
                    "Published" in courseData
                    for courseData in coursesData.values()
                    if isinstance(courseData, dict)
                ):
                    if "Published" not in coursesData or not coursesData["Published"]:
                        thread = threading.Thread(
                            target=getStuCurrentCoursesData,
                            args=(
                                stuId,
                                coursesData,
                                filteredCanvasEnrollmentsDf,
                                unpublishedCoursesList,
                                filteredSisEnrollmentsDf,
                                deletedSisCourseIds,
                            ),
                        )
                        thread.start()
                        ongoingThreads.append(thread)
                        threadCounter += 1

                        if threadCounter >= 100:
                            for t in ongoingThreads:
                                t.join()
                            ongoingThreads.clear()
                            batchCounter += 1
                            localSetup.logger.info(f"{batchCounter * 10}0 threads have been completed")
                            threadCounter = 0

            for t in ongoingThreads:
                t.join()

            localSetup.logger.info(f"{batchCounter * 10 + threadCounter} threads have been completed")

        ## Merge into complete dict
        if not completeStudentEnrollmentDataDict:
            completeStudentEnrollmentDataDict = studentDataDict
        else:
            for stuId, coursesData in studentDataDict.items():
                if stuId not in completeStudentEnrollmentDataDict:
                    completeStudentEnrollmentDataDict[stuId] = coursesData
                else:
                    completeStudentEnrollmentDataDict[stuId].update(coursesData)

        return completeStudentEnrollmentDataDict

    except Exception as Error:
         errorHandler.sendError("functionName", error)

## This function contains the start and end of the NightHawk 360 data report
def Nighthawk360CanvasReport():
    functionName = "Nighthawk 360 Canvas Report"
    try:

        localSetup.logger.info("\nBeginning the Nighthawk 360 Canvas Report")

        ## Load previous enrollment data if available
        oldEnrollmentDataDf = pd.DataFrame()
        activityPath = os.path.join (localSetup.getExternalResourcePath('Pharos'), "Enrollment_Data_Activity.csv")
        submissionPath = os.path.join (localSetup.getExternalResourcePath('Pharos'), "Enrollment_Data_Submissions.csv")

        if os.path.exists(activityPath) and os.path.exists(submissionPath):
            oldActivityDf = pd.read_csv(activityPath, sep="|")
            oldSubmissionDf = pd.read_csv(submissionPath, sep="|")
            oldEnrollmentDataDf = pd.merge(
                oldActivityDf,
                oldSubmissionDf,
                on=["Student ID", "Course Number"],
                how="outer"
            )

        ## Get current enrollment data
        enrollmentDataDict = getNighthawk360Data(oldEnrollmentDataDf)

        ## Prepare output files
        activityFilePath = os.path.join (localSetup.getInternalResourcePaths("Canvas"), "Enrollment_Data_Activity.csv")
        submissionFilePath = os.path.join (localSetup.getInternalResourcePaths("Canvas"), "Enrollment_Data_Submissions.csv")

        with open(activityFilePath, 'w', newline='') as activityCsv, \
             open(submissionFilePath, 'w', newline='') as submissionCsv:

            ## Write headers (pipe-delimited, quoted)
            activityCsv.write('Student ID|"Course Number"|"Last Canvas Activity"|"Published"|"Last Course Activity"|"Last Course Participation"\n')
            submissionCsv.write('Student ID|"Course Number"|"Current Grade"|"Number of Missed Assignments"|"Number of Assignments graded 0"\n')

            ## Write data rows
            for p1_stuId, p1_dataPoints in enrollmentDataDict.items():
                for p1_courseKey in p1_dataPoints:
                    if p1_courseKey in ["Last Canvas Activity", "stuCanvasId"] or not p1_dataPoints[p1_courseKey]:
                        continue

                    try: ## Irregular try clause, do not comment out in testing 
                        ## Format values for activity
                        formattedCourseCode = p1_courseKey.replace("_", "-")
                        formattedLastCanvasActivity = p1_dataPoints.get("Last Canvas Activity", "")
                        formattedPublished = p1_dataPoints[p1_courseKey].get("Published", "")
                        formattedLastCourseActivity = p1_dataPoints[p1_courseKey].get("Last Course Activity", "")
                        formattedLastCourseParticipation = p1_dataPoints[p1_courseKey].get("Last Course Participation", "")

                        ## Format values for submission
                        formattedCurrentGrade = p1_dataPoints[p1_courseKey].get("Current Grade", "")
                        formattedMissedAssignments = p1_dataPoints[p1_courseKey].get("Number of Missed Assignments", "")
                        formattedZeroGrades = p1_dataPoints[p1_courseKey].get("Number of Assignments graded 0", "")

                        ## Write activity row
                        activityCsv.write(
                            f'{p1_stuId}|"'
                            f'{formattedCourseCode}"|"'
                            f'{formattedLastCanvasActivity}"|"'
                            f'{formattedPublished}"|"'
                            f'{formattedLastCourseActivity}"|"'
                            f'{formattedLastCourseParticipation}"\n'
                        )

                        ## Write submission row
                        submissionCsv.write(
                            f'{p1_stuId}|"'
                            f'{formattedCourseCode}"|"'
                            f'{formattedCurrentGrade}"|"'
                            f'{formattedMissedAssignments}"|"'
                            f'{formattedZeroGrades}"\n'
                        )

                    except Exception as Error: ## Irregular try clause, do not comment out in testing
                        localSetup.logger.warning(
                            f"Error: {Error}\nOccurred while processing {p1_courseKey}:{p1_dataPoints[p1_courseKey]} for Student ID: {str(p1_stuId)}"
                        )
                        errorHandler.sendError("functionName", p1_ErrorInfo=...)

        ## Copy files to external output path
        shutil.copy(activityFilePath, activityPath)
        shutil.copy(submissionFilePath, submissionPath)

        localSetup.logger.info("\nActivity and Data CSVs saved to internal and external paths")

    except Exception as Error:
         errorHandler.sendError("functionName", error)

if __name__ == "__main__":

    ## Start the NightHawk 360 data report
    Nighthawk360CanvasReport ()

    input("Press enter to exit")

## ===========================================================================
## FILE: ReportModules\Non_Official_Instructors_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Moduels
import traceback, os, sys, logging, threading, csv, requests, json, pdfkit, re, os, os.path
from datetime import date
import pandas as pd

## Set working directory
os.chdir(os.path.dirname(__file__))

## Add Script repository to syspath
sys.path.append(f"{os.getcwd()}\ResourceModules")

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Non Official Instructors Report"

## Script file identifier
scriptRequirementMissingFolderIdentifier = "Courses_Without_Required_Outcome_Attached"

scriptPurpose = r"""
This script takes in the current term's enrollments and the SIS enrollment feed to create an excel file of the non instructors of record for each course.
"""
externalRequirements = r"""
To function properly, this script requires access to the ..\Canvas Resources folder and the shared drive Instructional Design and Technology\Canvas_Load_Files folder in the 
"""

## Time variables
currentDateTime = date.today()
currentYear = currentDateTime.year
currentMonth = currentDateTime.month
lastYear = currentYear - 1
nextYear = currentYear + 1
century = str(currentYear)[:2]
decade = str(currentYear)[2:]

##pdfkit (which enables the script to convert html code into .pdf and save it) needs to access wkhtmltopdf.exe which is easier if it has a direct path configured instead of try:ing to find it generally
path_wkhtmltopdf = r'Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe' ##This is the default location of wkhtmltopdf.exe and would need to be changed if the default installation location for wkhtmltopdf was edited.
config = pdfkit.configuration(wkhtmltopdf=path_wkhtmltopdf)

## Set working directory
fileDir = os.path.dirname(__file__)
os.chdir(fileDir)

## The relative path is used to provide a generic way of finding where the Scripts TLC folder has been placed
## This provides a non-script specific manner of finding the vaiours related modules
PFRelativePath = r".\\"

## If the Scripts TLC folder is not in the folder the PFRelative path points to
## look for it in the next parent folder
while "Scripts TLC" not in os.listdir(PFRelativePath):

    PFRelativePath = f"..\\{PFRelativePath}"

## Change the relative path to an absolute path
absolutePath = f"{os.path.abspath(PFRelativePath)}\\"

## Define the internal paths
rawInternalInputPath = f"{absolutePath}Canvas Resources\\"
internalOutputPath = f"{absolutePath}Canvas Resources\\"

## Add Input Modules to the sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ResourceModules")

## Import local modules
from Error_Email_API import errorEmailApi
from Download_File import downloadFile

from Create_Sub_Account_Save_Path import determineDepartmentSavePath
from Download_File import downloadFile

## Local Path Variables
baseLogPath = f"{absolutePath}Logs\\{scriptName}\\"
configPath = f"{absolutePath}\\Configs TLC\\"
baseLocalInputPath = f"{absolutePath}Canvas Resources\\"  ## This is only the base path as the real path requires the requested term
baseLocalOutputPath = f"{absolutePath}Canvas Resources\\" ## This is only the base path as the real path requires the requested term

## External Path Variables

## Define a variable to hold the base external input path which is where the sis input files are stored
baseExternalOutputPath = None ## Where the syllabus repository will be created and relavent reports stored
## Open External_Resource_Paths.json from the config path and get the SISResourcePath value
with open (f"{configPath}External_Resource_Paths.json", "r") as file:
    fileJson = json.load(file)
    baseExternalOutputPath = fileJson["UniversitySyllabusResourcePath"]

## Canvas Instance Url
coreCanvasApiUrl = None
## Open the Core_Canvas_Url.txt from the config path
with open (f"{configPath}Core_Canvas_Url.txt", "r") as file:
    coreCanvasApiUrl = file.readlines()[0]


## If the script is run as main the folder with the access token is in the parent directory
canvasAccessToken = ""

## Open and retrieve the Canvas Access Token
with open (fr"{configPath}Canvas_Access_Token.txt", "r") as file:
    canvasAccessToken = file.readlines()[0]

## List of courses that don't need a syllabus. Syllabi for such courses are still gathered but they are not listed in the missing_syllabi.csv
list_of_courses_that_dont_need_syllabi = []
with open(f"{configPath}List_of_uneeded_syllabi.csv", 'r') as tempCsvFile:
    tempcsvReader = csv.DictReader(tempCsvFile, delimiter = ',')
    for row in tempcsvReader:
        list_of_courses_that_dont_need_syllabi.append(row['course_id'])
    tempCsvFile.close()

##Primary API call header and payload
header = {'Authorization' : 'Bearer ' + canvasAccessToken}
payload = {'include[]': ['syllabus_body', 'term', 'account', 'teachers', 'sections', 'total_students']}

## Begin localSetup.logger set up

## If the base log path doesn't already exist, create it
if not (os.path.exists(baseLogPath)):
    os.makedirs(baseLogPath, mode=0o777, exist_ok=False)

## Log configurations
logger = logging.getLogger(__name__)
rootFormat = ("%(asctime)s %(levelname)s %(message)s")
FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
logging.basicConfig(format=rootFormat, filemode = "a", level=logging.INFO)

## Info Log Handler
infoLogFile = f"{baseLogPath}\\Info Log.txt"
logInfo = logging.FileHandler(infoLogFile, mode = 'a')
logInfo.setLevel(logging.INFO)
logInfo.setFormatter(FORMAT)
localSetup.logger.addHandler(logInfo)

## Warning Log handler
warningLogFile = f"{baseLogPath}\\Warning Log.txt"
logWarning = logging.FileHandler(warningLogFile, mode = 'a')
logWarning.setLevel(logging.WARNING)
logWarning.setFormatter(FORMAT)
localSetup.logger.addHandler(logWarning)

## Error Log handler
errorLogFile = f"{baseLogPath}\\Error Log.txt"
logError = logging.FileHandler(errorLogFile, mode = 'a')
logError.setLevel(logging.ERROR)
logError.setFormatter(FORMAT)
localSetup.logger.addHandler(logError)

## This variable enables the except function to only send

## by tracking what functions have already been recorded as having errors
errorHandler = errorEmailApi(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function handles function errors
def errorHandler.sendError (p1_ErrorLocation, p1_ErrorInfo, sendOnce = True):
    functionName = "errorHandler.sendError"

    ## Log the error
    localSetup.logger.error (f"     \nA script error occured while running {p1_ErrorLocation}. " +
                     f"Error: {str(p1_ErrorInfo)}")

    ## If the function with the error has not already been processed send an email alert
    if (p1_ErrorLocation not in setOfFunctionsWithErrors):
        errorEmailApi.sendEmailError(p2_ScriptName = scriptName, p2_ScriptPurpose = scriptPurpose, 
                                     p2_ExternalRequirements = externalRequirements, 
                                     p2_ErrorLocation = p1_ErrorLocation, p2_ErrorInfo = f"{p1_ErrorInfo}: \n\n {traceback.format_exc()}")
        
        ## Add the function name to the set of functions with errors
        setOfFunctionsWithErrors.add(p1_ErrorLocation)
        
        ## Note that an error email was sent
        localSetup.logger.error (f"     \nError Email Sent")
    
    ## Otherwise log the fact that an error email as already been sent
    else:
        localSetup.logger.error (f"     \nError email already sent")

## This function takes in a term and returns the instructor information for non-official instructors 
def termNonOfficialInstructorsReport(p1_inputTerm = ""):
    functionName = "termNonOfficialInstructorsReport"

    try:

        ## Determine and save the term's school year
        schoolYear = None
        if re.search("AF|FA|GF", p1_inputTerm):
            ## Fall terms are the first terms of a new school year so FA20 is part of the 2020-21 school year.
            schoolYear = (century + p1_inputTerm[2:] + "-" + str(int(p1_inputTerm[2:]) + 1))
        elif re.search("SP|GS|AS|SG|SA|SU", p1_inputTerm):
            ## Spring and Summer terms belong in the same school year as the fall terms before them, so SP21 is part of the same 2020-21 school year as FA20.
            schoolYear = (century + str(int(p1_inputTerm[2:]) - 1) + "-" + p1_inputTerm[2:])

        ## Determine the relevant grad term
        gradTerm = None
        if "FA" in p1_inputTerm:
            gradTerm = f"GF{p1_inputTerm[2:]}"

        elif "SP" in p1_inputTerm:
            gradTerm = f"GS{p1_inputTerm[2:]}"

        elif "SU" in p1_inputTerm:
            gradTerm = f"SG{p1_inputTerm[2:]}"
        
        ## Create the school year relavent input and output paths
        schoolYearInputPath = f"{rawInternalInputPath}\\{schoolYear}\\"
        schoolYearOutputPath = f"{internalOutputPath}\\{schoolYear}\\"
        
        ## Define the undergrad term specific input path
        undgTermInputPath = f"{schoolYearInputPath}{p1_inputTerm}\\"

        ## Define the grad term specific input path
        gradTermInputPath = f"{schoolYearInputPath}{gradTerm}\\"
    
        ## Retrieve the Undergraduate enrollments file as a df, filter it to only contain the rows that have "Instructor" in the role value
        rawUndgTermInstructorEnrollmentsDF = pd.read_csv(f"{undgTermInputPath}{p1_inputTerm}_Complete_Canvas_Enrollments.csv")

        ## Filter the Undg Enrollments to only have rows that have "Instructor" in the role value
        firstFilteredUndgTermInstructorEnrollmentsDF = rawUndgTermInstructorEnrollmentsDF[rawUndgTermInstructorEnrollmentsDF['role'] == 'teacher']

        ## Filter the Undg Enrollments to only have rows that have "active" in the status value
        secondFilteredUndgTermInstructorEnrollmentDF = firstFilteredUndgTermInstructorEnrollmentsDF[firstFilteredUndgTermInstructorEnrollmentsDF['status'] == 'active']
        
        ## Retrieve the Graduate enrollments file as a df, filter it to only contain the rows that have "Instructor" in the role value and active in the status value
        rawGradTermInstructorEnrollmentsDF = pd.read_csv(f"{gradTermInputPath}{gradTerm}_Complete_Canvas_Enrollments.csv")

        ## Filter the Grad Enrollments to only have rows that have "Instructor" in the role value
        firstFilteredGradTermInstructorEnrollmentsDF = rawGradTermInstructorEnrollmentsDF[rawGradTermInstructorEnrollmentsDF['role'] == 'teacher']

        ## Filter the Grad Enrollments to only have rows that have "active" in the status value
        secondFilteredGradTermInstructorEnrollmentsDF = firstFilteredGradTermInstructorEnrollmentsDF[firstFilteredGradTermInstructorEnrollmentsDF['status'] == 'active']

        ## Retrieve the SIS feed enrollments file as a df, and filter it to only contain the rows that have "Instructor" in the role value
        rawSisEnrollmentsDF = pd.read_csv(f"{SISResourcePath}canvas_enroll.csv")
        
        ## Filter the SIS Enrollments to only have rows that have "Instructor" in the role value
        firstFilteredSisEnrollmentsDF = rawSisEnrollmentsDF[rawSisEnrollmentsDF['role'] == 'teacher']

        ## Filter the SIS Enrollments to only have rows that have "active" in the status value
        secondFilteredSisEnrollmentsDF = firstFilteredSisEnrollmentsDF[firstFilteredSisEnrollmentsDF['status'] == 'active']

        ## Add a column that combines the course_id and user_id to create a unique identifier for each row
        secondFilteredSisEnrollmentsDF['course_plus_user_id'] = secondFilteredSisEnrollmentsDF['course_id'] + secondFilteredSisEnrollmentsDF['user_id'].astype(str)
        
        ## Create a non official instructors df by concatenating the undergrad and grad dfs
        rawCombinedTermInstructorEnrollmentDF = pd.concat([secondFilteredUndgTermInstructorEnrollmentDF, secondFilteredGradTermInstructorEnrollmentsDF])

        ## Retrieve the grad and undergrad sections dfs
        rawGradSectionsDF = pd.read_csv(f"{gradTermInputPath}{gradTerm}_Canvas_Sections.csv")
        rawUndgSectionsDF = pd.read_csv(f"{undgTermInputPath}{p1_inputTerm}_Canvas_Sections.csv")

        ## Combine the grad and undergrad sections dfs
        rawCombinedSectionsDF = pd.concat([rawGradSectionsDF, rawUndgSectionsDF])

        ## Remove any duplicate rows from the combined sections df
        rawCombinedSectionsDF.drop_duplicates(inplace = True)

        ## Create a dictionary from rawCombinedSectionsDF for quick lookup
        rawCombinedSectionsDF['name'] = rawCombinedSectionsDF['name'].astype(str)
        canvasSectionIdNameDict = rawCombinedSectionsDF.set_index('canvas_section_id')['name'].apply(lambda x: x.split(' ')[-1]).to_dict()

        ## Map the canvas_section_id to the corresponding name in the enrollment file
        rawCombinedTermInstructorEnrollmentDF['section_id'] = rawCombinedTermInstructorEnrollmentDF['canvas_section_id'].map(canvasSectionIdNameDict).fillna('Unknown')
        
        ## Add a column that combines the course_id and user_id to create a unique identifier for each row
        rawCombinedTermInstructorEnrollmentDF['course_plus_user_id'] = rawCombinedTermInstructorEnrollmentDF['section_id'] + rawCombinedTermInstructorEnrollmentDF['user_id'].astype(str)

        ## Filter out any rows that are in the SIS feed
        filteredCombinedTermInstructorEnrollmentDF = rawCombinedTermInstructorEnrollmentDF[~rawCombinedTermInstructorEnrollmentDF['course_plus_user_id'].isin(secondFilteredSisEnrollmentsDF['course_plus_user_id'])]

        ## Delete the course_plus_user_id column
        del filteredCombinedTermInstructorEnrollmentDF['course_plus_user_id']

        ## Set the type of the course_id column to int
        filteredCombinedTermInstructorEnrollmentDF['user_id'] = filteredCombinedTermInstructorEnrollmentDF['user_id'].fillna(0).astype(int)

        ## Get the user file from the raw input path
        userFileDf = pd.read_csv(f"{rawInternalInputPath}Canvas_Users.csv")

        ## Create a Instructor Name column by matching the user_id in the user file to the user_id in the filtered combined term instructor enrollment df
        filteredCombinedTermInstructorEnrollmentDF['full_name'] = filteredCombinedTermInstructorEnrollmentDF['canvas_user_id'].apply(
            lambda x: userFileDf.loc[userFileDf['canvas_user_id'] == x, 'full_name'].values[0] if len(userFileDf.loc[userFileDf['canvas_user_id'] == x, 'full_name'].values) > 0 else 'Unknown'
        )
        
        ## Create a non official instructors df by taking the course_id, course_name, user_id, and full_name columns
        rawNonOfficialInstructorDf = filteredCombinedTermInstructorEnrollmentDF[['course_id', 'user_id', 'full_name', "created_by_sis"]]

        ## Drop any rows where the course_id is null or ""
        rawNonOfficialInstructorDf = rawNonOfficialInstructorDf[~rawNonOfficialInstructorDf['course_id'].isnull()]

        ## Change the user_id column to instructor_id and the full name column to instructor_name
        rawNonOfficialInstructorDf.rename(columns = {'user_id' : 'instructor_id', 'full_name' : 'instructor_name'}, inplace = True)
        
        ## Filter out any rows with 63232 as the user_id
        filteredNonOfficialInstructorDf = rawNonOfficialInstructorDf[
            (rawNonOfficialInstructorDf['instructor_id'] != 63232) & 
            (rawNonOfficialInstructorDf['created_by_sis'] == False)
        ]

        ## Drop the created_by_sis column
        filteredNonOfficialInstructorDf.drop(columns = ['created_by_sis'], inplace = True)

        ## Save the raw and filtered non official instructors dfs to the output path as excel files
        rawNonOfficialInstructorDf.to_excel(f"{schoolYearOutputPath}Raw_Non_Official_Instructors.xlsx", index = False)
        filteredNonOfficialInstructorDf.to_excel(f"{schoolYearOutputPath}Non_Official_Instructors.xlsx", index = False)
        
        
    
    except Exception as Error:
        errorHandler.sendError (functionName, Error)


## This function takes in a input term or creates one to run the term Non Official Instructors Report
def createNonOfficialInstructorsReport (inputTerm = ""):
    functionName = "Run OutcomeAttachment Report"
    
    try:

        currentTerm = ""

        ## If a term is not given, determine it off of the current year
        if not inputTerm:
            currentTerm = None
            
            ## January through May is the Spring Term
            if currentMonth >= 1 and currentMonth <= 5:
                currentTerm = f"SP{str(currentYear)[2:]}"

            ## June through August is the Summer Term
            elif currentMonth >= 6 and currentMonth <= 8:
                currentTerm = f"SU{str(currentYear)[2:]}"

            ## The other months (September through December) is the Fall Term
            else:
                currentTerm = f"FA{str(currentYear)[2:]}"

            ## Set the input term as current term
            inputTerm = currentTerm

        termNonOfficialInstructorsReport (p1_inputTerm = inputTerm)
     
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

if __name__ == "__main__":

    ## Define the API Call header using the retreived Canvas Token
    ##header = {'Authorization' : f"Bearer {canvasAccessToken}"}

    ## Start and download the Canvas report
    createNonOfficialInstructorsReport (inputTerm = input("Enter the desired term in \
four character format (FA20, SU20, SP20): "))

    input("Press enter to exit")

## ===========================================================================
## FILE: ReportModules\Outcome_Attachment_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## External libraries
import traceback, os, sys, logging, threading, csv, requests, json, pdfkit, re, os, os.path, time
from datetime import date, datetime
import pandas as pd

## Add Script repository to syspath
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

## New resource modules
from Local_Setup import LocalSetup
from TLC_Common import makeApiCall, isFileRecent
from Canvas_Report import CanvasReport
from Common_Configs import coreCanvasApiUrl, canvasAccessToken
from Error_Email import errorEmail

## Create the localsetup variable
localSetup = LocalSetup(datetime.now(), __file__)  ## sets cwd, paths, logs, date parts

from Common_Configs import undgTermsCodesToWordsDict, gradTermsCodesToWordsDict

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
The Course Addendum Checker Script was written by NNU's IDT department to check whether NNU's canavs courses have the static Syllabus Addendum link, make .csv lista of the courses that do not have the link, and store the .csv files under \Employees-Read Only\University Syllabi by college and department.
"""
externalRequirements = r"""
To function properly, this script requires that the static Syllabus Addendum link "https://my.nnu.edu/ics/syllabus_addendum.aspx" (which redirects to the current addendum) be placed in the Canvas Syllabus tab.
"""

## Setup the error handler
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)


""" 
 This fuction saves the course ID and other identifiers of the course in question.
 The intended purpose of this function is to make a csv of missing syllabi made up of courses without
 a syllabus or with short syllabi (which generally indicate that the link wasn't named properly)
 with the ulimate goal that all syllabi are gathered because departments are able to find and 
 add/fix the syllabi in the log.
"""
def saveOutcomeAttachmentCourseInfo(saveLocation, fileName, p1_course_name, p1_requiredOutcome, issue, p1_instructor_name, p1_instructor_email, p2_newFileCreated):
    functionName = "saveOutcomeAttachmentCourseInfo"
    try:

        ## This function creates a csv file to record when a Outcome outcpome is missing
        ## Create a new csv for that context the first time that a department is missing the requirement
        if not p2_newFileCreated[0]:

            if not (os.path.exists(saveLocation)):
                os.makedirs(saveLocation, mode=0o777, exist_ok=False)
            with open (f"{saveLocation}{fileName}", "w", newline="") as csvFile_2:
                fieldnames = ["Course_name", "Required Outcome", "Issue", "Instructor Name", "Instructor Email"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writeheader()
                csvWriter.writerow({"Course_name": p1_course_name
                                    , "Required Outcome": p1_requiredOutcome
                                    , "Issue": issue
                                    , "Instructor Name": p1_instructor_name
                                    , "Instructor Email": p1_instructor_email})
                csvFile_2.close()
            p2_newFileCreated[0] = True

        ## If it is the second time (or more) in the current run of the script the missing syllabi file is added onto
        else:
            with open (f"{saveLocation}{fileName}", "a", newline="") as csvFile_2:
                fieldnames = ["Course_name", "Required Outcome", "Issue", "Instructor Name", "Instructor Email"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writerow({"Course_name": p1_course_name
                                    , "Required Outcome": p1_requiredOutcome
                                    , "Issue": issue
                                    , "Instructor Name": p1_instructor_name
                                    , "Instructor Email": p1_instructor_email})
            csvFile_2.close()

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function processes an assignment that an outcome is attached to to ensure that it is published
## and assigned to the primary course section
def assignmentIsPublishedCheck (p1_rubric_api_url, assignment_id):
    functionName = "Assignment Is Published Check"

    ## Isolate the api url through the sis ID (leaving out the rubric specific piece)
    assignmentApiUlr = p1_rubric_api_url[:57] + p1_rubric_api_url.split(':')[2].split('/')[0] + "/assignments/" + str(assignment_id)
    
    ## Define the api payload to include associations
    assignmentApiPayload = {"include": ["submission", "assignment_visibility"]}

    ## Make a variable to hold the course's rubric api object
    assignmentApiObject = makeApiCall(localSetup, p1_apiUrl = assignmentApiUlr, p1_payload = assignmentApiPayload)

    ## Save the primary body of information retrieved by the API call
    assignmentApiText = assignmentApiObject.text
        
    ## Convert the json body of information into a Python Dictionary
    assignmentApiDict = json.loads(assignmentApiText)
    
    ## If the assignment is published and is visible to at least one student
    if assignmentApiDict["published"] and assignmentApiDict["assignment_visibility"]:

        ## Return True
        return True

    ## If the assignment is not published or is not visible to at least one student
    else:
        
        ## Return False
        return False

## This function processes a rubric with the desired outcome and returns true if the rubric is attached to a published assignment within the course
def rubricIsAttachedToAPublishedAssignmentCheck(p1_courseRubricApiUrl, p1_rubricId):
    functionName = "Rubric Is Attached To A Published Assignment Check"

    ## Define the rubric specific api url by replacing the per page piece with a / and the rubric's id
    ## on the all rubrics api url
    rubricApiUlr = p1_courseRubricApiUrl.replace("?per_page=100", "/" + str(p1_rubricId))

    ## Define the api payload to include associations
    rubricApiPayload = {"include": ["assessments", "graded_assessments", "assignment_associations"]}

    ## Make a variable to hold the course's rubric api object
    rubricApiObject = None
    ## Try to get the api object, but count 404 errors as not attached to published assignment
    try:
        rubricApiObject = makeApiCall(localSetup, p1_apiUrl = rubricApiUlr, p1_payload = rubricApiPayload)
    except Exception as Error:
        msg = str(Error)
        ## If the error is a 404 error, the rubric may be in an unsaved state or deleted, so return false
        if "HTTP 404" in msg or "Rubric not found" in msg:
            return False
        else:
            raise

                    
    ## Save the primary body of information retrieved by the API call
    rubricApiText = rubricApiObject.text
        
    ## Convert the json body of information into a Python Dictionary
    rubricApiDict = json.loads(rubricApiText)
                    
    ## Define a boolean variable to track whether the rubric is attached to any published assignments
    ## in the relavent course
    attachedToPublishedAssignment = False

    ## If the rubric has associations in its keys
    if "associations" in rubricApiDict.keys():
        
        ## If the associations key has a value
        if rubricApiDict["associations"]:

            ## For each association
            for association in rubricApiDict["associations"]:

                ## If attachedToPublishedAssignment is still false
                if not attachedToPublishedAssignment:
                
                    ## If the association is an assignment
                    if (association["association_type"] == "Assignment"):
                        attachedToPublishedAssignment = assignmentIsPublishedCheck(rubricApiUlr, association["association_id"])

    return attachedToPublishedAssignment

## This function 

## This function Checks a course's rubrics for outcome alignments
## and checks to see if the rubric is attached to a published assignment
## Updating the p1_uniqueAttachedOutcomes dict to be true for the outcome
## if the rubric is attached to a published assignment
def checkRubricOutcomeAlignment(p1_row, p1_targetCourseSisId, p1_uniqueAttachedOutcomes, p1_uniqueAttachedOutcomesVendorGuidDict):
    functionName = "Check Rubric Outcome Alignment"

    try:
        ## Define a dict to hold the rubric ids of rubrics with the desired outcomes with values of the outcomes that are attached
        rubricsWithOutcomes = {}
            
        ## Define the course's API rubric call url
        courseRubricApiUlr = coreCanvasApiUrl + "courses/sis_course_id:" + p1_targetCourseSisId + "/rubrics" + "?per_page=100"
            
        ## Make a variable to hold the course's rubric api object
        courseRubricApiObject = makeApiCall(localSetup, p1_apiUrl = courseRubricApiUlr)
            
        ## Save the primary body of information retrieved by the API call
        course_rubrics_api_call_text_jsonString = courseRubricApiObject.text
        
        ## Convert the json body of information into a Python Dictionary
        course_rubrics_api_call_text_dict = json.loads(course_rubrics_api_call_text_jsonString)
            
        ## Go through each rubric in the text dict
        for rubric in course_rubrics_api_call_text_dict:
                
            ## Go through each of the rubrics criterion
            for criterion in rubric["data"]:

                ## Define a refined criterion title and variable by replacing the unicode character
                criterionTitle = criterion["title"].replace('\u200b', '') if "title" in criterion.keys() \
                    else ""
                criterionDescription = criterion["description"].replace('\u200b', '') if "description" in criterion.keys() \
                    else ""

                ## Define the target identifier for the outcome as the title if it exists and contains the outcome area, otherwise the description
                targetOutcomeIdentifier = (criterionTitle 
                                           if (criterionTitle 
                                               and p1_row['Outcome Area'] in criterionTitle
                                               ) 
                                           else criterionDescription
                                           )
                
                ## If the criterion is an outcome
                if 'learning_outcome_id' in criterion.keys():

                    ## If the title of the outcome is in uniqueAttachedOutcomes
                    if targetOutcomeIdentifier in p1_uniqueAttachedOutcomes.keys():

                        ## Add the rubric id as a key and the outcome as a value in a list to the rubrics with outcomes dict, appending the outcome if the key already exists
                        rubricsWithOutcomes.setdefault(rubric["id"], []).append(targetOutcomeIdentifier)

                        
                    ## Otherwise check to see if the vendor id matches
                    else:    

                        ## Define a Get outcome api url
                        outcomeApiUrl = f"{coreCanvasApiUrl}outcomes/{criterion['learning_outcome_id']}"

                        ## Make a variable to hold the outcome api object
                        outcomeApiObject = makeApiCall(localSetup, p1_apiUrl = outcomeApiUrl)
                        
                        ## Save the primary body of information retrieved by the API call
                        outcomeApiText = outcomeApiObject.text
                        
                        ## Convert the json body of information into a Python Dictionary  
                        outcomeApiDict = json.loads(outcomeApiText)

                        ## Define a refined outcome title variable by replacing the unicode character
                        outcomeTitle = outcomeApiDict["title"].replace('\u200b', '')
                
                        ## If the vendor_guid of the outcome is in the keys of the uniqueAttachedOutcomesVendorGuidDict or if the title of the outcome is in uniqueAttachedOutcomes
                        if outcomeApiDict["vendor_guid"] in p1_uniqueAttachedOutcomesVendorGuidDict.values():

                            ## Add the rubric id as a key and the outcome as a value in a list to the rubrics with outcomes dict, appending the outcome if the key already exists
                            rubricsWithOutcomes.setdefault(rubric["id"], []).append(outcomeTitle)

                    
        ## For each rubric in the rubrics with outcomes list 
        for rubric_id in rubricsWithOutcomes:
            
            ## If the rubric is attached to a published assignment
            if rubricIsAttachedToAPublishedAssignmentCheck(courseRubricApiUlr, rubric_id):

                ## For each outcome in the list of outcomes attached to the rubric
                for outcome in rubricsWithOutcomes[rubric_id]:

                    ## If the outcome's value in the unique outcomes attached dict is still false
                    if p1_uniqueAttachedOutcomes[outcome] == False:

                        ## Set the value to true
                        p1_uniqueAttachedOutcomes[outcome] = True

    ## If there is an error
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function checks the rubrics in each course on the list to see which, if any, have the required outcome/s 
## and if those rubrics are attached to a published assignment. It adds the course to the naughty list if any of 
## these checks come back false
def outcomeAttachmentReport(row, p1_rawOutcomesDF, p1_outcomeCoursesMissingAttachmentsDataDict):
    functionName = "Check Outcome Attachments"

    try:

        ## All courses sis ids should be strings, otherwise there is an issue with the row so ignore it
        if not isinstance(row["Course_sis_id"], str):
            return
    
        ## Make variables for the relavent course information
        courseSisId = row["Course_sis_id"]
        courseName = row["Course_name"]
        parentCourseSisId = row["Parent_Course_sis_id"]
        targetCourseSisId = None

        ## If there is a parent course id
        if (not pd.isna(row["Parent_Course_sis_id"]) 
        and row["Parent_Course_sis_id"] not in ["", None]
        ):
            
            ## Set the target course id to the parent course id
            targetCourseSisId = row["Parent_Course_sis_id"]

        ## If there is no parent course id
        else:
            
            ## Set the target course id to the course id
            targetCourseSisId = courseSisId

        ## Make a dict of the unique outcomes associated with the course
        uniqueAttachedOutcomes = {row[key]: False for key in row.index 
            if "Outcome" in key 
            and "Area" not in key 
            and str(row[key]) != "nan"
            }
            
        ## Make a filtered df by keeping only the rows where the outcome is in the uniqueAttachedOutcomes and the row['Outcome Area'] is in the title
        outcomesDF = p1_rawOutcomesDF[
            (p1_rawOutcomesDF['title'].isin(uniqueAttachedOutcomes.keys()))
             & (p1_rawOutcomesDF['title'].str.contains(row['Outcome Area']))
             ]
        
            
        ## Make a dict with the outcome titles as keys and the vendor_guids as values
        uniqueAttachedOutcomesVendorGuidDict = {row['title']: row['vendor_guid'] for index, row in outcomesDF.iterrows()}
        
        ## Check the rubrics in the course for the desired outcomes
        checkRubricOutcomeAlignment(row, targetCourseSisId, uniqueAttachedOutcomes, uniqueAttachedOutcomesVendorGuidDict)

        ## If any of the unique outcomes attached to the course are still false
        ##if False in uniqueAttachedOutcomes.values():

            ## Check the new quizzes in the course for the desired outcomes


        ## If any of the unique outcomes attached to the course are continue to be false after checking the rubrics and quizz
        if False in uniqueAttachedOutcomes.values():
            
            ## Make a list of the outcomes that are still false
            missingOutcomes = [key for key, value in uniqueAttachedOutcomes.items() if value == False]

            ## Make a list of instructor name values that are non nan
            instructorNames = [row[instructorColumn] for instructorColumn in row.index if (
                "name" in instructorColumn
                and "Instructor" in instructorColumn
                and not pd.isna(row[instructorColumn])
                )
            ]
            
            ## Make a list of the instructor email values that are non nan
            instructorEmails = [row[instructorColumn] for instructorColumn in row.index if (
                "email" in instructorColumn
                and "Instructor" in instructorColumn
                and not pd.isna(row[instructorColumn])
                )
            ]
            
            ## Make a string of the missing outcomes
            missingOutcomesString = ", ".join(missingOutcomes)

            ## If there is more than one outcome in the missing outcomes list
            if len(missingOutcomes) > 1:
            
                ## Get the last outcome in the missing outcomes list
                lastMissingOutcome = missingOutcomes[-1]
            
                ## Replace the last outcome in the missing outcomes list with "and" + the last outcome
                missingOutcomesString = missingOutcomesString.replace(lastMissingOutcome, f"and {lastMissingOutcome}")

            ## Make a string of the teacher names
            instructorNamesString = ", ".join(instructorNames)
            
            ## Make a string of the teacher emails
            instructorEmailsString = ", ".join(instructorEmails)
            
            ## Add the course's information to the dictionary of courses missing outcomes
            p1_outcomeCoursesMissingAttachmentsDataDict["Course_name"].append(courseName)
            p1_outcomeCoursesMissingAttachmentsDataDict["Required Outcome"].append(missingOutcomesString)
            p1_outcomeCoursesMissingAttachmentsDataDict["Issue"].append("The Associated Outcome/s is/are not attached to a published assignment")
            p1_outcomeCoursesMissingAttachmentsDataDict["Instructor Name"].append(instructorNamesString)
            p1_outcomeCoursesMissingAttachmentsDataDict["Instructor Email"].append(instructorEmailsString)

    except Exception as Error:
        errorHandler.sendError (functionName, Error)
                    
  
## This function processes the rows of the CSV file and sends on the relavent data to process_course
def termOutcomeAttachmentReport (p1_inputTerm
                                 , p1_targetDesignator
                                 ):
    functionName = "Term OutcomeAttachment Report"

    try:
       
        ## Extract term prefix and decade
        ## Extract term prefix and decade
        termCodePrefix = p1_inputTerm[:2]  ## e.g., "FA", "SP", "SU"
        termWord = undgTermsCodesToWordsDict.get(termCodePrefix, gradTermsCodesToWordsDict.get(termCodePrefix))
        termYear = int(str(localSetup.dateDict["century"]) + p1_inputTerm[2:])

        ## Build local paths  
        designatorLocalOutputPath = localSetup.getTargetDesignatedOutputPath(termWord, termYear, p1_targetDesignator)

        ## Ensure directories exist
        os.makedirs(designatorLocalOutputPath, exist_ok=True)

        ## Define the output file name
        termOutputFileName = f"{p1_inputTerm}_{p1_targetDesignator}_Outcome_Attachment_Report.csv"

        ## Build the designated internal output path
        targetDestinationFilePath = os.path.join(designatorLocalOutputPath, termOutputFileName)

        ## If the file is recent return
        if isFileRecent(localSetup, targetDestinationFilePath):
            return targetDestinationFilePath
            
        ## Retrieve Automated Outcome Tool Variables
        automatedOutcomeToolVariablesDf = pd.read_excel(
            os.path.join(localSetup.getExternalResourcePath("TLC"), "Automated Outcome Tool Variables.xlsx")
        )
        targetAccountName = automatedOutcomeToolVariablesDf.loc[
            automatedOutcomeToolVariablesDf["Target Designator"] == p1_targetDesignator,
            "Outcome Location Account Name"
        ].values[0]

        ## Retrieve the current outcomes csv file path
        rawOutcomesDF = CanvasReport.getOutcomesDf(localSetup, p1_inputTerm, targetAccountName, p1_targetDesignator)

        ## Remove the unicode character from the title column
        rawOutcomesDF['title'] = rawOutcomesDF['title'].str.replace('\u200b', '')

        ## Get the relavent term's course report as a df
        termActiveOutcomeCoursesDF = CanvasReport.getActiveOutcomeCoursesDf(localSetup, p1_inputTerm, p1_targetDesignator)
        
        ## For each column in the term active Outcome courses df
        for column in termActiveOutcomeCoursesDF.columns:

            ## If the column has outcome in the name and doesn't have area in the name
            if "Outcome" in column and "Area" not in column:
                
                ## Replace any nan values with ""
                termActiveOutcomeCoursesDF[column].fillna("")

        ## Define a dict to hold the assignment data for published assignments with outcomes
        outcomeCoursesMissingAttachments = {
            "Course_name": []
            , "Required Outcome": []
            , "Issue": []
            , "Instructor Name": []
            , "Instructor Email": []
            }
        
        ## Create a list to hold the ongoing outcome attachment report threads
        outcomeAttachmentReportThreads = []
        
        ## For each row in the termActiveOutcomeCoursesDF
        for index, row in termActiveOutcomeCoursesDF.iterrows():

            ## Target a specific course for testing if needed
            ##if row['Course_sis_id'] == "GF2024_EDUC7160_7A":
            
                ## If the row is not a nan
                if not pd.isna(row["Course_sis_id"]):
                
                    ## Create a thread to process the row
                    outcomeAttachmentReportThread = threading.Thread(target=outcomeAttachmentReport
                                                                     , args=(row
                                                                             , rawOutcomesDF
                                                                             , outcomeCoursesMissingAttachments
                                                                             )
                                                                     )
                
                    ## Start the thread
                    outcomeAttachmentReportThread.start()
                
                    ## Add the thread to the ongoing threads list
                    outcomeAttachmentReportThreads.append(outcomeAttachmentReportThread)
                
        ## For each thread in the ongoing threads list
        for thread in outcomeAttachmentReportThreads:
            
            ## Wait for the thread to finish
            thread.join()
            
        ## If any of the lists in the outcomeCoursesMissingAttachments dict are not empty
        if any([len(outcomeCoursesMissingAttachments[key]) > 0 for key in outcomeCoursesMissingAttachments.keys()]):
            
            ## Create a dataframe from the outcomeCoursesMissingAttachments dict
            outcomeCoursesMissingAttachmentsDF = pd.DataFrame(outcomeCoursesMissingAttachments)

            ## Save the dataframe to a csv to both the local and external output paths
            outcomeCoursesMissingAttachmentsDF.to_csv(f"{targetDestinationFilePath}", index = False)

        return targetDestinationFilePath

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

if __name__ == "__main__":

    ## Define the API Call header using the retreived Canvas Token
    ##header = {'Authorization' : f"Bearer {canvasAccessToken}"}

    ## Start and download the Canvas report
    termOutcomeAttachmentReport (
        p1_inputTerm = input("Enter the desired term in four character format (FA20, SU20, SP20): ")
        , p1_targetDesignator = input("Enter the desired target designator (GE, I-EDUC, U-ENGR): ")
        )

    input("Press enter to exit")

## ===========================================================================
## FILE: ReportModules\Outcome_Results_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller


from datetime import datetime
import traceback, os, logging, sys, re, threading, shutil, ast, json
import pandas as pd, numpy as np, time

## Add Script repository to syspath
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

## New resource modules
from Local_Setup import LocalSetup
from TLC_Common import makeApiCall, isFileRecent
from Canvas_Report import CanvasReport
from Common_Configs import coreCanvasApiUrl
from Error_Email import errorEmail

## Create the localsetup variable
localSetup = LocalSetup(datetime.now(), __file__)  ## sets cwd, paths, logs, date parts

from Common_Configs import undgTermsCodesToWordsDict, gradTermsCodesToWordsDict

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
This script (Outcome_Results_Report) views the active GE course lists and Outcome Results reports for a given term,
and creates a report that shows which courses have outcome data for the required GE outcomes. The script also creates
a csv report to that shows the highest scoring outcome for each student in each course. The script saves the reports
in the Canvas Resources folder and the Institutional Effectiveness shared drive.
"""
externalRequirements = r"""
To function properly this script requires access to the institutions Canvas instance via an Active Canvas Bearer Token
"""

## Setup the error handler
errorHandler = errorEmail(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function checks whether each outcome course has outcome data of the required type
def termCreateOutcomeComplianceReport(
        p3_inputTerm
        , p2_schoolYear
        , p2_uniqueOutcomeInfoDictOfDicts
        , p2_outcomeResultDF
        , p2_activeCanvasOutcomeCoursesDf
        , p2_accountInfoDF
        , p1_targetAccountDataDict
        , p2_termEnrollmentDf
        ):
    functionName = "Term Outcome Results Info"

    try:

        ## If the p1_combinedTermoutcomeResultDF is not empty
        if not p2_outcomeResultDF.empty:
            
            ## Define a dict to hold the outcome result report
            outcomeResultReportDict = {
                "Term_ID" : []
                , "School_Year" : []
                , "Term_Year" : []
                , "Course_name" : []
                , "Course_code" : []
                , "Course_section" : []
                , "Course_Section_ID" : []
                , "Instructor_Name_List" : []
                , "Number_of_students" : []
                , "Canvas_Account_id" : []
                , "Account_Canvas_ID" : []
                , "College" : []
                , "Discpline" : []
                , "Department" : []
                , "Outcome_Area": []
                , "Outcome_Title" : []
                , "Outcome_Name" : []
                , "Outcome_Parent" : []
                , "Outcome_Root" : []
                , "Outcome_Id" : []
                , "Outcome_Version" : []
                , "Outcome_group title" : []
                , "Vendor_Guid": []
                , "Number_of_Students_With_Submission_Records_for_Outcome_Assignments" : []
                , "Students_Missing_Submission_Records_for_Outcome_Assignments" : []
                , "Number of Students assessed" : []
                , "Assessment_Status" : []
                }

            ## For each course in the p1_targetDesignatorActiveCanvasOutcomeCoursesDf
            for index, course in p2_activeCanvasOutcomeCoursesDf.iterrows():

                ## If the courseDict's course_sis_id has 3400 in it
                ##if "EDUC3750" in course["Course_sis_id"]:

                    ## Define a target course sis id
                    targetCourseSisId = course["Course_sis_id"]
                    termID = course["Course_sis_id"].split("_")[0][:2] + course["Course_sis_id"].split("_")[0][4:]
                    termYear = course["Course_sis_id"].split("_")[0][4:]

                    ## If there is a non nan Parent_Course_sis_id
                    if not pd.isna(course["Parent_Course_sis_id"]) and course["Parent_Course_sis_id"] not in ["", None]:

                        ## Set the target course sis id to the Parent_Course_sis_id
                        targetCourseSisId = course["Parent_Course_sis_id"]

                    ## Make a course info dict
                    courseInfoDict = {"Term_ID" : termID
                                      , "School_Year" : p2_schoolYear
                                      , "Term_Year" : termYear
                                      , "Course_name" : course["Course_name"]
                                      , "Course_code" : course["Course_sis_id"].split("_")[1]
                                      , "Course_section" : course["Course_sis_id"].split("_")[2]
                                      , "Course Section ID" : course["Section_id"]
                                      , "Instructor_Name_List" : ", ".join([course[instructorColumn] 
                                                                  for instructorColumn in course.index.tolist() 
                                                                  if ("Instructor" in instructorColumn
                                                                      and "name" in instructorColumn
                                                                      and (course[instructorColumn] != ""
                                                                           and str(course[instructorColumn]) != "nan"
                                                                           )
                                                                      )
                                                                  ])
                                      , "Number_of_students" : course["Number_of_students"]
                                      , "Canvas_Account_id" : course["Canvas_Account_id"]
                                      , "Account_Canvas_ID": p2_accountInfoDF.loc[
                                          p2_accountInfoDF["canvas_account_id"] == course["Canvas_Account_id"]
                                          , "canvas_account_id"
                                          ].values[0] if course["Canvas_Account_id"] != 1 else 1
                                      , "College" : ""
                                      , "Discpline" : ""
                                      , "Department" : ""
                                      }
                
                    #######################################################################
                    ## The following for course code uses the Account_ID column to determine each 
                    ## course's department and college and add them to the college and department 
                    ## list to be added to the outcomeResultReportDF in place of the Account_ID column
                    #######################################################################

                    ## If the account id is not already in the dict
                    if courseInfoDict["Canvas_Account_id"] not in p1_targetAccountDataDict.keys():

                        ## Determine what the save path for the department would be (which is determined by the parent 
                        ## accounts for the particular sub account)
                        courseDepartmentPath = CanvasReport.determineDepartmentSavePath (localSetup, courseInfoDict["Canvas_Account_id"])

                        ## Split the path by \\ to seperate the college, department, and sub department where applicable
                        courseDepartmentPathSeperated = courseDepartmentPath.split("\\")

                        ## The course college (## e.g. College of Business) is always the 0th element of the section 
                        courseInfoDict["College"] = courseDepartmentPathSeperated[0].replace("College of ", "")

                        ## Append the college name to the p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] list as the 0th element
                        p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] = [courseInfoDict["College"]]

                        ## The length of the seperated sections list tells whether the college is made of multiple disciplines
                        ## or if it is all one. This changes where the department name is placed in the section list
                        courseDepartmentPathNumberOfSections = len(courseDepartmentPathSeperated)

                        ## If the length of the section list == 4, the college contains multiple disciplines
                        if courseDepartmentPathNumberOfSections == 4:

                            ## The discpline names (## e.g. Music) for college's with multiple disciplines is the 2nd element
                            ## of the section list. Append the discpline name to the p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] list as the 1st element
                            courseInfoDict['Discpline'] = courseDepartmentPathSeperated[1]
                            p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]].append(courseInfoDict['Discpline'])

                            ## The department (## e.g. Undergraduate Music, Undergraduate_NNUO Music) is made by combining the
                            ## 2nd element in the list and the course discpline
                            courseInfoDict["Department"] = f"{courseDepartmentPathSeperated[2]} {courseInfoDict['Discpline']}"

                            ## Append the department name to the p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] list as the 2nd element
                            p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]].append(courseInfoDict["Department"])

                        ## If the length of the section list isn't 4
                        else:
                            ## The college name and discipline name is the same
                            courseInfoDict['Discpline'] = courseInfoDict["College"]

                            ## Append the discpline name to the p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] list as the 1st element
                            p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]].append(courseInfoDict['Discpline'])

                            ## The department (## e.g. Undergraduate Nursing, Undergraduate RN-BSN Nursing) for single
                            ## discipline colleges is made of up the secondary department component (## e.g. Undergraduate, Undergraduate RN-BSN)
                            ## and the College discipline (## e.g. Nursing). 
                            courseInfoDict["Department"] = f"{courseDepartmentPathSeperated[1]} {courseInfoDict['Discpline']}"

                            ## Append the department name to the p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] list
                            p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]].append(courseInfoDict["Department"])
                        
                    ## If the account id is already in the dict
                    else:
                    
                        ## Set the courseInfoDict["College"] to the 0th element of the p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] list
                        courseInfoDict["College"] = p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]][0]
                    
                        ## Set the courseInfoDict['Discpline'] to the 1st element of the p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] list
                        courseInfoDict['Discpline'] = p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]][1]
                    
                        ## Set the courseInfoDict["Department"] to the 2nd element of the p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]] list
                        courseInfoDict["Department"] = p1_targetAccountDataDict[courseInfoDict["Canvas_Account_id"]][2]

                    ## For each column in the aux term report df that doesn't have area in the title
                    for column in course.index.tolist():

                        ## If the column doesn't have area in the title
                        if "Outcome" in column and "Area" not in column:
                        
                            ## If there is no outcome value in the column
                            if str(course[column]).strip() == "" or str(course[column]).lower() == "nan":
                            
                                ## Skip the column
                                continue

                            ## Get the outcome info dict
                            outcomeInfoDict = p2_uniqueOutcomeInfoDictOfDicts[course[column]]

                            ## Filter the outcome results to only include the current course, section, and the current outcome
                            targetCourseOutcomeResults = p2_outcomeResultDF[
                                (p2_outcomeResultDF["course name"] == courseInfoDict["Course_name"])
                                & (p2_outcomeResultDF["section id"] == courseInfoDict["Course Section ID"])
                                & (
                                    (p2_outcomeResultDF["learning outcome name"].str.contains(outcomeInfoDict["Outcome_Name"]))
                                    | (p2_outcomeResultDF["learning outcome id"] == outcomeInfoDict["Outcome_Id"])
                                    )
                                ]
                            ##targetCourseOutcomeResults = p1_combinedTermoutcomeResultDF[p1_combinedTermoutcomeResultDF["course name"] == course["Course_name"]]

                            ## Find the number of students with an outcome result after filtering to only contain rows that have a "learning outcome rating points" value
                            numOfStuWithOutcomeResults = targetCourseOutcomeResults.dropna(
                                subset=["learning outcome rating points"]
                                )["student id"].nunique()
                        
                            ##numOfStuWithOutcomeResults = targetCourseOutcomeResults["student id"].nunique()

                            ## Record the number of students with outcome results
                            outcomeInfoDict["Number of Students assessed"] = numOfStuWithOutcomeResults
                        
                            ## Define lists to track what students submitted to outcome assignments
                            listOfStudentsWithSubmissionRecordsForOutcomeAssignments = []
                            outcomeInfoDict["Students_Missing_Submission_Records_for_Outcome_Assignments"] = []
                        
                            ## If there are any outcome results for the course
                            if numOfStuWithOutcomeResults > 0:

                                ## If the course sis id == FA2024_PHYS1010_1U
                                ## if course["Course_sis_id"] == "FA2024_PHYS1010_1U":

                                ##     print (1)
                        
                                ## Get the unique assignment ids
                                uniqueAssignmentIds = targetCourseOutcomeResults["assessment id"].unique()
                            
                                ## For each unique assignment id
                                for assignmentId in uniqueAssignmentIds:
                                
                                    ## Define a assignment results api url
                                    assignmentResultsApiUrl = f"{coreCanvasApiUrl}courses/sis_course_id:{targetCourseSisId}/assignments/{assignmentId}/submissions"
                                
                                    ## Make a call to the assignment results api
                                    assignmentResultsObject = makeApiCall(
                                        localSetup
                                        , p1_apiUrl = assignmentResultsApiUrl
                                        , p1_payload = {"include[]": ['user']}
                                        )
                                
                                    ## Define a variable to hold the raw object link list/s
                                    rawAccountOutcomeLinksList = []

                                    ## If the object is actually a list of objects
                                    if isinstance(assignmentResultsObject, list):

                                        ## For each response object in the list
                                        for accountOutcomeLinkObject in assignmentResultsObject:
                    
                                            ## If the response was a 200
                                            if accountOutcomeLinkObject.status_code == 200:

                                                ## Extend the assignmentResultsList with the object
                                                rawAccountOutcomeLinksList.extend(accountOutcomeLinkObject.json())

                                    ## Otherwise there was just one response
                                    else:
                
                                        ## If the status code was a 200
                                        if assignmentResultsObject.status_code == 200:

                                            ## Extend the assignmentResultsList with the object
                                            rawAccountOutcomeLinksList.extend(assignmentResultsObject.json())

                                    ## For each object in the rawAccountOutcomeLinksList
                                    for responseOjbect in rawAccountOutcomeLinksList:

                                        ## Filter the p2_termEnrollmentDf to only contain the current student
                                        targetStudentDf = p2_termEnrollmentDf[p2_termEnrollmentDf["canvas_user_id"] == responseOjbect["user_id"]]

                                        ## Further filter it to contain only the student's enrollment in the current course if it exists
                                        targetStudentCourseDf = targetStudentDf[targetStudentDf["course_id"] == targetCourseSisId]

                                        ## If the targetStudentCourseDf is not empty and the status is active
                                        if not targetStudentCourseDf.empty and targetStudentCourseDf["status"].values[0] != "deleted":
                                    
                                            ## If "user_id" hasn't already been added to the list
                                            ## and they are not the test student (indicated by a null excused field)
                                            ## and their assignment is not missing
                                            if (responseOjbect["user_id"] not in listOfStudentsWithSubmissionRecordsForOutcomeAssignments):
                                        
                                                ## If the excused field niether null nor true and the assignment is not missing
                                                if (str(responseOjbect["excused"]).lower() not in ["null", "true"]
                                                and str(responseOjbect["missing"]).lower() != "true"
                                                ):
                                                
                                                    ## Add it to the list of students with submission records for outcome assignments
                                                    listOfStudentsWithSubmissionRecordsForOutcomeAssignments.append(responseOjbect["user_id"])

                                                    ## If the id was in outcomeInfoDict["Students_Missing_Submission_Records_for_Outcome_Assignments"]
                                                    if (responseOjbect["user_id"] in outcomeInfoDict[
                                                        "Students_Missing_Submission_Records_for_Outcome_Assignments"
                                                        ]):

                                                        ## Remove it from the list of students missing submission records for outcome assignments
                                                        outcomeInfoDict[
                                                            "Students_Missing_Submission_Records_for_Outcome_Assignments"
                                                            ].remove(responseOjbect["user"]["sis_user_id"])
                                                    
                                                ## Else if the missing status is true
                                                ## and the id is not already in outcomeInfoDict["Students_Missing_Submission_Records_for_Outcome_Assignments"]        
                                                elif (
                                                    str(responseOjbect["missing"]).lower() == "true"
                                                    and responseOjbect["user_id"] not in outcomeInfoDict[
                                                        "Students_Missing_Submission_Records_for_Outcome_Assignments"
                                                        ]
                                                    ):
                                                    
                                                    ## Add it to the list of students missing submission records for outcome assignments
                                                    outcomeInfoDict[
                                                        "Students_Missing_Submission_Records_for_Outcome_Assignments"
                                                        ].append(responseOjbect["user"]["sis_user_id"])

                                ## Record the "Number_of_Students_With_Submission_Records_for_Outcome_Assignments"
                                outcomeInfoDict[
                                    "Number_of_Students_With_Submission_Records_for_Outcome_Assignments"
                                    ] = len(listOfStudentsWithSubmissionRecordsForOutcomeAssignments)
                                        
                                ## If numOfStuWithOutcomeResults is equal to or greater than .75 of the the length of the listOfStudentsWithSubmissionRecordsForOutcomeAssignments
                                if numOfStuWithOutcomeResults >= (len(listOfStudentsWithSubmissionRecordsForOutcomeAssignments) * .75):
                            
                                    ## Set the "Assessment_Statusa" column to "Yes"
                                    outcomeInfoDict["Assessment_Status"] = "Assessed"
                            
                                ## Otherwise
                                else:
                            
                                    ## Set the "Assessment_Status" column to "Partial"
                                    outcomeInfoDict["Assessment_Status"] = "Partially Assessed"
                                
                            ## Otherwise
                            else:
                            
                                ## Set the "Assessment_Status" column to "Not Assessed"
                                outcomeInfoDict["Assessment_Status"] = "Not Assessed"
                            
                                ## Set the "Number_of_Students_With_Submission_Records_for_Outcome_Assignments" to 0
                                outcomeInfoDict["Number_of_Students_With_Submission_Records_for_Outcome_Assignments"] = 0

                            ## For each key in the course info dict
                            for key in courseInfoDict.keys():

                                ## Replace the " " in the course info dict key to make the outcome result report dict key
                                outcomeResultReportDictKey = key.replace(" ", "_")
                            
                                ## Append the value to the outcomeResultReportDict
                                outcomeResultReportDict[outcomeResultReportDictKey].append(courseInfoDict[key])
                            
                            ## For each key in the outcome info dict
                            for key in outcomeInfoDict.keys():

                                ## Append the value to the outcomeResultReportDict
                                outcomeResultReportDict[key].append(outcomeInfoDict[key])
                    
            ## Convert the outcomeResultReportDict to a df
            outcomeResultReportDF = pd.DataFrame(outcomeResultReportDict)        

            ## Return the outcomeResultReportDF
            return outcomeResultReportDF

        ## Otherwise
        else:
            
            ## Return an empty dataframe
            return pd.DataFrame()

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function compiles the outcome scores from the outcome results report into longitudinal data
def termCompileCourseOutcomesScores (p1_CourseDict
                                    , p1_targetTermEnrollmentDf
                                    , p1_targetOutcomeResultsDf
                                    , p1_targetOutcomeResultReportDf
                                    , p1_outcomeResultsDashboardDataDictList
                                    , p2_uniqueOutcomeInfoDictOfDicts
                                    ):
        
    functionName = "Term Compile Outcome Scores"

    try:

        ## For each unique student of the course
        #for studentID in p1_targetTermEnrollmentDf["user_id"].astype(int).unique():
        for studentID in p1_targetTermEnrollmentDf["user_id"].unique():
            
            ## For each column with a value that has outcome and not area in the title of p1_CourseDict
            for column in (column 
                           for column in p1_CourseDict.index.tolist() 
                           if ("Outcome" in column 
                               and "Area" not in column
                               and pd.notna(p1_CourseDict[column])
                               and str(p1_CourseDict[column]).strip() not in ("", "nan", "none", "NaN", "None")
                               )
                           ):
                                
                ## Create a Outcome Name Variable
                outcomeFullTitle = p1_CourseDict[column]

                ## Get the outcome id and outcome name for the column from p2_uniqueOutcomeInfoDictOfDicts
                outcomeId = p2_uniqueOutcomeInfoDictOfDicts[
                    outcomeFullTitle
                    ]["Outcome_Id"]
                outcomeName = p2_uniqueOutcomeInfoDictOfDicts[outcomeFullTitle]["Outcome_Name"]

                ## Get the target unique outcome info dict
                targetUniqueOutcomeInfoDict = p2_uniqueOutcomeInfoDictOfDicts[outcomeFullTitle]
                    
                ## Filter the target outcome results df to only contain the current student and outcome 
                ## results that either match the outcome id or contains the name of the outcome
                targetStudentOutcomeResults = p1_targetOutcomeResultsDf[
                    (p1_targetOutcomeResultsDf["student sis id"] == studentID)
                    & (
                        (p1_targetOutcomeResultsDf["learning outcome id"] == outcomeId)
                        | (p1_targetOutcomeResultsDf["learning outcome name"].str.contains(outcomeName))
                        )
                    ]

                ## If any of the targetStudentOutcomeResults's learning outcome name values are not 
                ## equal to the outcomeName and match one of the keys in p2_uniqueOutcomeInfoDictOfDicts
                if (not targetStudentOutcomeResults.empty
                    and targetStudentOutcomeResults[
                        "learning outcome name"
                        ].str.contains(
                            outcomeFullTitle
                            ).any()
                    and not targetStudentOutcomeResults[
                        "learning outcome name"
                        ].str.contains(
                            outcomeFullTitle
                            ).all()
                    and any(
                        targetStudentOutcomeResults[
                            "learning outcome name"
                            ].isin(
                                p2_uniqueOutcomeInfoDictOfDicts.keys()
                                )
                        )
                    ):

                    ## Filter out those that are in p2_uniqueOutcomeInfoDictOfDicts and are not equal to the outcomeFullTitle
                    targetStudentOutcomeResults = targetStudentOutcomeResults[
                        targetStudentOutcomeResults[
                            "learning outcome name"
                            ].isin(
                                p2_uniqueOutcomeInfoDictOfDicts.keys()
                                )
                        & ~targetStudentOutcomeResults[
                            "learning outcome name"
                            ].str.contains(
                                outcomeFullTitle
                                )
                        ]

                ## Define the relevent instructor name
                instructorName = p1_targetOutcomeResultReportDf["Instructor_Name_List"].values[0]
                        
                ## Define the outcome information using the targetUniqueOutcomeInfoDict
                outcomeRoot = targetUniqueOutcomeInfoDict["Outcome_Root"]
                outcomeParent = targetUniqueOutcomeInfoDict["Outcome_Parent"]
                outcomeVersion = targetUniqueOutcomeInfoDict["Outcome_Version"]
                outcomeGroupTitle = targetUniqueOutcomeInfoDict["Outcome_group title"]
                
                ## Define the term and course information using the course sis id
                termYear = p1_CourseDict["Course_sis_id"].split("_")[0]
                courseID = p1_CourseDict["Course_sis_id"]
                courseCode = p1_CourseDict["Course_sis_id"].split("_")[1]
                courseSection = p1_CourseDict["Course_sis_id"].split("_")[2]
                
                ## Initialize outcomeDashboardDataDict with the relavent information from the row and places for future data
                outcomeDashboardDataDict = {"Term_Year" : termYear
                                            , "Course_ID" : courseID
                                            , "Course_code" : courseCode
                                            , "Course_Section" : courseSection
                                            , "Instructor" : instructorName
                                            , "Outcome_Title" : outcomeFullTitle
                                            , "Outcome_Name" : outcomeName
                                            , "Outcome_Id" : outcomeId
                                            , "Outcome_Root" : outcomeRoot
                                            , "Outcome_Parent" : outcomeParent
                                            , "Outcome_Version" : outcomeVersion
                                            , "Outcome_group title" : outcomeGroupTitle
                                            , "College" : p1_targetOutcomeResultReportDf["College"].values[0]
                                            , "Discpline" : p1_targetOutcomeResultReportDf["Discpline"].values[0]
                                            , "Department" : p1_targetOutcomeResultReportDf["Department"].values[0]
                                            , "Student Canvas Id" : studentID
                        }
                    
                ## If the targetStudentOutcomeResults is not empty and the student name dict is not empty
                if (not targetStudentOutcomeResults.empty 
                    and not targetStudentOutcomeResults['student name'].isnull().all()
                    and not targetStudentOutcomeResults['learning outcome rating'].isnull().all()
                    ):
                        
                    ## Find the row of p1_targetOutcomeResultReportDf that has the highest rating points
                    highestRatingPointsEntry = targetStudentOutcomeResults[
                        targetStudentOutcomeResults[
                            "learning outcome rating points"
                            ] == targetStudentOutcomeResults[
                                "learning outcome rating points"
                                ].max()
                        ]
                    
                    ## Add the highest rating date points to the outcomeDashboardDataDict
                    outcomeDashboardDataDict.update({
                        "Assignment_Type" : highestRatingPointsEntry["assessment type"].values[0]
                        , "Outcome_Mastered" : highestRatingPointsEntry["learning outcome mastered"].values[0]
                        , "Outcome_rating" : highestRatingPointsEntry["learning outcome rating"].values[0]
                        , "Outcome_rating points" : highestRatingPointsEntry["learning outcome rating points"].values[0]
                    })
                        
                    
                    
                ## Otherwise
                else:

                    ## For each student missing submission records for outcome assignments value
                    for idList in p1_targetOutcomeResultReportDf[
                        "Students_Missing_Submission_Records_for_Outcome_Assignments"
                        ].values:
                        
                        ## If the ID list is not == '[]' and is not a list
                        if idList != '[]' and not isinstance(idList, list):

                            ## If the student id is in the ID list
                            if studentID in ast.literal_eval(idList):

                                ## Record the outcomeDashboardDataDict with the outcome rating points set to 0
                                outcomeDashboardDataDict.update({
                                    "Assignment_Type" : "No Assessment"
                                    , "Outcome_Mastered" : 0
                                    , "Outcome_rating" : "Outcome Not Met"
                                    , "Outcome_rating points" : 1 if "G-EDUC" in outcomeFullTitle else 0
                                })

                                ## Break the loop
                                break
                            
                        ## Else if the ID list is a list and is not empty
                        elif isinstance(idList, list) and idList != []:

                            ## If the student id is in the ID list
                            if studentID in idList:

                                ## Record the outcomeDashboardDataDict with the outcome rating points set to 0
                                outcomeDashboardDataDict.update({
                                    "Assignment_Type" : "No Assessment"
                                    , "Outcome_Mastered" : 0
                                    , "Outcome_rating" : "Outcome Not Met"
                                    , "Outcome_rating points" : 1 if "G-EDUC" in outcomeFullTitle else 0
                                })

                                ## Break the loop
                                break
                            
                    ## If there is no Outcome Raiting Points key in the outcomeDashboardDataDict
                    if "Outcome_rating points" not in outcomeDashboardDataDict.keys():
                        
                        ## Record the outcomeDashboardDataDict with the outcome rating points set to -1
                        outcomeDashboardDataDict.update({
                            "Assignment_Type" : "No Assignment"
                            , "Outcome_Mastered" : -1
                            , "Outcome_rating" : "Outcome Not Met"
                            , "Outcome_rating points" : -1
                        })

                ## Make the dict df conversion compatible
                modifiedoutcomeDashboardDataDict = {key: [value] if isinstance(value, (str, int, float, np.int32, np.int64)) else value for key, value in outcomeDashboardDataDict.items()}

                ## Convert the created dict to a df
                outcomeDashboardDataDf = pd.DataFrame(modifiedoutcomeDashboardDataDict)
        
                ## Append the df to the outcomeResultsDashboardDataDictList
                p1_outcomeResultsDashboardDataDictList.append(outcomeDashboardDataDf)

                ## localSetup.logger.info the current length of the outcomeResultsDashboardDataDictList
                localSetup.logger.info(len(p1_outcomeResultsDashboardDataDictList))
            
        ## End the function
        return

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function processes the outcome results for a given target designation
def targetDesignatorProcessOutcomeResults(
        p2_inputTerm
        , p1_schoolYear
        , p1_destinationFilePathDict
        , p1_uniqueOutcomeInfoDictOfDicts
        , p1_outcomeResultDF
        , p1_activeCanvasOutcomeCoursesDf
        , p1_accountInfoDF
        , p1_termEnrollmentDf
        ):
    
    functionName = "Term Get Outcome Results"
    
    try:

        ## Define the account data dict
        targetAccountDataDict = {}
        
        ## Define a variable to hold the outcomeResultReportDF
        outcomeResultReportDF = None
        
        ## If the first internal output report file exists
        if isFileRecent(localSetup, p1_destinationFilePathDict["Internal Output Report File Path and Name"]):

                ## Read the file into a df
                outcomeResultReportDF = pd.read_excel(p1_destinationFilePathDict["Internal Output Report File Path and Name"], sheet_name = "General")

        ## If the first internal output report wasn't found or is older than an hour
        if outcomeResultReportDF is None:
            
            ## Create the Outcome Compliance Report
            outcomeResultReportDF = termCreateOutcomeComplianceReport(
                p3_inputTerm = p2_inputTerm
                , p2_schoolYear = p1_schoolYear
                , p2_uniqueOutcomeInfoDictOfDicts = p1_uniqueOutcomeInfoDictOfDicts
                , p2_outcomeResultDF = p1_outcomeResultDF
                , p2_activeCanvasOutcomeCoursesDf = p1_activeCanvasOutcomeCoursesDf
                , p2_accountInfoDF = p1_accountInfoDF
                , p1_targetAccountDataDict = targetAccountDataDict
                , p2_termEnrollmentDf = p1_termEnrollmentDf
                )

            ## If a df returned from termCreateOutcomeComplianceReport
            if not outcomeResultReportDF.empty:
            
                ## Save the DF into an excel file
                outcomeResultReportDF.to_excel(p1_destinationFilePathDict["Internal Output Report File Path and Name"], sheet_name = "General", index=False)
                
            ## Otherwise
            else:
                
                ## Log that there are no outcome results to report on
                localSetup.logger.info("No Outcome Results to Report on. Exiting function")
                
                ## Exit the function
                return

        ## Create a list to hold the outcome results dashboard data
        outcomeResultsDashboardDataDictList = []
            
        ## Create a new column that is a combination of the student id, course id, and outcome id
        p1_outcomeResultDF["student-course-outcome id"] = p1_outcomeResultDF["student id"].astype(str) + p1_outcomeResultDF["course sis id"].astype(str) + p1_outcomeResultDF["learning outcome id"].astype(str)

        ## Create a list of the unique student-course-outcome ids
        ##uniqueStudentCourseIds = p1_outcomeResultDF["student-course-outcome id"].unique()

        ## Create a list to hold active threads
        activeThreadsList = []

        ## For each active Canvas Outcome Course
        for index, courseDict in p1_activeCanvasOutcomeCoursesDf.iterrows():

            ## If the courseDict's course_sis_id has 3400 in it
            ##if "COMM1210" in courseDict["Course_sis_id"]:
            
                ## Define a target course variables
                targetCourseSisId = courseDict["Course_sis_id"]
                targetCourseName = courseDict["Course_name"]
                targetSectionId = courseDict["Section_id"]

                ## If there is a non nan Parent_Course_sis_id
                if not pd.isna(courseDict["Parent_Course_sis_id"]) and courseDict["Parent_Course_sis_id"] not in ["", None]:

                    ## Set the target course sis id to the Parent_Course_sis_id
                    targetCourseSisId = courseDict["Parent_Course_sis_id"]

                    ## Find the index of the Parent_Course_sis_id in the activeCanvasOutcomeCoursesDf
                    parentCourseIndex = p1_activeCanvasOutcomeCoursesDf[p1_activeCanvasOutcomeCoursesDf["Course_sis_id"] == targetCourseSisId].index[0]

                    ## Set the target course name to the Parent_Course_sis_id's course name
                    targetCourseName = p1_activeCanvasOutcomeCoursesDf.at[parentCourseIndex, "Course_name"]
            
                ## Make a filtered p1_termEnrollmentDf for the target course using the target course sis id and the canvas_section_id
                targetTermEnrollmentDf = p1_termEnrollmentDf[
                    (p1_termEnrollmentDf["course_id"] == targetCourseSisId)
                    & (p1_termEnrollmentDf["canvas_section_id"] == targetSectionId)
                    ]

                ## Make a filtered p1_outcomeResultDF for the current course using the target course sis id amd section id
                targetOutcomeResultsDf = p1_outcomeResultDF[
                    (p1_outcomeResultDF["course sis id"] == targetCourseSisId)
                    & (p1_outcomeResultDF["section id"] == targetSectionId)
                    ]
                
                ## Make a filtered outcomeResultReportDF for the current course
                targetOutcomeResultReportDf = outcomeResultReportDF[outcomeResultReportDF["Course_name"] == targetCourseName]

                ## Create a thread for the current course
                currentThread = threading.Thread(target=termCompileCourseOutcomesScores
                                                    , args=(courseDict
                                                            , targetTermEnrollmentDf
                                                            , targetOutcomeResultsDf
                                                            , targetOutcomeResultReportDf
                                                            , outcomeResultsDashboardDataDictList
                                                            , p1_uniqueOutcomeInfoDictOfDicts
                                                            )
                                                    )
                
                ## Start the thread
                currentThread.start()
                
                ## Append the thread to the active threads list
                activeThreadsList.append(currentThread)
            
        ## For each active thread
        for thread in activeThreadsList:

            ## Join the thread
            thread.join()
            

        ## If there are any dashboard dicts in the outcomeResultsDashboardDataDictList
        if outcomeResultsDashboardDataDictList:
                
            ## Combine the dashboard data dicts in the dasboard data list to become one dataframe
            outcomeResultsDashboardDataDF = pd.concat(outcomeResultsDashboardDataDictList)

            ## Save the dataframe in the relavent Canvas Resources folder
            outcomeResultsDashboardDataDF.to_excel(p1_destinationFilePathDict["Second Internal Output Report File Path and Name"], sheet_name = "General", index=False)
    
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function processes the outcome results for a given term
def termProcessOutcomeResults(p1_inputTerm
                              , p1_targetDesignator
                              ):
    functionName = "Term Get Outcome Results"

    try:
        ## Extract term prefix and decade
        termCodePrefix = p1_inputTerm[:2]  ## e.g., "FA", "SP", "SU"
        termWord = undgTermsCodesToWordsDict.get(termCodePrefix, gradTermsCodesToWordsDict.get(termCodePrefix))
        termYear = int(str(localSetup.dateDict["century"]) + p1_inputTerm[2:])

        ## Use LocalSetup to calculate school year dynamically
        schoolYear = localSetup.getSchoolYear(termWord, localSetup.dateDict["year"])

        ## Build lcoal paths  
        designatorLocalOutputPath = localSetup.getTargetDesignatedOutputPath(termWord, termYear, p1_targetDesignator)

        ## Ensure directories exist
        os.makedirs(designatorLocalOutputPath, exist_ok=True)
            
        ## Create a dict of the first and second, internal and external output report file paths
        destinationFilePathDict = {
            "Internal Output Report File Path and Name" : os.path.join(designatorLocalOutputPath, f"{p1_inputTerm}_{p1_targetDesignator}_Outcome_Results_Course_Data.xlsx")
            , "Second Internal Output Report File Path and Name" : os.path.join(designatorLocalOutputPath, f"{p1_inputTerm}_{p1_targetDesignator}_Outcome_Results_Dashboard_Data.xlsx")
            }
        
        ## If the internal output report file and the external output report file already exist
        if (isFileRecent(localSetup, destinationFilePathDict["Internal Output Report File Path and Name"]) 
            and isFileRecent(localSetup, destinationFilePathDict["Second Internal Output Report File Path and Name"])
            ):
                ## Return from the function
                return (
                    destinationFilePathDict["Internal Output Report File Path and Name"],
                    destinationFilePathDict["Second Internal Output Report File Path and Name"],
                )
                
        ## Retrieve the Automated Outcome Tool Variables excel file as a df    
        automatedOutcomeToolVariablesDf = pd.read_excel(
            os.path.join(
                localSetup.getExternalResourcePath("TLC"), 
                "Automated Outcome Tool Variables.xlsx"
                )
        )

        ## Get the account name associated with the target designator
        targetAccountName = automatedOutcomeToolVariablesDf.loc[
            automatedOutcomeToolVariablesDf["Target Designator"] == p1_targetDesignator, 
            "Outcome Location Account Name"
            ].values[0]

        ## Read the outcomes csv into a pandas dataframe
        outcomesCsvDf = CanvasReport.getOutcomesDf(localSetup, p1_inputTerm, targetAccountName, p1_targetDesignator)
        
        ## Remove the unicode character from the title column
        outcomesCsvDf['title'] = outcomesCsvDf['title'].str.replace('\u200b', '')

        ## Retrieve the active Canvas Outcome Courses excel file as a df, updating it if necessary
        activeCanvasOutcomeCoursesDf = CanvasReport.getActiveOutcomeCoursesDf(localSetup, p1_inputTerm, p1_targetDesignator)
        
        ## Open the accounts csv as a df
        accountInfoDF = CanvasReport.getAccountsDf(localSetup)
        
        ## Retrieve Automated Outcome Tool Variables
        automatedOutcomeToolVariablesDf = pd.read_excel(
            os.path.join(localSetup.getExternalResourcePath("SIS"), "Internal Tool Files", "Automated Outcome Tool Variables.xlsx")
        )
        targetAccountName = automatedOutcomeToolVariablesDf.loc[
            automatedOutcomeToolVariablesDf["Target Designator"] == p1_targetDesignator,
            "Outcome Location Account Name"
        ].values[0]

        ## Get the canvas account id associated with the targetAccountName
        targetCanvasAccountId = (
            1 if targetAccountName == "NNU" 
            else accountInfoDF.loc[accountInfoDF["name"] == targetAccountName, "canvas_account_id"].values[0]
            )

        ## Use the targetCanvasAccountId to determine  and add the department specific path element
        departmentSpecifcPathElement = CanvasReport.determineDepartmentSavePath(localSetup, targetCanvasAccountId)
        termExternalOutputPath = os.path.join(localSetup.getExternalResourcePath("IE"), departmentSpecifcPathElement, schoolYear, p1_inputTerm)

        ## Create a Unique Outcome Title : Vendor guids dict
        uniqueOutcomeInfoDictOfDicts = {}

        ## For each column in the activeCanvasOutcomeCoursesDf
        for column in activeCanvasOutcomeCoursesDf.columns:

            ## If the column  has outcome in the title and doesn't have area in the title
            if "Outcome" in column and "Area" not in column:    

                ## Get all the unique outcomes in the column, but only if they are not empty strings or nan
                rawUniqueOutcomes = activeCanvasOutcomeCoursesDf[column].dropna().astype(str)
                uniqueOutcomes = rawUniqueOutcomes[rawUniqueOutcomes.str.strip() != ""].unique()
                
                ## For each unique outcome in the column
                for uniqueOutcome in uniqueOutcomes:
                    
                    ## If the unique outcome is not nan
                    if not pd.isna(uniqueOutcome):
                        
                        ## If the unique outcome is not in the uniqueOutcomeVendorGuidDict
                        if uniqueOutcome not in uniqueOutcomeInfoDictOfDicts.keys():
                            
                            ## Add the unique outcome to the dict with a value of an empty list
                            uniqueOutcomeInfoDictOfDicts[uniqueOutcome] = {
                                "Outcome_Area" : p1_targetDesignator
                                , "Outcome_Title" : uniqueOutcome
                                , "Outcome_Name" : (
                                    uniqueOutcome.split("_")[1].split(":")[1] if (
                                        ":" in uniqueOutcome
                                        ) 
                                    else uniqueOutcome.split("_")[1]
                                    )
                                , "Outcome_Parent" : (
                                    uniqueOutcome.split("_")[1][:2] if (
                                        p1_targetDesignator == "GE"
                                        )
                                    else uniqueOutcome.split("_")[1].split("Standard")[0] if (
                                        p1_targetDesignator == "I-EDUC" or p1_targetDesignator == "G-EDUC"
                                        ) 
                                    else uniqueOutcome.split("_")[1].split(":")[0]
                                    )
                                , "Outcome_Root" : (p1_targetDesignator if (
                                        p1_targetDesignator == "GE"
                                        )
                                        else uniqueOutcome.split("_")[1].split(" ")[0].replace(":", "")
                                        )
                                , "Outcome_Version" : uniqueOutcome.split("_")[2]
                                }
                            
        ## Make a list to retain unique outcome keys that don't have a vendor guid
        uniqueOutcomesWithoutVendorGuidList = []
                            
        ## For each unique outcome in the uniqueOutcomeVendorGuidDict
        for uniqueOutcome in uniqueOutcomeInfoDictOfDicts.keys():
            
            ## Find the vendor guid that is associated with the unique outcome within outcomesCsvDf
            vendorGuidValueList = outcomesCsvDf.loc[outcomesCsvDf["title"] == uniqueOutcome, "vendor_guid"].values

            ## Find the learning outcome group title associated with the vendor guid within outcomesCsvDf
            outcomeParentGuidList = outcomesCsvDf.loc[outcomesCsvDf["title"] == uniqueOutcome, "parent_guids"].values
            
            ## Create variables for the vendor guid and outcome group title
            vendorGuid = ""
            outcomeGroupTitle = ""

            ## If the vendor guid value list is not empty
            if vendorGuidValueList.size > 0:

                ## Set the vendor guid as the first value in the list
                vendorGuid = vendorGuidValueList[0]

                ## Set the parentGuid as the first value in the list
                parentGuid = outcomeParentGuidList[0]

                ## Find the title coresponding to the parent guid
                outcomeGroupTitleList = outcomesCsvDf.loc[outcomesCsvDf["vendor_guid"] == parentGuid, "title"].values

                ## Set the outcome group title as the first value in the list
                outcomeGroupTitle = (
                    targetAccountName if str(parentGuid).strip() == "nan" 
                    else outcomeGroupTitleList[0]
                    )

            ## Otherwise
            else:

                ## Add the unique outcome to the uniqueOutcomesWithoutVendorGuidList
                uniqueOutcomesWithoutVendorGuidList.append(uniqueOutcome)

                ## Log that the outcome was not found in the outcomes csv and handle the error
                localSetup.logger.warning(f"Outcome {uniqueOutcome} was not found in the Canvas outcomes csv. Skipping it.")
                errorHandler.sendError (functionName, f"Outcome {uniqueOutcome} was not found in the Canvas outcomes csv. Skipping it.")

                ## Skip the value
                continue
            
            ## Set the vendor guid as the value for the unique outcome in the uniqueOutcomeVendorGuidDict
            uniqueOutcomeInfoDictOfDicts[uniqueOutcome]["Vendor_Guid"] = vendorGuid

            ## Also set the Outcome Group value in uniqueOutcomeInfoDictOfDicts to the learning outcome group title
            uniqueOutcomeInfoDictOfDicts[uniqueOutcome]["Outcome_group title"] = outcomeGroupTitle

        ## For each unique outcome in the uniqueOutcomesWithoutVendorGuidList
        for uniqueOutcome in uniqueOutcomesWithoutVendorGuidList:

            ## Remove it from the uniqueOutcomeVendorGuidDict
            del uniqueOutcomeInfoDictOfDicts[uniqueOutcome]

            ## Replace all instances of it from activeCanvasOutcomeCoursesDf
            activeCanvasOutcomeCoursesDf.replace(uniqueOutcome, "", inplace=True)

        ## Define a api url to get all outcome links for the targetCanvasAccountId
        accountOutcomeLinkApiUrl = f"{coreCanvasApiUrl}accounts/{targetCanvasAccountId}/outcome_group_links"

        ## Make an api call to get the outcome links related to the account id
        accountOutcomeLinksObject = makeApiCall(
            localSetup,
            accountOutcomeLinkApiUrl
            )

        ## Define a variable to hold the raw object link list/s
        rawAccountOutcomeLinksList = []

        ## If the object is actually a list of objects
        if isinstance(accountOutcomeLinksObject, list):

            ## For each response object in the list
            for accountOutcomeLinkObject in accountOutcomeLinksObject:
                    
                ## If the response was a 200
                if accountOutcomeLinkObject.status_code == 200:

                    ## Extend the accountOutcomeLinksList with the object
                    rawAccountOutcomeLinksList.extend(accountOutcomeLinkObject.json())

        ## Otherwise there was just one response
        else:
                
            ## If the status code was a 200
            if accountOutcomeLinksObject.status_code == 200:

                ## Extend the accountOutcomeLinksList with the object
                rawAccountOutcomeLinksList.extend(accountOutcomeLinksObject.json())

        ## For each object in the rawAccountOutcomeLinksList
        for responseOjbect in rawAccountOutcomeLinksList:
                
            ## Get its outcome title
            outcomeTitle = responseOjbect["outcome"]["title"].replace('\u200b', '')

            ## If that outcome title matches one of the keys in the uniqueOutcomeVendorGuidDict
            if outcomeTitle in uniqueOutcomeInfoDictOfDicts.keys():
                    
                ## Set the canvas id as the value for the outcome title in the uniqueOutcomeInfoDictOfDicts
                uniqueOutcomeInfoDictOfDicts[outcomeTitle]["Outcome_Id"] = responseOjbect["outcome"]["id"]

        ## Get the outcome results df for the target designator
        targetOutcomeResultsDf = CanvasReport.getOutcomeResultsDf(localSetup, p1_inputTerm, targetAccountName, p1_targetDesignator)
        
        ## Fill NA/NaN values with an empty string
        targetOutcomeResultsDf["learning outcome name"].fillna("", inplace=True)

        ## If the course's Outcome Area is GE
        if p1_targetDesignator == "GE":

            ## Some outcome ratings don't have the intial descriptor word (i.e. exemplary, target, etc.)
            ## The following dictionary has snippets of these descriptions and the words that need to be added to them
            ## The contents of the following if was generated by Chat GPT as a clean up of my original code
            ## Define a dictionary to map the first four words to the descriptor word
            descriptor_mapping = {
                "Design and carry out a research study": "Exemplary",
                "Students will evaluate conclusions relative to": "Exemplary",
                "Engage in redemptive service to the world": "Exemplary",
                "Engage substantially in body stewardship practices": "Exemplary",
                "Create personal visual": "Exemplary",
                "Generate solutions, using epistemologies": "Exemplary",
                "Initiate interactions with individuals from diverse cultures": "Exemplary",
                "Engage in the practice and application of the humanities": "Exemplary",
                "Construct a persuasive historical interpretation": "Exemplary",
                "Deliver a persuasive presentation, written or oral": "Exemplary",
                "Analyze their own and others' assumptions": "Exemplary",
                "Effectively problem-solve in contexts demanding quantitative literacy": "Exemplary",
                "Research multiple sources of information on a topic": "Exemplary",
                "In any popular communication (## e.g., article, interview, blog, movie, documentary) students will assess": "Target",
                "Students will properly analyze data": "Target",
                "Investigate the influence of social, cultural, economic, and political institutions": "Target",
                "Assess their own health status and develop a plan": "Target",
                "Delineate the characteristics that make the historical composers/artists relevant": "Target",
                "Apply the diverse ways of knowing to analyze real-world problems": "Target",
                "Demonstrate cultural competence by observing, contrasting, comparing, and understanding": "Target",
                "Demonstrate knowledge of humanities and the skills": "Target",
                "Articulate an adequate historical interpretation, supported by ample historical evidence": "Target",
                "Effectively use the English language in writing and speaking": "Target",
                "Make an informed, logical judgment of the arguments of others": "Target",
                "Critically evaluate data and draw reasonable and appropriately qualified conclusions": "Target",
                "Research information in response to critical inquiry and synthesize": "Target",
                "In any popular communication (## e.g., article, interview, blog, movie, documentary) students will identify": "Minimum",
                "Students will gather and analyze accurate data": "Minimum",
                "State the guiding theories of two area of the social sciences": "Minimum",
                "Describe a healthy lifestyle": "Minimum",
                "Identify and define historical characteristics of visual, musical, and literary art": "Minimum",
                "Define ways of knowing and identify them within a major discipline": "Minimum",
                "Compare and contrast their own culture with another culture": "Minimum",
                "Identify the contribution of the humanities in culture": "Minimum",
                "Identify a possible historical interpretation, which references some historical evidence": "Minimum",
                "Create a clear and coherent written or oral presentation for an audience": "Minimum",
                "Develop reasoned and meaningful arguments and positions": "Minimum",
                "Use quantitative concepts and methods to interpret data and form plausible arguments": "Minimum",
                "Locate, access, and utilize information in a research study": "Minimum"
            }
            
            ## Iterate through the outcome descriptions and add the descriptor word if applicable
            for index, row in targetOutcomeResultsDf.iterrows():

                ## Skip rows where the learning outcome rating is NaN
                if pd.isna(row["learning outcome rating"]):
                    continue
                
                for descriptor, rating in descriptor_mapping.items():
                    if row["learning outcome rating"].startswith(descriptor):
                        row["learning outcome rating"] = f"{rating}: {row['learning outcome rating']}"
                        break  ## Stop searching for descriptor if found

            ## Iterate through each row in the filtered term report df
            ## The contents of the following for was generated by Chat GPT as a clean up of my original code
            for index, row in targetOutcomeResultsDf.iterrows():
                
                ## If there is no learning outcome rating points
                ## Determine the rating points based on the rating
                if pd.isna(row["learning outcome rating points"]):
                    ## Skip rows with NaN rating
                    if pd.isna(row["learning outcome rating"]):
                        continue
        
                    ## Determine rating points based on the starting of the rating
                    rating = row["learning outcome rating"]
                    rating_points = 0
                    outcome_mastered = 0
                    if rating.startswith("Exemplary"):
                        rating_points = 3
                        outcome_mastered = 1
                    elif rating.startswith("Target"):
                        rating_points = 2
                        outcome_mastered = 1
                    elif rating.startswith("Minimum"):
                        rating_points = 1
                        outcome_mastered = 0
                    elif rating.startswith("Outcome_Not Met"):
                        rating_points = 0
                        outcome_mastered = 0
        
                    ## Set the learning outcome rating points and mastered
                    targetOutcomeResultsDf.at[index, "learning outcome rating points"] = rating_points
                    targetOutcomeResultsDf.at[index, "learning outcome mastered"] = outcome_mastered
                    
                    ## Fix any outcome name spelling errors
                    targetOutcomeResultsDf.at[index, "learning outcome name"] = targetOutcomeResultsDf.at[index, "learning outcome name"].replace("S1", "SC1").replace("S2", "SC2").replace("S3", "SC3").replace("H1", "HU1").replace("H3", "HU3").replace("H4", "HU4").replace("H5", "HU5")

        ## If the course's Outcome Area is I-EDUC
        elif p1_targetDesignator == "I-EDUC":
            
            ## Iterate through each row in the filtered term report df
            for index, row in targetOutcomeResultsDf.iterrows():
                
                ## If there is a rating points value
                if pd.isna(row["learning outcome rating points"]):
                    ## Skip rows with NaN rating as the points for those can't be determined
                    if pd.isna(row["learning outcome rating"]):
                        continue
        
                    ## Determine rating points based on the starting of the rating
                    rating = row["learning outcome rating"]
                    rating_points = 0
                    outcome_mastered = 0
                    if rating.startswith("Distinguished"):
                        rating_points = 4
                        outcome_mastered = 1
                    elif rating.startswith("Proficient"):
                        rating_points = 3
                        outcome_mastered = 1
                    elif rating.startswith("Basic"):
                        rating_points = 2
                        outcome_mastered = 0
                    elif rating.startswith("Unsatisfactory"):
                        rating_points = 1
                        outcome_mastered = 0
                    elif rating.startswith("No Evidence"):
                        rating_points = 0
                        outcome_mastered = 0
        
                    ## Set the learning outcome rating points and mastered
                    targetOutcomeResultsDf.at[index, "learning outcome rating points"] = rating_points
                    targetOutcomeResultsDf.at[index, "learning outcome mastered"] = outcome_mastered
                    
                    ## Create a variable to hold the target unique outcome info dict
                    targetUniqueOutcomeInfoDict = None

                    ## For each unique outcome info dict
                    for uniqueOutcomeInfoDict in uniqueOutcomeInfoDictOfDicts.values():
                        
                        ## If the unique outcome info dict's outcome id is equal to the learning outcome id
                        if uniqueOutcomeInfoDict["Outcome_Id"] == row["learning outcome id"]:
                            
                            ## Set the target unique outcome info dict to the unique outcome info dict
                            targetUniqueOutcomeInfoDict = uniqueOutcomeInfoDict
                            break

                    ## If targetUniqueOutcomeInfoDict is still none
                    if targetUniqueOutcomeInfoDict is None:

                        ## Log a warning and continue
                        localSetup.logger.warning(f"Could not find unique outcome info dict for outcome id {row['learning outcome id']}. Skipping row.")
                        continue

                    ## Set the name of the outcome to the title paired with the id in the unique outcome info dict
                    targetOutcomeResultsDf.at[
                        index
                        , "learning outcome name"
                        ] = targetUniqueOutcomeInfoDict[
                            "Outcome_Title"
                            ]

        ## Open the target enrollment file as a df
        rawTermEnrollmentDf = CanvasReport.getEnrollmentsDf(localSetup, p1_inputTerm)
        
        ## Filter the rawTermEnrollmentDf to only contain rows with student as the role 
        ## and active or concluded as the status
        termEnrollmentDf = rawTermEnrollmentDf[
            (rawTermEnrollmentDf["role"] == "student") 
            & (
                (rawTermEnrollmentDf["status"] == "active")
                | (rawTermEnrollmentDf["status"] == "concluded")
                )
            ]
        ##termEnrollmentDf = rawTermEnrollmentDf[rawTermEnrollmentDf["role"] == "student"]
        
        ## Fill any na values of user id with -1
        termEnrollmentDf.loc[:, "user_id"] = termEnrollmentDf["user_id"].fillna(-1)

        ## Create a thread for the current target designation
        targetDesignatorProcessOutcomeResults (
            p2_inputTerm = p1_inputTerm
             , p1_schoolYear = schoolYear
             , p1_destinationFilePathDict = destinationFilePathDict
             , p1_uniqueOutcomeInfoDictOfDicts = uniqueOutcomeInfoDictOfDicts
             , p1_outcomeResultDF = targetOutcomeResultsDf
             , p1_activeCanvasOutcomeCoursesDf = activeCanvasOutcomeCoursesDf
             , p1_accountInfoDF = accountInfoDF
             , p1_termEnrollmentDf = termEnrollmentDf
             )
        
        return (
                    destinationFilePathDict["Internal Output Report File Path and Name"],
                    destinationFilePathDict["Second Internal Output Report File Path and Name"],
                )

    except Exception as Error:
        errorHandler.sendError (functionName, Error)
        
## This function opens the CSV file, the save locations json file, sends the information on, and closes both files
def runOutcomeResultsReport(inputTerm, targetDesignator):
    functionName = "Run OutcomeAttachment Report"
    
    try:
    
        ## Run the termOutcomeAttachmentReport function
        termProcessOutcomeResults (p1_inputTerm = inputTerm
                                     , p1_targetDesignator = targetDesignator
                                     )
     
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

if __name__ == "__main__":

    ## Start and download the Canvas report
    runOutcomeResultsReport (inputTerm = input("Enter the desired term in four character format (FA20, SU20, SP20): ")
        , targetDesignator = input("Enter the desired target designator (GE, I-EDUC, U-ENGR): ")
        )

    input("Press enter to exit")


## ===========================================================================
## FILE: ReportModules\Syllabi_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Moduels
import traceback, os, sys, logging, csv, requests, json, pdfkit, re, os, shutil, os.path, re, threading, time
from datetime import date
import pandas as pd

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Syllabi Report"

## Script file identifier
scriptRequirementMissingFolderIdentifier = "Missing_Syllabi"

scriptPurpose = r"""
Search active Canvas course's Syllabus tabs for syllabi. Download those that are found and make notes regarding what is retrieved and what is missing.
Downloaded Syllabi are stored in S:\Employees-Read Only\University Syllabi
"""
externalRequirements = r"""
To function properly, this script requires that syllabi be placed in the Canvas Syllabus tab as a word document, pdf, microsoft doc, or as basic text (copied and pasted). 
If the syllabus is in a document, the document needs to have "Syllabus" in the file title (which can only be changed prior to the file being uploaded to Canvas).
"""

##pdfkit (which enables the script to convert html code into .pdf and save it) needs to access wkhtmltopdf.exe which is easier if it has a direct path configured instead of :ing to find it generally
path_wkhtmltopdf = r'Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe' ##This is the default location of wkhtmltopdf.exe and would need to be changed if the default installation location for wkhtmltopdf was edited.
config = pdfkit.configuration(wkhtmltopdf=path_wkhtmltopdf)

## Import local modules
from Download_File import downloadFile
from Core_Microsoft_Api import downloadSharedMicrosoftFile


## List of courses that don't need a syllabus. Syllabi for such courses are still gathered but they are not listed in the missing_syllabi.csv
list_of_courses_that_dont_need_syllabi = []
with open(f"{configPath}List_of_uneeded_syllabi.csv", 'r') as tempCsvFile:
    tempcsvReader = csv.DictReader(tempCsvFile, delimiter = ',')
    for row in tempcsvReader:
        list_of_courses_that_dont_need_syllabi.append(row['course_id'])
    tempCsvFile.close()

## This function clears the syllabi folders connected to the relavent terms
def clearRelaventSyllabiFolders(inputTerm):
    functionName = "Clear Relavent Syllabi Folders"
    try:
        targetSchoolYear = None

        ## Define the current school year by whether it is before or during/after september
        if re.search("AF|FA|GF", inputTerm):
            ## Fall terms are the first terms of a new school year so FA20 is part of the 2020-21 school year.
            targetSchoolYear = f"{century}{inputTerm[2:]}-{int(inputTerm[2:]) + 1}"
        if re.search("SP|GS|AS|SG|SA|SU", inputTerm):
            ## Spring and Summer terms belong in the same school year as the fall terms before them, so SP21 is part of the same 2020-21 school year as FA20.
            targetSchoolYear = f"{century}{int(inputTerm[2:]) - 1}-{inputTerm[2:]}"
        
        ## Retrieve a list of the college syllabi folders
        list_of_college_folders = os.listdir(baseExternalOutputPath)

        ## Clear the current year's syllabi in preparation to retrieve their current versions
        for college_folder in list_of_college_folders:
            
            ## Skip anything that is not a college
            if "College" in college_folder or "Academic Services" in college_folder: 
                ## Define the College Folder Path
                college_folder_path = f"{baseExternalOutputPath}{college_folder}\\"
            
                ## Retrieve a dict of of the contents of the college syllabi folders
                college_folder_contents = os.listdir(college_folder_path)

                for firstLvlDepartmentitem in college_folder_contents:
                        
                    ## Skip the college missing syllabi and college missing addendum folders
                    if "College_Missing" not in firstLvlDepartmentitem:

                        ## Define the current department path
                        firstLvlDepartment_path = college_folder_path + firstLvlDepartmentitem + "\\"

                        ## Retrieve a list of the department's syllabi for the current year
                        firstLvlDepartment_folder_contents = os.listdir(firstLvlDepartment_path)

                        ## Skip the department if it doesn't have the current year
                        if targetSchoolYear in firstLvlDepartment_folder_contents:

                            ## Define the department target year path
                            firstLvlDepartmentTargetYearPath = f"{firstLvlDepartment_path}{targetSchoolYear}\\"
                            firstLvlDepartmentTargetYearFolderContents = os.listdir(firstLvlDepartmentTargetYearPath)
                                
                            ## Skip the department if it doesn't have the current year
                            if inputTerm in firstLvlDepartmentTargetYearFolderContents:
                                ## Define the department target term path
                                firstLvlDepartmentTargetTermPath = f"{firstLvlDepartmentTargetYearPath}{inputTerm}\\"

                                ## Retrieve a list of the department's syllabi for the current year
                                firstLvlDepartmentTargetTermFolderContents = os.listdir(firstLvlDepartmentTargetTermPath)

                                ## Clear the syllabi from the college's current year folder
                                ## Skip the Other_course_files folder and Missing Syllabi Folder
                                for item in firstLvlDepartmentTargetTermFolderContents:
                                    if "Other_Course_Files" not in item and "Missing_Syllabi" not in item:
                                        try: ## Irregular try clause, do not comment out in testing
                                            os.remove(firstLvlDepartmentTargetTermPath + item)
                                            localSetup.logger.info (item + " removed from " + firstLvlDepartmentTargetTermPath)
                                        except Exception as Error: ## Irregular except clause, do not comment out in testing
                                            localSetup.logger.info ("/n" + item + " not deleted due to error: " + str(error))
                                localSetup.logger.info ("Files cleared from " + firstLvlDepartmentTargetTermPath)

                        ## For non-wholistic colleges go down another folder level each
                        elif "Graduate" in firstLvlDepartment_folder_contents or "Undergraduate" in firstLvlDepartment_folder_contents:
                            
                            for secondLvlDepartmentitem in firstLvlDepartment_folder_contents:

                                ## Define the second level current department path
                                secondLvlDepartmentPath = f"{firstLvlDepartment_path}{secondLvlDepartmentitem}\\"

                                ## Retrieve a list of the second level department's syllabi for the current year
                                secondLvlDepartmentFolderContents = os.listdir(secondLvlDepartmentPath)

                                if targetSchoolYear in secondLvlDepartmentFolderContents:

                                    ## Define the department target year path
                                    secondLvlDepartmentTargetYearPath = f"{secondLvlDepartmentPath}{targetSchoolYear}\\"
                                    secondLvlDepartmentTargetYearFolderContents = os.listdir(secondLvlDepartmentTargetYearPath)
                                
                                    ## Skip the department if it doesn't have the current year
                                    if inputTerm in secondLvlDepartmentTargetYearFolderContents:
                                        ## Define the department target term path
                                        secondtLvlDepartmentTargetTermPath = f"{secondLvlDepartmentTargetYearPath}{inputTerm}\\"

                                        ## Retrieve a list of the department's syllabi for the current year
                                        secondLvlDepartmentTargetTermFolderContents = os.listdir(secondtLvlDepartmentTargetTermPath)

                                        ## Clear the syllabi from the college's current year folder
                                        ## Skip the Other_course_files folder and Missing Syllabi Folder
                                        for item in secondLvlDepartmentTargetTermFolderContents:
                                            if "Other_Course_Files" not in item and "Missing_Syllabi" not in item:
                                                try: ## Irregular try clause, do not comment out in testing
                                                    os.remove(secondtLvlDepartmentTargetTermPath + item)
                                                    localSetup.logger.info (item + " removed from " + secondtLvlDepartmentTargetTermPath)
                                                except Exception as Error: ## Irregular except clause, do not comment out in testing
                                                    localSetup.logger.info ("/n" + item + " not deleted due to error: " + str(error))
                                        localSetup.logger.info ("Files cleared from " + secondtLvlDepartmentTargetTermPath)
                                else:

                                    ## Check for the presence of third level departments
                                    for secondlvlFolder in secondLvlDepartmentFolderContents:
                                        
                                        ## All years have - in them, so if a second lvl folder doesn't have - it is a third level department
                                        if "-" not in secondlvlFolder:

                                            ## Define the second level current department path
                                            thirdLvlDepartmentPath = f"{secondLvlDepartmentPath}{secondlvlFolder}\\"

                                            ## Retrieve a list of the second level department's syllabi for the current year
                                            thirdLvlDepartmentFolderContents = os.listdir(thirdLvlDepartmentPath)

                                            if targetSchoolYear in thirdLvlDepartmentFolderContents:

                                                ## Define the department target year path
                                                thirdLvlDepartmentTargetYearPath = f"{thirdLvlDepartmentPath}{targetSchoolYear}\\"
                                                thirdLvlDepartmentTargetYearFolderContents = os.listdir(thirdLvlDepartmentTargetYearPath)
                                
                                                ## Skip the department if it doesn't have the current year
                                                if inputTerm in thirdLvlDepartmentTargetYearFolderContents:
                                                    ## Define the department target term path
                                                    thirdtLvlDepartmentTargetTermPath = f"{thirdLvlDepartmentTargetYearPath}{inputTerm}\\"

                                                    ## Retrieve a list of the department's syllabi for the current year
                                                    thirdLvlDepartmentTargetTermFolderContents = os.listdir(thirdtLvlDepartmentTargetTermPath)

                                                    ## Clear the syllabi from the college's current year folder
                                                    ## Skip the Other_course_files folder and Missing Syllabi Folder
                                                    for item in thirdLvlDepartmentTargetTermFolderContents:
                                                        if "Other_Course_Files" not in item and "Missing_Syllabi" not in item:
                                                            try: ## Irregular try clause, do not comment out in testing
                                                                os.remove(thirdtLvlDepartmentTargetTermPath + item)
                                                                localSetup.logger.info (item + " removed from " + thirdtLvlDepartmentTargetTermPath)
                                                            except Exception as Error: ## Irregular except clause, do not comment out in testing
                                                                localSetup.logger.info ("/n" + item + " not deleted due to error: " + str(error))
                                                    localSetup.logger.info ("Files cleared from " + thirdtLvlDepartmentTargetTermPath)
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

""" 
 This fuction saves the course ID and other identifiers of the course in question.
 The intended purpose of this function is to make a csv of missing syllabi made up of courses without
 a syllabus or with short syllabi (which generally indicate that the link wasn't named properly)
 with the ulimate goal that all syllabi are gathered because departments are able to find and 
 add/fix the syllabi in the log.
"""
def syllabiReportSaveCourseInfo(p1_save_location, p1_collegeReportLocation, p1_courseName, issue, required_action, \
   p1_instructor_name, p1_start_date, p1_end_date, p1_term_id, p1_department, p2_collegeOrDeptMissingRequirement):
    functionName = "syllabiReportSaveCourseInfo"
    try:
        ## This function creates a csv file to record when the requirement is missing or if it's existence is uncertain.
        ## Create a new missingRequirement csv for that context the first time that a department is missing the requirement
        departmentReportLocation = p1_save_location.replace(p1_term_id, f"{scriptRequirementMissingFolderIdentifier}")
        deptmentMissingRequirementCsv = departmentReportLocation + f"{p1_term_id}_{scriptRequirementMissingFolderIdentifier}.csv"
        collegeMissingRequirementCsv = p1_collegeReportLocation + f"{p1_term_id}_{scriptRequirementMissingFolderIdentifier}.csv"
        
        if (deptmentMissingRequirementCsv not in p2_collegeOrDeptMissingRequirement):
            ## If the path doesn't exist, create it
            if not (os.path.exists(departmentReportLocation)):
                os.makedirs(departmentReportLocation, mode=0o777, exist_ok=False)
            ## If it does exist, ensure the last iteration of this department's missing requirement file for the relavent term has been removed
            else:
                if os.path.exists(deptmentMissingRequirementCsv):
                    os.remove(deptmentMissingRequirementCsv)
            ## Create a new department MissingRequirement csv
            with open (deptmentMissingRequirementCsv, "w", newline="") as csvFile_2:
                fieldnames = ["courseName", "Issue", "Required Action", "Instructor Name", "start_date", "end_date", "department"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writeheader()
                csvWriter.writerow({"courseName": p1_courseName, "Issue": issue, "Required Action": required_action, "Instructor Name": p1_instructor_name, "start_date": p1_start_date, "end_date": p1_end_date, "department": p1_department})
                csvFile_2.close()
        ## If it is the second time (or more) in the current run of the script the missing requirement file is added onto
        else:
            with open (deptmentMissingRequirementCsv, "a", newline="") as csvFile_2:
                fieldnames = ["courseName", "Issue", "Required Action", "Instructor Name", "start_date", "end_date", "department"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writerow({"courseName": p1_courseName, "Issue": issue, "Required Action": required_action, "Instructor Name": p1_instructor_name, "start_date": p1_start_date, "end_date": p1_end_date, "department": p1_department})
                csvFile_2.close()
        ## A college level version of the missing requirement is made in addition to the department level file
        if (collegeMissingRequirementCsv not in p2_collegeOrDeptMissingRequirement):
            ## If the path doesn't exist, create it
            if not (os.path.exists(p1_collegeReportLocation)):
                os.makedirs(p1_collegeReportLocation, mode=0o777, exist_ok=False)
            ## If it does exist, ensure the last iteration of this department's missing requirement file for the relavent term has been removed
            else:
                if os.path.exists(collegeMissingRequirementCsv):
                    os.remove(collegeMissingRequirementCsv)
            ## Create a new college MissingRequirement csv
            with open (collegeMissingRequirementCsv, "w", newline="") as csvFile_2:
                fieldnames = ["courseName", "Issue", "Required Action", "Instructor Name", "start_date", "end_date", "Term", "department"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writeheader()
                csvWriter.writerow({"courseName": p1_courseName, "Issue": issue, "Required Action": required_action, "Instructor Name": p1_instructor_name, "start_date": p1_start_date, "end_date": p1_end_date, "department": p1_department})
                csvFile_2.close()
        ## If it is the second time (or more) in the current run of the script the missing requirement file is added onto    
        else:
            with open (collegeMissingRequirementCsv, "a", newline="") as csvFile_2:
                fieldnames = ["courseName", "Issue", "Required Action", "Instructor Name", "start_date", "end_date", "Term", "department"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writerow({"courseName": p1_courseName, "Issue": issue, "Required Action": required_action, "Instructor Name": p1_instructor_name, "start_date": p1_start_date, "end_date": p1_end_date, "department": p1_department})
                csvFile_2.close()
        return deptmentMissingRequirementCsv, collegeMissingRequirementCsv
    except Exception as Error:
        errorHandler.sendError (functionName, Error)
        return "", ""

## This function processes the urls found within the course syllabus tab and downloads course files and microsoft files
def process_url_matches (p1_all_url_matches, p2_courseName, p1_save_location):
    functionName = "process_url_matches"

    try:
        ## The following list and sets enable the tracking of whether a likely syllabus has been
        ## downloaded and ebles the script to skip previously processed urls and course files
        list_of_syllabi_downloaded = []
        processed_urls = set()
        processed_files = set()
                    
        ## Track the number of downloads for the course
        download_order = []
        
        for element in p1_all_url_matches:
            ## Skip previously encountered URLs
            if (element in processed_urls):
                localSetup.logger.info("Link Skipped: Previously processed URL")
            ## URL has not been seen before - attempt to process it.
            else:
                ## Creating a file_number out of the length of download_order when length is greater than 1 enables the script to differentiate
                ## between the first and second download and ensure that the second doesn't overwrite the first.
                ## If more than one file needs to be downloaded, append a number on to the end to ensure the first file isn't overwritten
                download_number = len(download_order) + 1
                file_number = ""
                if download_number > 1:
                    file_number = "_" + str(download_number)
                localSetup.logger.info(f"\n     {p2_courseName}: {element}")
                processed_urls.add(str(element))
                ## Check if the URL is to a course file
                course_file = re.findall(r'courses/\d+/files/\d+', element)
                ## Check if the URL is to a onedrive file
                microsoftFile = re.findall(r'nnuedu.sharepoint.com\S+', element)
                ## Check if the URL is the syllabus addendum link
                external_addendum = re.search(r'University_Syllabus_Addendum', element, re.IGNORECASE)
                ## If the URL is to a course file, check the course file number to determine if the file hasn't been seen (there are often two urls to the same file)
                ## Skip previously processed files
                if (course_file):
                    if (course_file[0] in processed_files):
                        localSetup.logger.info(f"\n     {p2_courseName} Link Skipped: Previously processed course file\
                        {str(course_file[0])}")
                    ## We have not yet downloaded this course file - attempt to download it.
                    else:
                        processed_files.add(str(course_file[0]))
                        course_file_API_url = coreCanvasApiUrl + str(course_file[0])
                        file_object = requests.get(course_file_API_url, headers = header)
                        if not (file_object.status_code == 200):
                            ## Unable to fetch course file info from Canvas. API error.
                            localSetup.logger.info (f"     \n{p2_courseName} Course File Error: {str(file_object.status_code)}\
                                {course_file_API_url}")
                        else:
                            ## Course File info was successfully fetched from Canvas.
                            file_jsonString = file_object.text
                            file_jsonObject = json.loads(file_jsonString)
                            display_name = file_jsonObject["display_name"]
                            mime_class = file_jsonObject["mime_class"]
                            content_type = file_jsonObject["content-type"]
                            course_file_download_url = (file_jsonObject["url"])
                            localSetup.logger.info(f"\n     {p2_courseName} Course File: " + str(display_name))
                            if ((re.search(r'Addendum' or r'addendum', display_name)) or (re.search(r'image', mime_class))):
                                if re.search(r'Addendum' or r'addendum', display_name):
                                    ## Filename (display_name) identifies this course file as the syllabus addendum. Skip it.
                                    localSetup.logger.info(f"\n     {p2_courseName} Course File Skipped: Syllabus Addendum")
                                elif re.search(r'image', mime_class):
                                    ## This is an image file. Skip it.
                                    localSetup.logger.info(f"\n     {p2_courseName} Course File Skipped: {content_type}")
                            else:
                                if (re.search('syll' or 'syllabus' or 'syllabi', display_name, re.IGNORECASE)):
                                    ## Filename indicates that this is a syllabus. Download and put it into the primary department directory.
                                    download_order.append(display_name)
                                    list_of_syllabi_downloaded.append(display_name)
                
                                    file_name = ""
                                    file_extension = ""
                
                                    ## Determine file exstension
                                    if re.search(r'application/vnd.openxmlformats', content_type):
                                        file_extension = ".docx"
                                    elif re.search(r'application/pdf', content_type):
                                        file_extension = ".pdf"
                                    elif re.search(r'application/msword', content_type):
                                        file_extension = ".doc"
                                    else:
                                        ## Look into file handling for if the display_name makes the p1_save_location + file_name longer than Windows will allow.
                                        file_extension = (" %s" % display_name)
                    
                                    file_name = (p2_courseName + file_number + file_extension)
                                    downloadFile(course_file_download_url, p1_save_location + "\\" + file_name, "w")
                                    if ((file_extension != ".pdf") and (len(list_of_syllabi_downloaded) < 1)):
                                        try: ## Irregular try clause, do not comment out in testing
                                            os.remove(p1_save_location + "\\" + p2_courseName + ".pdf")
                                            localSetup.logger.info (f"     \n{p2_courseName} old .pdf file removed")
                                        except: ## Irregular except clause, do not comment out in testing
                                            localSetup.logger.info ("no old .pdf file found")
                                    localSetup.logger.info(f"\n     {p2_courseName} Download: Probable Syllabus")
                                else:
                                    ## File name did not indicate syllabus. Download it anyway, but put it into Other_Course_Files.
                                    download_order.append(display_name)
                                    raw_file_name = p2_courseName + "---" + file_number + "-" + display_name
                                    file_name = raw_file_name.replace(':','-')
                                    downloadFile(course_file_download_url, p1_save_location + "\Other_Course_Files\\" + file_name, "w")
                                    localSetup.logger.info(f"\n     {p2_courseName} Download: Other Course File")
                elif (external_addendum):
                    ## This URL match is the University_Syllabus_Addendum
                    localSetup.logger.info(f"\n     {p2_courseName} Link Skipped: Syllabus Addendum")
                elif (microsoftFile):
                    ## This URL match is a OneDrive file.
                    if (microsoftFile[0] in processed_files):
                        localSetup.logger.info(f"\n     {p2_courseName} Link Skipped: Previously processed One Drive file\
                        \n{str(microsoftFile[0])}")
                    else:
                        ## We have not yet downloaded this microsoft file - attempt to download it.
                        processed_files.add(str(microsoftFile[0]))
                        download_order.append(element)

                        ## Download the microsoft file
                        microsoftFile = downloadSharedMicrosoftFile(p1_microsoftUserName = serviceEmailAccount
                                                                    , p1_fileShareUrl = element
                                                                    , p1_downloadSavePath = p1_save_location)
                        
                        ## If a microsoft file was successfuly downloaded
                        if microsoftFile:
                            
                            ## Separate the name from the path
                            microsoftFileName = microsoftFile.split("\\")[-1]

                            ## Look at the downloaded file and move it to the releavent other course files folder if it doesn't have Syllabus in the title
                            if not (re.search('syll' or 'syllabus' or 'syllabi', microsoftFileName, re.IGNORECASE)):
                                microsoftFileNewDestination = os.path.abspath(f"{p1_save_location}Other_Course_Files")
                                if os.path.exists(f"{microsoftFileNewDestination}\\{microsoftFileName}"):
                                    os.remove(f"{microsoftFileNewDestination}\\{microsoftFileName}")
                                shutil.move(microsoftFile, microsoftFileNewDestination)
                                
                            ## Otherwise add it to the list of downloaded syllabi
                            else:
                                list_of_syllabi_downloaded.append(microsoftFile)
                        else:
                            localSetup.logger.warning(f"\n     {p2_courseName} Link Skipped: Unable to download microsoft file")

                else:
                    ## This URL match is not a recognizable file source. Skip it.
                    localSetup.logger.info(f"\n     {p2_courseName} Link Skipped: URL is niether course file nor microsoft Doc")
        return list_of_syllabi_downloaded
    except Exception as Error:
        errorHandler.sendError (functionName, f"{Error} \nCourse: {p2_courseName}")
        return ""

## This function makes a get call to the course API URL and processes the course listed on the most recent 
## p1_row of the CSV file and looks for urls within the contents syllabus tab
## Script Specific
def courseSyllabiReport (p1_row, p2_inputTerm, p1_departmentSavePaths, p1_CollegeOrDeptMissingRequirement):

    ## Record the function name for error reporting
    functionName = "Course Syllabi Report"

    try:
        
        ## Define the variables that will be used to track the course's information and save paths    
        requirementMet = None
        departmentReportLocation = None
        collegeReportLocation = None
    
        ## If the p1_row's course name is pd.nan, return
        if not pd.notna(p1_row['short_name']):
            return

        ## For each p1_row in our CSV file we only pull three columns, long_name, courseId, and account_id.

        ## Sample course_id values: FA2021_BIOL2220_01, FA2021_EDUC2110_1L, FA2021_ACCT2060_01
        courseSisId = p1_row['course_id'] 

        ## Sample status values: active, deleted, unpublished
        courseAccountId = p1_row['account_id']  

        ## Sample account_id values: U_HSPS, U_LLIT, U_MUSI_APP
        ## Replace unsaveable characters in the course name with spaces
        courseName = p1_row['short_name'].replace("<", " ").replace(">", " ").replace(":", " ").replace('"', " ")\
            .replace("/", " ").replace("\\", " ").replace("|", " ").replace("?", " ").replace("*", " ") 

        ## Begin a new course entry: in the log (the --'s are to increase the readability of the log file by adding
        ## easy to see seperations between each course entry:
        localSetup.logger.info("\n     Course: " + courseSisId)
            
        ## Create the URL the API call will be made to
        course_API_url = coreCanvasApiUrl + "courses/sis_course_id:" + courseSisId
                
        ## Make the API call and save the result as course_object
        course_object = requests.get(course_API_url, headers = header, params = payload)
                
        ## If the API status code is anything other than 200 it means the call was unsucessful
        ## In such cases log the error and skip the course
        if (course_object.status_code != 200):
            localSetup.logger.info(f"\n     {courseName} Error: {str(course_object.status_code)}" \
                + f"\n{course_API_url})" \
                + f"\n{course_object.url}")
            requirementMet = True

        ## Successfully fetched course info from Canvas.
        else:

            ## Save the primary body of information retrieved by the API call as courseTextJsonString 
            courseTextJsonString = course_object.text
        
            ## Convert the json body of information as a Python Dictionary
            courseTextDict = json.loads(courseTextJsonString)
        
            ## Skip the course if it doesn't have students
            if (courseTextDict['total_students'] == 0):
                localSetup.logger.info(f"\n     {courseName} Skipped: No students so no need for a syllabi")
                return
        
            ## From courseTextJsonString, isolate the course's syllabus body
            syllabusBody = courseTextDict["syllabus_body"]
        
            ## Define empty variables to hold the department and college specific save paths 
            courseDepartmentPath = None
            courseCollegePath = None
            school_year_path = None

            ## Check whether the courseAccountId is listed in the departmentSavePaths dict. If it is, 
            ## retrieve the department's associated filepath (example: /College of Natural & Applied Sciences/Chemistry:/).
            if courseAccountId in p1_departmentSavePaths:
                courseDepartmentPath = p1_departmentSavePaths[courseAccountId]

            ## Otherwise create use the Canvas sub-account structure above the course to create the department's filepath 
            else:
                ## If the course account ID is blank, set the course department path to the Misc Folder
                if pd.isna(courseAccountId):
                    courseDepartmentPath = "Misc\\Uncategorized\\"

                else:
                    courseDepartmentPath = p1_departmentSavePaths[courseAccountId] = determineDepartmentSavePath \
                        (courseAccountId = courseAccountId)

            ## If the determined path has the manually created courses parent account name in it, skip the course
            if "Manually-Created Courses" in courseDepartmentPath:
                localSetup.logger.info(f"\n     {courseName} Skipped: Manually created course so no need for a syllabi")
                return
            
            ## Isolate the college piece of the department file path and save it as courseCollegePath.
            rawcourseCollegePath = (courseDepartmentPath.rsplit("\\"))[0]
            courseCollegePath = f"\{rawcourseCollegePath}\\"

            ## Determine and save the course's school year for file path purposes and in case the syllbus is missing or unidentifiable
            if re.search("AF|FA|GF", p2_inputTerm):
                ## Fall terms are the first terms of a new school year so FA20 is part of the 2020-21 school year.
                school_year = (century + p2_inputTerm[-2:] + "-" + str(int(p2_inputTerm[-2:]) + 1))
                school_year_path = (f"{school_year}\\")
            elif re.search("SP|GS|AS|SG|SA|SU", p2_inputTerm):
                ## Spring and Summer terms belong in the same school year as the fall terms before them, so SP21 is part of the same 2020-21 school year as FA20.
                school_year = (century + str(int(p2_inputTerm[-2:]) - 1) + "-" + p2_inputTerm[-2:])
                school_year_path = (f"{school_year}\\")
        
            ## If the course has its own indivigual start and end date seperate from the term start and end date, save them in case the syllbus is missing or unidentifiable.
            start_date = ""
            end_date = ""
            if courseTextDict["start_at"]:
                start_date = courseTextDict["start_at"]
            if courseTextDict["end_at"]:
                end_date = courseTextDict["end_at"]
        
            ## Save the instructor name in case the syllbus is missing or unidentifiable, but save it as none initially because not all courses have instructors.
            course_teacher_1_name = None
            if (courseTextDict["teachers"]):
                course_teacher_1_name = courseTextDict["teachers"][0]["display_name"]
        
            ## Create save location variables
            save_location = None
            collegeReportLocation = None
        
            ## Save all course related files to the corresponding location found in departmentSavePaths
            save_location = f"{baseExternalOutputPath}{courseDepartmentPath}{school_year_path}{p2_inputTerm}\\"
            collegeReportLocation = f"{baseExternalOutputPath}{courseCollegePath}\\College_{scriptRequirementMissingFolderIdentifier}\\{school_year_path}"
            if not (os.path.exists(save_location + "\Other_Course_Files")):
                ## Create the sub-account & department specific directory if it doesn't already exist.
                os.makedirs(save_location + "\Other_Course_Files", mode=0o777, exist_ok=False)
                localSetup.logger.info(f"\n     {save_location}\Other_Course_Files: directories created")
        
            ## Make note of whether or not the course is on the list of courses that don't need syllabi
            course_needs_syllabi = True
            for course_code in list_of_courses_that_dont_need_syllabi:
                if course_code in courseName:
                    course_needs_syllabi = False
        
            ## Proceed if the course is not one of the courses that doesn't need a syllabi
                
            ## If the course doesn't have a syllabus body, skip it and add the relavent info to the Missing_Syllabi.csv file.
            if not (syllabusBody):
                if course_needs_syllabi:
                    departmentReportLocation, collegeReportLocation = syllabiReportSaveCourseInfo (p1_save_location = save_location, p1_collegeReportLocation = collegeReportLocation, p1_courseName = courseName, \
                        issue = "Course Skipped: No Syllabus_Body", required_action = "Embed the syllabus file in the Syllabus Tab", \
                        p1_instructor_name = course_teacher_1_name, p1_start_date = start_date, p1_end_date = end_date, p1_term_id = p2_inputTerm, \
                        p1_department = courseAccountId, p2_collegeOrDeptMissingRequirement = p1_CollegeOrDeptMissingRequirement)

                    localSetup.logger.info(f"\n     {courseName} Course Skipped: No Syllabus_Body")
                    
                    requirementMet = False
                else:
                    localSetup.logger.info (f"     \n{courseName} Course does not have a syllabus but doesn't need one.")
                    requirementMet = True
            else:
                ## If the course has a template syllabus body, skip it and add the relavent info to the Missing_Syllabi.csv file.
                ## 323 is the known character length of one version of the syllabus template, and the <span> listed is a known piece of the version of the syllabus template current when this comment was written (11/5/21).
                if (len(syllabusBody) == 323 or re.search(r'<span style="font-size: 36pt;">Replace with Syllabus Content</span>', syllabusBody)):
                    if course_needs_syllabi:
                        departmentReportLocation, collegeReportLocation = syllabiReportSaveCourseInfo (p1_save_location = save_location, p1_collegeReportLocation = collegeReportLocation, p1_courseName = courseName, \
                            issue = "Course Skipped: Template Syllabus Body", required_action = "Embed the syllabus file in the Syllabus Tab", \
                            p1_instructor_name = course_teacher_1_name, p1_start_date = start_date, p1_end_date = end_date, p1_term_id = p2_inputTerm, \
                            p1_department = courseAccountId, p2_collegeOrDeptMissingRequirement = p1_CollegeOrDeptMissingRequirement)
                        
                        localSetup.logger.info(f"\n     {courseName} Course Skipped: Template Syllabus Body")
                        
                        requirementMet = False
                    else:
                        localSetup.logger.info (f"     \n{courseName} Course doesn't have a syllabus but doesn't need one.")
                        requirementMet = True
                else:
                    ## Find all http and https links. Beginning the search with " helps ensure that only valid urls are found.
                    all_url_matches = re.findall(r'"https?://[^"]+|"/courses/\d+/files/\d+', syllabusBody)

                    ## syllabi_downloaded will contain the names of any downloaded syllabi
                    syllabi_downloaded = []
                
                    if (all_url_matches):
                        ## The JSON.syllabus_body contains at least one URL
                        ## Iterate through all the URLs and process them one at a time.
                        syllabi_downloaded.extend(process_url_matches (all_url_matches, courseName, save_location))
                    else:
                        ## JSON.syllabus_body did not contain any URLs
                        localSetup.logger.info(f"\n     {courseName} No url matches")
                    if (syllabi_downloaded):
                        ## At least one potential syllabus was found.
                        localSetup.logger.info(f"\n     {courseName} Syllabi Downloaded: " + str(syllabi_downloaded))
                        requirementMet = True
                    else:
                        ## None of the URL matches (i.e. links in the HTML) were a course or microsoft file containing the word syllabus in the filename
                        ## or there were just no URLs. Either way, save the json.syllabus_body retrieved earlier and convert it to PDF.
                        localSetup.logger.info(f"\n     {courseName} No known Syllabi downloaded")
                        try: ## Irregular try clause, do not comment out in testing
                            if (len(syllabusBody) < 1500):
                                ## The syllabus body is short. It is probably bogus so make note of it by saving the courseName
                                ## Convert HTML to PDF, download it, and put it into the primary directory
                                pdfkit.from_string("<meta charset='utf-8'>" + courseName + syllabusBody, save_location + "\\" + courseName + ".pdf", configuration=config)
                                if course_needs_syllabi:
                                    departmentReportLocation, collegeReportLocation = syllabiReportSaveCourseInfo (p1_save_location = save_location, p1_collegeReportLocation = collegeReportLocation, p1_courseName = courseName, \
                                        issue = "Short Syllabus Downloaded", required_action = "Check whether a syllabus is embedded on the course's syllabus tab. " \
                                            + "If there is a syllabus, download it, rename it to have syllabus in its file name, and upload " \
                                            + "the new file to replace the old file. If there isn't a syllabus file in the syllabus tab, embed one", \
                                        p1_instructor_name = course_teacher_1_name, p1_start_date = start_date, p1_end_date = end_date, p1_term_id = p2_inputTerm, \
                                        p1_department = courseAccountId, p2_collegeOrDeptMissingRequirement = p1_CollegeOrDeptMissingRequirement)
                                    
                                    localSetup.logger.info(f"\n     {courseName} Download: Short Syllabus Body to converted pdf")
                                    
                                    requirementMet = False
                                else:
                                    localSetup.logger.info (f"     \n{courseName} has a short syllabus but doesn't need one.")
                                    requirementMet = True
                            else:
                                ## Convert HTML to PDF and download. Save to Probable_Syllabus.
                                pdfkit.from_string("<meta charset='utf-8'>" + courseName + syllabusBody, save_location + "\\" + courseName + ".pdf", configuration=config)
                                localSetup.logger.info(f"\n     {courseName} Download: Syllabus Body converted to pdf")
                                requirementMet = True
                                departmentReportLocation = f"{save_location}{scriptRequirementMissingFolderIdentifier}\\"
                                collegeReportLocation = collegeReportLocation
                        except Exception as Error: ## Irregular except clause, do not comment out in testing
                            localSetup.logger.warning ("Saving the syllabus_body as a pdf", f" {Error} \nCourse: {courseName}")
            
            ## Track the results and actions of the call to support the collegeOrDeptMissingRequirement list
            if (requirementMet == False):
                if departmentReportLocation not in p1_CollegeOrDeptMissingRequirement:
                    p1_CollegeOrDeptMissingRequirement.append(departmentReportLocation)
                    localSetup.logger.info (f"     \nMissing Syllabi csv created at {departmentReportLocation}")

                if (collegeReportLocation):
                    if collegeReportLocation not in p1_CollegeOrDeptMissingRequirement:
                        p1_CollegeOrDeptMissingRequirement.append(collegeReportLocation)
                        localSetup.logger.info ("Missing Syllabi csv created at " + collegeReportLocation)
    except Exception as Error:
        errorHandler.sendError (f"functionName Course: {courseName}", error)

## This function processes the rows of the CSV file and sends on the relavent data to process_course
def termSyllabiReport (p1_inputTerm):
    functionName = "Term Syllabi Report"
    
    try:
        ## The collegeOrDeptMissingRequirement list is for the syllabiReportSaveCourseInfo function. 
        ## It enables the function to overwrite the previous version of the missing_syllabi file at the beginning and then append all new information after the first overwite.
        collegeOrDeptMissingRequirement = []

        ## Create a list to save the department save pathes determined by the relavent function based
        ## off of the Canvas sub-account structure
        departmentSavePaths = {}

        targetSchoolYear = None

        ## Define the current school year by whether it is before or during/after september
        if re.search("AF|FA|GF", p1_inputTerm):
            ## Fall terms are the first terms of a new school year so FA20 is part of the 2020-21 school year.
            targetSchoolYear = f"{century}{p1_inputTerm[2:]}-{int(p1_inputTerm[2:]) + 1}"
        if re.search("SP|GS|AS|SG|SA|SU", p1_inputTerm):
            ## Spring and Summer terms belong in the same school year as the fall terms before them, so SP21 is part of the same 2020-21 school year as FA20.
            targetSchoolYear = f"{century}{int(p1_inputTerm[2:]) - 1}-{p1_inputTerm[2:]}"

        ## Read the relavent term's courses file into a pandas dataframe
        rawTermCoursesDF = pd.read_csv(f"{baseLocalInputPath}{targetSchoolYear}\\{p1_inputTerm}\\{p1_inputTerm}_Canvas_Courses.csv")

        ## Remove any rows where the course is unpublished or is the chapel course, or were not created by the SIS
        termCoursesDF = rawTermCoursesDF[rawTermCoursesDF['status'] != "unpublished"]
        termCoursesDF = termCoursesDF[termCoursesDF['account_id'] != "U_CHPL"]
        termCoursesDF = termCoursesDF[termCoursesDF['created_by_sis'] == True]
        termCoursesDF = termCoursesDF.dropna(how='all')
        
        ## Create a list to hold the ongoing syllabus retrieval threads
        ongoingcourseSyllabiReportThreads = []
        
        ## For each row in the termCoursesDF dataframe
        for index, row in termCoursesDF.iterrows():

            ## Define a outcome reports and actions thread
            courseSyllabiReportThread = threading.Thread(target=courseSyllabiReport, args=(row, p1_inputTerm, departmentSavePaths, collegeOrDeptMissingRequirement,))
                
            ## Start the outcome reports and actions thread
            courseSyllabiReportThread.start()
                
            ## Add the outcome reports and actions thread to the list of ongoing threads
            ongoingcourseSyllabiReportThreads.append(courseSyllabiReportThread)
                
            ## Wait a second to ensure there is a gap before the next thread
            time.sleep(1)
        
        ## Check if all ongoing outcome threads have completed
        for thread in ongoingcourseSyllabiReportThreads:
            thread.join()

        ## Apply courseSyllabiReport to each row
        ##termCoursesDF.apply(courseSyllabiReport, args=(p1_inputTerm, departmentSavePaths, collegeOrDeptMissingRequirement,), axis=1)

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function opens the CSV file, the save locations json file, sends the information on, and closes both files
def runSyllabiReport(inputTerm = ""):
    functionName = "Run Syllabi Report"
    
    try:
        currentTerm = ""

        if inputTerm:
            currentTerm = inputTerm
    
        else:
            ## January through May is the Spring Term
            if currentMonth >= 1 and currentMonth <= 5:
                currentTerm = f"SP{str(currentYear)[2:]}"

            ## June through August is the Summer Term
            elif currentMonth >= 6 and currentMonth <= 8:
                currentTerm = f"SU{str(currentYear)[2:]}"

            ## The other months (September through December) is the Fall Term
            else:
                currentTerm = f"FA{str(currentYear)[2:]}"

        termSyllabiReport (p1_inputTerm = currentTerm)
     
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

if __name__ == "__main__":

    ## Start and download the Canvas report
    runSyllabiReport (inputTerm = input("Enter the desired term in \
four character format (FA20, SU20, SP20): "))

    input("Press enter to exit")





## ===========================================================================
## FILE: ReportModules\Syllabus_Addendum_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Moduels

from math import fabs
import traceback, os, sys, logging, threading, time, numpy, csv, requests, time, json, pdfkit, re, os, shutil, io, os.path
import base64
from datetime import datetime
from datetime import date
import pandas as pd

## Set working directory
os.chdir(os.path.dirname(__file__))

## Add Script repository to syspath
sys.path.append(f"{os.getcwd()}\ResourceModules")

## Define the script name, purpose, and external requirements for logging and error reporting purposes
scriptName = "Syllabus Addendum Report"

## Script file identifier
scriptRequirementMissingFolderIdentifier = "Missing_Addendum"

scriptPurpose = r"""
The Course Addendum Checker Script was written by NNU's IDT department to check whether NNU's canavs courses have the static Syllabus Addendum link, make .csv lista of the courses that do not have the link, and store the .csv files under \Employees-Read Only\University Syllabi by college and department.
"""
externalRequirements = r"""
To function properly, this script requires that the static Syllabus Addendum link "https://my.nnu.edu/ics/syllabus_addendum.aspx" (which redirects to the current addendum) be placed in the Canvas Syllabus tab.
"""

## Time variables
currentDateTime = date.today()
currentYear = currentDateTime.year
currentMonth = currentDateTime.month
lastYear = currentYear - 1
nextYear = currentYear + 1
century = str(currentYear)[:2]
decade = str(currentYear)[2:]

##pdfkit (which enables the script to convert html code into .pdf and save it) needs to access wkhtmltopdf.exe which is easier if it has a direct path configured instead of try:ing to find it generally
path_wkhtmltopdf = r'Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe' ##This is the default location of wkhtmltopdf.exe and would need to be changed if the default installation location for wkhtmltopdf was edited.
config = pdfkit.configuration(wkhtmltopdf=path_wkhtmltopdf)

## Set working directory
fileDir = os.path.dirname(__file__)
os.chdir(fileDir)

## The relative path is used to provide a generic way of finding where the Scripts TLC folder has been placed
## This provides a non-script specific manner of finding the vaiours related modules
PFRelativePath = r".\\"

## If the Scripts TLC folder is not in the folder the PFRelative path points to
## look for it in the next parent folder
while "Scripts TLC" not in os.listdir(PFRelativePath):

    PFRelativePath = f"..\\{PFRelativePath}"

## Change the relative path to an absolute path
absolutePath = f"{os.path.abspath(PFRelativePath)}\\"

## Add Input Modules to the sys path
sys.path.append(f"{absolutePath}Scripts TLC\\ResourceModules")

## Import local modules
from Error_Email_API import errorEmailApi
from Download_File import downloadFile

from Create_Sub_Account_Save_Path import determineDepartmentSavePath

## Local Path Variables
baseLogPath = f"{absolutePath}Logs\\{scriptName}\\"
configPath = f"{absolutePath}\\Configs TLC\\"
baseLocalInputPath = f"{absolutePath}Canvas Resources\\"  ## This is only the base path as the real path requires the requested term

## External Path Variables

## Define a variable to hold the output path 
baseExternalOutputPath = None ## Where the syllabus repository will be created and relavent reports stored

## Open External_Resource_Paths.json from the config path and get the SISResourcePath and baseExternalOutputPath values
with open (f"{configPath}External_Resource_Paths.json", "r") as file:
    fileJson = json.load(file)
    baseExternalOutputPath = fileJson["UniversitySyllabusResourcePath"]

## Canvas Instance Url
coreCanvasApiUrl = None
## Open the Core_Canvas_Url.txt from the config path
with open (f"{configPath}Core_Canvas_Url.txt", "r") as file:
    coreCanvasApiUrl = file.readlines()[0]

## If the script is run as main the folder with the access token is in the parent directory
canvasAccessToken = ""

## Open and retrieve the Canvas Access Token
with open (fr"{configPath}Canvas_Access_Token.txt", "r") as file:
    canvasAccessToken = file.readlines()[0]

## List of courses that don't need a syllabus. Syllabi for such courses are still gathered but they are not listed in the missing_syllabi.csv
list_of_courses_that_dont_need_syllabi = []
with open(f"{configPath}List_of_uneeded_syllabi.csv", 'r') as tempCsvFile:
    tempcsvReader = csv.DictReader(tempCsvFile, delimiter = ',')
    for row in tempcsvReader:
        list_of_courses_that_dont_need_syllabi.append(row['course_id'])
    tempCsvFile.close()

##Primary API call header and payload
header = {'Authorization' : 'Bearer ' + canvasAccessToken}
payload = {'include[]': ['syllabus_body', 'term', 'account', 'teachers', 'sections', 'total_students']}

## Begin localSetup.logger set up

## If the base log path doesn't already exist, create it
if not (os.path.exists(baseLogPath)):
    os.makedirs(baseLogPath, mode=0o777, exist_ok=False)

## Log configurations
logger = logging.getLogger(__name__)
rootFormat = ("%(asctime)s %(levelname)s %(message)s")
FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
logging.basicConfig(format=rootFormat, filemode = "a", level=logging.INFO)

## Info Log Handler
infoLogFile = f"{baseLogPath}\\Info Log.txt"
logInfo = logging.FileHandler(infoLogFile, mode = 'a')
logInfo.setLevel(logging.INFO)
logInfo.setFormatter(FORMAT)
localSetup.logger.addHandler(logInfo)

## Warning Log handler
warningLogFile = f"{baseLogPath}\\Warning Log.txt"
logWarning = logging.FileHandler(warningLogFile, mode = 'a')
logWarning.setLevel(logging.WARNING)
logWarning.setFormatter(FORMAT)
localSetup.logger.addHandler(logWarning)

## Error Log handler
errorLogFile = f"{baseLogPath}\\Error Log.txt"
logError = logging.FileHandler(errorLogFile, mode = 'a')
logError.setLevel(logging.ERROR)
logError.setFormatter(FORMAT)
localSetup.logger.addHandler(logError)

## This variable enables the except function to only send

## by tracking what functions have already been recorded as having errors
errorHandler = errorEmailApi(scriptName, scriptPurpose, externalRequirements, localSetup)

## This function handles function errors
def errorHandler.sendError (p1_ErrorLocation, p1_ErrorInfo, sendOnce = True):
    functionName = "errorHandler.sendError"

    ## Log the error
    localSetup.logger.error (f"     \nA script error occured while running {p1_ErrorLocation}. " +
                     f"Error: {str(p1_ErrorInfo)}")

    ## If the function with the error has not already been processed send an email alert
    if (p1_ErrorLocation not in setOfFunctionsWithErrors):
        errorEmailApi.sendEmailError(p2_ScriptName = scriptName, p2_ScriptPurpose = scriptPurpose, 
                                     p2_ExternalRequirements = externalRequirements, 
                                     p2_ErrorLocation = p1_ErrorLocation, p2_ErrorInfo = f"{p1_ErrorInfo}: \n\n {traceback.format_exc()}")
        
        ## Add the function name to the set of functions with errors
        setOfFunctionsWithErrors.add(p1_ErrorLocation)
        
        ## Note that an error email was sent
        localSetup.logger.error (f"     \nError Email Sent")
    
    ## Otherwise log the fact that an error email as already been sent
    else:
        localSetup.logger.error (f"     \nError email already sent")

""" 
 This fuction saves the course ID and other identifiers of the course in question.
 The intended purpose of this function is to make a log of courses without a syllabus addendum
 with the ulimate goal that departments work through and add/fix the syllabi for these courses.
"""
def addendumReportSaveCourseInfo(p1_saveLocation, p1_college_saveLocation, p1_courseName, issue, p1_instructor_name,\
   p1_start_date, p1_end_date, p1_term_id, p1_department, p2_collegeOrDeptMissingRequirement):
    functionName = "addendumReportSaveCourseInfo"

    try:
        ## This function creates a csv file to record when a syllabus is missing or it is uncertain if a syllabus was retrieved.
        ## Create a new missing_syllabi csv for that context the first time that a department is missing a syllabi
        departmentReportLocation = f"{p1_saveLocation}\\{scriptRequirementMissingFolderIdentifier}\\"
        deptmentMissingRequirementCsv = departmentReportLocation + f"{p1_term_id}_{scriptRequirementMissingFolderIdentifier}.csv"
        collegeMissingRequirementCsv = f"{p1_college_saveLocation}\\{p1_term_id}_{scriptRequirementMissingFolderIdentifier}.csv"

        if (deptmentMissingRequirementCsv not in p2_collegeOrDeptMissingRequirement):
            ## If the path doesn't exist, create it
            if not (os.path.exists(departmentReportLocation)):
                os.makedirs(departmentReportLocation, mode=0o777, exist_ok=False)
            ## If it does exist, ensure the last iteration of this department's missing requirement file for the relavent term has been removed
            else:
                if os.path.exists(deptmentMissingRequirementCsv):
                    os.remove(deptmentMissingRequirementCsv)
            ## Create a new department MissingRequirement csv
            with open (deptmentMissingRequirementCsv, "w", newline="") as csvFile_2:
                fieldnames = ["courseName", "Issue", "Required Action", "Instructor Name", "start_date", "end_date", "department"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writeheader()
                csvWriter.writerow({"courseName": p1_courseName, "Issue": issue, "Instructor Name": p1_instructor_name, "start_date": p1_start_date, "end_date": p1_end_date, "department": p1_department})
                csvFile_2.close()
        ## If it is the second time (or more) in the current run of the script the missing requirement file is added onto
        else:
            with open (deptmentMissingRequirementCsv, "a", newline="") as csvFile_2:
                fieldnames = ["courseName", "Issue", "Required Action", "Instructor Name", "start_date", "end_date", "department"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writerow({"courseName": p1_courseName, "Issue": issue, "Instructor Name": p1_instructor_name, "start_date": p1_start_date, "end_date": p1_end_date, "department": p1_department})
                csvFile_2.close()
        ## A college level version of the missing requirement is made in addition to the department level file
        if (collegeMissingRequirementCsv not in p2_collegeOrDeptMissingRequirement):
            ## If the path doesn't exist, create it
            if not (os.path.exists(p1_college_saveLocation)):
                os.makedirs(p1_college_saveLocation, mode=0o777, exist_ok=False)
            ## If it does exist, ensure the last iteration of this department's missing requirement file for the relavent term has been removed
            else:
                if os.path.exists(collegeMissingRequirementCsv):
                    os.remove(collegeMissingRequirementCsv)
            ## Create a new college MissingRequirement csv
            with open (collegeMissingRequirementCsv, "w", newline="") as csvFile_2:
                fieldnames = ["courseName", "Issue", "Required Action", "Instructor Name", "start_date", "end_date", "Term", "department"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writeheader()
                csvWriter.writerow({"courseName": p1_courseName, "Issue": issue, "Instructor Name": p1_instructor_name, "start_date": p1_start_date, "end_date": p1_end_date, "department": p1_department})
                csvFile_2.close()
        ## If it is the second time (or more) in the current run of the script the missing requirement file is added onto    
        else:
            with open (collegeMissingRequirementCsv, "a", newline="") as csvFile_2:
                fieldnames = ["courseName", "Issue", "Required Action", "Instructor Name", "start_date", "end_date", "Term", "department"]
                csvWriter = csv.DictWriter(csvFile_2, fieldnames=fieldnames, delimiter = ',')
                csvWriter.writerow({"courseName": p1_courseName, "Issue": issue, "Instructor Name": p1_instructor_name, "start_date": p1_start_date, "end_date": p1_end_date, "department": p1_department})
                csvFile_2.close()
                
        p2_collegeOrDeptMissingRequirement.append (deptmentMissingRequirementCsv)
        p2_collegeOrDeptMissingRequirement.append (collegeMissingRequirementCsv)

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function processes the urls found within the course syllabus tab and makes a note if the course doesn't have the syllabus addendum
## Script Specific
def process_url_matches (p1_all_url_matches):
    functionName = "process_url_matches"

    try:
        ## The following set enable the script to skip previously processed urls
        processed_urls = set()
        
        ## Define Requirement to hold whether or not the requirement is met
        requirementMet = False

        for element in p1_all_url_matches:
            if (element in processed_urls):
                localSetup.logger.info("Link Skipped: Previously processed URL")
            else:
                ## URL has not been seen before - attempt to process it.
                processed_urls.add(str(element))
                if re.search(r'syllabus_addendum.aspx',  element, re.IGNORECASE):
                    requirementMet = True
        return requirementMet
    except Exception as Error:
        errorHandler.sendError (functionName, Error)
        return True

## This function makes a get call to the and processes the course listed on the most recent 
## row of the CSV file and looks for urls within its syllabus tab
## This function processes the rows of the CSV file and sends on the relavent data to process_course
def courseAddendumReport (row, p3_inputTerm, p1_departmentSavePaths, p1_CollegeOrDeptMissingRequirement, p1_schoolYear):
    functionName = "Course Addendum Report"

    try:
    
        ## Define the variables that will be used to save the course's information
        requirementMet = None
        reportSaveLocation = None
        reportCollegeSaveLocation = None
    
        ## If the row's course name is pd.nan, return
        if pd.isna(row['long_name']):
            return
           
        ## For each row in our CSV file we only pull two columns: course_id, and account_id.

        ## Sample course_id values: FA2021_BIOL2220_01, FA2021_EDUC2110_1L, FA2021_ACCT2060_01
        courseSisId = row['course_id'] 

        ## Sample account_id values: U_HSPS, U_LLIT, U_MUSI_APP
        courseAccountId = row['account_id']  

        ## Replace unsaveable characters in the course name with spaces
        courseName = row['short_name'].replace("<", " ").replace(">", " ").replace(":", " ").replace('"', " ")\
            .replace("/", " ").replace("\\", " ").replace("|", " ").replace("?", " ").replace("*", " ") 

        ## Begin a new course entry: in the log
        localSetup.logger.info("\n     Course: " + courseSisId)
            
        ## Create the URL the API call will be made to
        course_API_url = coreCanvasApiUrl + "courses/sis_course_id:" + courseSisId
                
        ## Make the API call and save the result as course_object
        course_object = requests.get(course_API_url, headers = header, params = payload)
                
        ## If the API status code is anything other than 200 it is an error, so log it and skip
        if (course_object.status_code != 200):
            localSetup.logger.info(f"\n     {courseName} Error: {str(course_object.status_code)}" \
                + f"\n{course_API_url})" \
                + f"\n{course_object.url}")
        else:

            ## Save the primary body of information retrieved by the API call as course_text_jsonString 
            course_text_jsonString = course_object.text
        
            ## Convert the json body of information as a Python Dictionary
            course_text_jsonObject = json.loads(course_text_jsonString)
        
            ## From course_text_jsonString, isolate the course's syllabus body and sections
            syllabus_body = course_text_jsonObject["syllabus_body"]
            sections = course_text_jsonObject["sections"]
        
            ## Define empty variables to hold the department and college specific save paths 
            courseDepartmentPath = None
            courseCollegePath = None

            ## Check whether the courseAccountId is listed in the departmentSavePaths dict. If it is, 
            ## retrieve the department's associated filepath (example: /College of Natural & Applied Sciences/Chemistry:/).
            if courseAccountId in p1_departmentSavePaths:
                courseDepartmentPath = p1_departmentSavePaths[courseAccountId]

            ## Otherwise create use the Canvas sub-account structure above the course to create the department's filepath 
            else:
                ## If the course account ID is blank, set the course department path to the Misc Folder
                if pd.isna(courseAccountId):
                    courseDepartmentPath = "Misc\\Uncategorized\\"

                else:
                    courseDepartmentPath = p1_departmentSavePaths[courseAccountId] = determineDepartmentSavePath \
                        (courseAccountId = courseAccountId)

            ## If the determined path has the manually created courses parent account name in it, skip the course
            if "Manually-Created Courses" in courseDepartmentPath:
                localSetup.logger.info(f"\n     {courseName} Skipped: Manually created course so no need for a syllabi")
                return
            
            ## Isolate the college piece of the department file path and save it as courseCollegePath.
            rawcourseCollegePath = (courseDepartmentPath.rsplit("\\"))[0]
            courseCollegePath = f"\{rawcourseCollegePath}\\"
            
            schoolYearPath = (f"{p1_schoolYear}\\")
        
            ## If the course has its own indivigual start and end date seperate from the term start and end date, save them in case the syllbus is missing or unidentifiable.
            start_date = ""
            end_date = ""
            if course_text_jsonObject["start_at"]:
                start_date = course_text_jsonObject["start_at"]
            if course_text_jsonObject["end_at"]:
                end_date = course_text_jsonObject["end_at"]
        
            ## Save the instructor name in case the syllbus is missing or unidentifiable, but save it as none initially because not all courses have instructors.
            course_teacher_1_name = None
            if (course_text_jsonObject["teachers"]):
                course_teacher_1_name = course_text_jsonObject["teachers"][0]["display_name"]
        
            ## Create the save and college save location
            saveLocation = os.path.abspath(baseExternalOutputPath + courseDepartmentPath + schoolYearPath)
            college_saveLocation = os.path.abspath(baseExternalOutputPath + courseCollegePath + "\College_" + scriptRequirementMissingFolderIdentifier + "\\" + schoolYearPath)
            if not (os.path.exists(saveLocation + "\Other_Course_Files")):
                ## Create the sub-account & department specific directory if it doesn't already exist.
                os.makedirs(saveLocation + "\Other_Course_Files", mode=0o777, exist_ok=False)
                localSetup.logger.info(str("\n" + saveLocation + "\Other_Course_Files: directories created\n"))
        
            ## If the course doesn't have a syllabus body, skip it and add the relavent info to the Missing_Syllabi.csv file.
            if not (course_text_jsonObject["syllabus_body"]):
                localSetup.logger.info("\n     Course Skipped: No Syllabus_Body")
                return "", "", False
            elif (course_text_jsonObject['total_students'] == 0):
                localSetup.logger.info("\n     Course Skipped: No Students")
                return "", "", False
            else:
                ## If the course has a template syllabus body, skip it and add the relavent info to the Missing_Syllabi.csv file.
                ## 323 is the known character length of one version of the syllabus template, and the <span> listed is a known piece of the version of the syllabus template current when this comment was written (11/5/21).
                if (len(syllabus_body) == 323 or re.search(r'<span style="font-size: 36pt;">Replace with Syllabus Content</span>', syllabus_body)):
                    localSetup.logger.info("\n     Course Skipped: Template Syllabus Body")
                    return "", "", False
                else:
                    ## Find all http and https links. Beginning the search with " helps ensure that only valid urls are found.
                    all_url_matches = re.findall(r'"https?://[^"]+', syllabus_body)

                    contains_requirement = False
                    if (all_url_matches):
                        ## The JSON.syllabus_body contains at least one URL
                        ## Iterate through all the URLs and process them one at a time.
                        contains_requirement = process_url_matches (all_url_matches)
                    else:
                        ## JSON.syllabus_body did not contain any URLs
                        localSetup.logger.info("\n     \nNo url matches")
                    if (contains_requirement):
                        ## Course contains syllabus addendum link
                        localSetup.logger.info ("Course contains external addendum link")
                        return (saveLocation + "\\" + p3_inputTerm), (college_saveLocation + "\\" + p3_inputTerm), True
                    else:
                        if not (sections):
                            ## Courses without sections do not need a syllabus addendum
                            return (saveLocation + "\\" + p3_inputTerm), (college_saveLocation + "\\" + p3_inputTerm), True
                        else:
                            addendumReportSaveCourseInfo(saveLocation, college_saveLocation, courseName, "Course doesn't have the most recent addendum link",
                                                         course_teacher_1_name, start_date, end_date, p3_inputTerm, courseAccountId, p1_CollegeOrDeptMissingRequirement)
                        localSetup.logger.info ("Course does not contain external addendum link")
                        return (saveLocation + "\\" + p3_inputTerm), (college_saveLocation + "\\" + p3_inputTerm), False

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function processes the rows of the CSV file and sends on the relavent data to process_course
def termAddendumReport (p2_inputTerm):
    functionName = "Term Addendum Report"

    try:
        ## The collegeOrDeptMissingRequirement list is for the addendumReportSaveCourseInfo function. 
        ## It enables the function to overwrite the previous version of the missing_syllabi file at the beginning and then append all new information after the first overwite.
        collegeOrDeptMissingRequirement = []

        ## Create a list to save the department save pathes determined by the relavent function based
        ## off of the Canvas sub-account structure
        departmentSavePaths = {}

        ## Determine and save the term's school year
        schoolYear = None
        if re.search("AF|FA|GF", p2_inputTerm):
            ## Fall terms are the first terms of a new school year so FA20 is part of the 2020-21 school year.
            schoolYear = (century + p2_inputTerm[2:] + "-" + str(int(p2_inputTerm[2:]) + 1))
        elif re.search("SP|GS|AS|SG|SA|SU", p2_inputTerm):
            ## Spring and Summer terms belong in the same school year as the fall terms before them, so SP21 is part of the same 2020-21 school year as FA20.
            schoolYear = (century + str(int(p2_inputTerm[2:]) - 1) + "-" + p2_inputTerm[2:])

        ## Read the relavent term's courses file into a pandas dataframe
        rawTermCoursesDF = pd.read_csv(f"{baseLocalInputPath}{schoolYear}\\{p2_inputTerm}\\{p2_inputTerm}_Canvas_Courses.csv")

        ## Remove any rows where the course is unpublished or is the chapel course
        termCoursesDF = rawTermCoursesDF[rawTermCoursesDF['status'] != "unpublished"]
        termCoursesDF = termCoursesDF[termCoursesDF['account_id'] != "U_CHPL"]
        termCoursesDF = termCoursesDF.dropna(how='all')
        termCoursesDF = termCoursesDF.dropna(subset=['course_id'])

        ## Apply courseSyllabiReport to each row
        termCoursesDF.apply(courseAddendumReport, args=(p2_inputTerm, departmentSavePaths, collegeOrDeptMissingRequirement, schoolYear), axis=1)

    except Exception as Error:
        errorHandler.sendError (functionName, Error)

## This function opens the CSV file, the save locations json file, sends the information on, and closes both files
def runAddendumReport(p1_inputTerm = ""):
    functionName = "Run Addendum Report"
    
    try:
        currentTerm = ""

        ## If a term is not given, determine it off of the current year
        if not p1_inputTerm:
            currentTerm = None
            
            ## January through May is the Spring Term
            if currentMonth >= 1 and currentMonth <= 5:
                currentTerm = f"SP{str(currentYear)[2:]}"

            ## June through August is the Summer Term
            elif currentMonth >= 6 and currentMonth <= 8:
                currentTerm = f"SU{str(currentYear)[2:]}"

            ## The other months (September through December) is the Fall Term
            else:
                currentTerm = f"FA{str(currentYear)[2:]}"

        termAddendumReport (p2_inputTerm = p1_inputTerm)
     
    except Exception as Error:
        errorHandler.sendError (functionName, Error)

if __name__ == "__main__":

    ## Define the API Call header using the retreived Canvas Token
    ##header = {'Authorization' : f"Bearer {canvasAccessToken}"}

    ## Start and download the Canvas report
    runAddendumReport (p1_inputTerm = input("Enter the desired term in \
four character format (FA20, SU20, SP20): "))

    input("Press enter to exit")

## ===========================================================================
## FILE: ReportModules\__init__.py
## ===========================================================================




## ===========================================================================
## FILE: ResourceModules\Canvas_Report.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Modules
import os, time, json, pandas as pd, io, csv, zipfile
from datetime import datetime
from pandas.errors import EmptyDataError

## If the module is run directly 
try: ## Irregular try clause, do not comment out in testing
    ## Import local modules and variables
    from Local_Setup import LocalSetup
    from TLC_Common import (downloadFile, makeApiCall, isFileRecent)
    from Core_Microsoft_Api import downloadSharedMicrosoftFile
except ImportError: ## Otherwise as a relative import if the module is imported
    from .Local_Setup import LocalSetup
    from .TLC_Common import (downloadFile, makeApiCall, isFileRecent)
    from .Core_Microsoft_Api import downloadSharedMicrosoftFile

## Import neccessary config variables
from Common_Configs import coreCanvasApiUrl, canvasAccessToken, undgTermsCodesToWordsDict, gradTermsCodesToWordsDict, gradTermsWordsToCodesDict, serviceEmailAccount

## Define the script name, purpose, and external requirements for logging and error reporting purposes
__scriptName = os.path.basename(__file__).replace(".py", "")
scriptPurpose = r"""
This module (Canvas_Report) provides the CanvasReport class for interacting with the Canvas Reports API.
It allows users to request reports, check their status, download them, and load them into pandas DataFrames.
It requires a valid Canvas API token and access to the specified report endpoints.
    """
externalRequirements = r"""
To function properly this module requires:
- A valid Canvas API token with permissions to access the specified report endpoints.
    """

class CanvasReport:
    def __init__(self, localSetup : LocalSetup, reportType, apiUrl = None, header = None, termCode=None, accountName="NNU",
                 outputRoot=None, includeDeleted=False, filename=None, payload=None, 
                 endpoint="provisioning_csv", accountCanvasID=None):
        ## Receive LocalSetup from caller
        self.localSetup = localSetup
        self.localSetup.logger = self.localSetup.logger  # Use LocalSetup's localSetup.logger
        ## Use LocalSetup's internal resource paths for Canvas unless overridden
        self.outputRoot = outputRoot or self.localSetup.getInternalResourcePaths("Canvas")
        ## Initialize the CanvasReport object with configuration parameters
        self.reportType = reportType
        self.apiUrl = apiUrl or coreCanvasApiUrl
        self.header = header or {'Authorization' : f"Bearer {canvasAccessToken}"}
        self.termCode = termCode
        self.accountName = accountName
        self.includeDeleted = includeDeleted
        self.filename = filename or self._generateFilename()  # Generate filename if not provided
        self.payload = payload or self._buildDefaultPayload()  # Use provided payload or build default
        self.endpoint = endpoint
        self.accountsDf = pd.DataFrame() if self.reportType == "accounts" else self.getAccountsDf(self.localSetup)
        self.accountCanvasID = accountCanvasID if accountCanvasID else self._resolveAccountId()
        self.outputPath = self._buildOutputPath()  # Build directory path for output
        self.filePath = os.path.join(self.outputPath, self.filename)  # Full path to the output file
        self.statusUrl = None
        os.makedirs(self.outputPath, exist_ok=True)  # Ensure output directory exists
        ## Log initialization
        self.localSetup.logger.info(f"Initialized CanvasReport for reportType={self.reportType}, outputPath={self.outputPath}")


    def _buildDefaultPayload(self):
        # Construct default payload for the API call
        payload = {f'parameters[{self.reportType}]': 'true'}
        if self.termCode and self.termCode != "All":
            payload['parameters[enrollment_term_id]'] = f"sis_term_id:{self.termCode}"
        if self.includeDeleted:
            payload['parameters[include_deleted]'] = 'true'
        return payload

    ## Generate a filename for the report
    def _generateFilename(self):
        suffix = self.reportType.replace(" ", "_").capitalize()
        if self.includeDeleted:
            suffix += "_including_deleted"
        return f"{self.termCode or 'All'}_{suffix}.csv"

    ## Build the output directory path based on term code and current year
    def _buildOutputPath(self):
        if self.termCode and self.termCode not in ("All", "Default Term"):
            # Extract year and term prefix
            termYear = int(str(self.localSetup.dateDict['century']) + self.termCode[2:])
            termPrefix = self.termCode[:2]

            # Determine term name (Fall, Spring, Summer)
            termName = undgTermsCodesToWordsDict.get(termPrefix) or gradTermsCodesToWordsDict.get(termPrefix)

            # Determine course level based on prefix
            courseLevel = "Graduate" if termPrefix in gradTermsCodesToWordsDict.keys() else "Undergraduate"

            # Use LocalSetup's public method to get or create the course-level path
            return self.localSetup.getCourseLevelPath(courseLevel, termName, termYear)

        # Default to Canvas root if termCode is "All"
        return self.outputRoot



    ## Resolve the Canvas account ID based on the account name
    def _resolveAccountId(self):
        if self.accountName == "NNU":
            return 1
        if self.accountsDf is not None and self.accountName:
            match = self.accountsDf.loc[self.accountsDf["name"] == self.accountName, "canvas_account_id"]
            if not match.empty:
                return match.values[0]
        return None  # fallback if not resolvable


    ## Check if the existing report file is current based on max age in hours
    def isCurrent(self, maxAgeHours=3.5):
        return isFileRecent(self.localSetup, self.filePath, maxAgeHours)

    ## Request a new report from Canvas and download it
    def getOrCreateReport(self, attempt=0, maxAttempts=3):
        ## Define the API endpoint, adjusting for account if needed
        apiUrl = f"{coreCanvasApiUrl}accounts/{self.accountCanvasID}/reports/{self.endpoint}" if self.accountCanvasID else self.apiUrl

        ## Get the first page of the index of reports to check for an already running report
        # indexResponse = makeApiCall(self.localSetup, p1_header=self.header, p1_apiUrl=apiUrl, p1_apiCallType="get", firstPageOnly=True)
        # indexData = indexResponse.json()
        # activeReport = next((r for r in indexData if r.get('status') in ['running', 'pending']), None)

        ## Define report ID and status URL variables
        # reportID = None
        # self.statusUrl = None

        ## IF there is an active report
        # if activeReport:
        #     ## Set the report ID and status URL
        #     reportID = activeReport['id']
        #     self.statusUrl = f"{apiUrl}/{reportID}"
        #     self.localSetup.logger.info(f"Found active report (ID: {reportID}). Monitoring progress...")
        # else:
            ## No active report, create a new one
        response = makeApiCall(self.localSetup, p1_header=self.header, p1_apiUrl=apiUrl, p1_payload=self.payload, p1_apiCallType="post")
        if response.status_code != 200:
            self.localSetup.logger.error(f"Failed to create new report. Status: {response.status_code}")
            return None
        reportId = json.loads(response.text)["id"]
        self.statusUrl = f"{apiUrl}/{reportId}"

        # Poll the report status until it's ready
        while True:
            statusResponse = makeApiCall(self.localSetup, p1_header=self.header, p1_apiUrl=self.statusUrl, p1_apiCallType="get")
            statusData = json.loads(statusResponse.text)
            #if statusResponse.status_code != 200:
                #raise Exception(f"Failed to get report status. HTTP {statusResponse.status_code}")
            if statusData.get("progress") == 100:
                break
            time.sleep(10)

        # Retry if the report is not properly generated
        if "attachment" not in statusData or "url" not in statusData["attachment"]:
            if attempt < maxAttempts:
                time.sleep(5)
                return self.getOrCreateReport(attempt + 1, maxAttempts)
            #raise Exception("Canvas report failed after multiple attempts.")

        # Download the report file
        downloadUrl = statusData["attachment"]["url"]
        downloadFile(self.localSetup, downloadUrl, self.filePath, "w")
        ## If the filepath doesn't exist or is empty, wait
        if not os.path.exists(self.filePath) or os.path.getsize(self.filePath) == 0:
            if attempt < maxAttempts:
                time.sleep(5)
                return self.getOrCreateReport(attempt + 1, maxAttempts)
            #raise Exception("Downloaded Canvas report file is empty after multiple attempts.")
        return self.filePath
    
    ## Get or create the report, monitoring its status until completion
    # def getOrCreateReport(self, pollInterval=10):
    #     """
    #     Checks if a report of this type is already running or completed.
    #     Monitors it until completion or creates a new one if none exist.
    #     Downloads the file when ready and returns the file path.
    #     """
    #     # Build index URL for this report type
    #     indexUrl = f"{coreCanvasApiUrl}accounts/{self.accountCanvasID}/reports/{self.endpoint}"
    #     self.localSetup.logger.info(f"Checking for existing {self.endpoint} reports...")
    #     response = makeApiCall(self.localSetup, p1_header=self.header, p1_apiUrl=indexUrl, p1_apiCallType="get", firstPageOnly=True)

    #     if response.status_code != 200:
    #         self.localSetup.logger.warning(f"Failed to retrieve report index for {self.endpoint}. Status: {response.status_code}")
    #         return None

    #     reportInstances = response.json()
    #     activeReport = next((r for r in reportInstances if r.get('status') in ['running', 'pending']), None)

    #     # If active report exists, monitor it
    #     if activeReport:
    #         reportId = activeReport['id']
    #         statusUrl = f"{indexUrl}/{reportId}"
    #         self.localSetup.logger.info(f"Found active report (ID: {reportId}). Monitoring progress...")
    #         while True:
    #             statusResponse = makeApiCall(self.localSetup, p1_header=self.header, p1_apiUrl=statusUrl, p1_apiCallType="get")
    #             statusData = statusResponse.json()
    #             progress = statusData.get('progress', 0)
    #             self.localSetup.logger.info(f"Report progress: {progress}%")
    #             if statusData.get('status') == 'complete':
    #                 downloadUrl = statusData.get('file_url') or statusData.get('attachment', {}).get('url')
    #                 if downloadUrl:
    #                     downloadFile(self.localSetup, downloadUrl, self.filePath, "w")
    #                     return self.filePath
    #             time.sleep(pollInterval)

    #     # No active report, create a new one
    #     createUrl = indexUrl
    #     self.localSetup.logger.info(f"No active report found. Creating new {self.endpoint} report...")
    #     createResponse = makeApiCall(self.localSetup, p1_header=self.header, p1_apiUrl=createUrl, p1_payload=self.payload, p1_apiCallType="post")

    #     if createResponse.status_code != 200:
    #         self.localSetup.logger.error(f"Failed to create new report. Status: {createResponse.status_code}")
    #         return None

    #     newReport = createResponse.json()
    #     reportId = newReport['id']
    #     statusUrl = f"{indexUrl}/{reportId}"
    #     self.localSetup.logger.info(f"New report created (ID: {reportId}). Monitoring progress...")

    #     while True:
    #         statusResponse = makeApiCall(self.localSetup, p1_header=self.header, p1_apiUrl=statusUrl, p1_apiCallType="get")
    #         statusData = statusResponse.json()
    #         progress = statusData.get('progress', 0)
    #         self.localSetup.logger.info(f"Report progress: {progress}%")
    #         if statusData.get('status') == 'complete':
    #             downloadUrl = statusData.get('file_url') or statusData.get('attachment', {}).get('url')
    #             if downloadUrl:
    #                 downloadFile(self.localSetup, downloadUrl, self.filePath, "w")
    #                 return self.filePath
    #         time.sleep(pollInterval)

    ## Get the current report if it's fresh, otherwise request a new one
    def getCurrentReport(self, maxAgeHours=3.5):
        # Return the current report if it's fresh, otherwise get a new one
        if self.isCurrent(maxAgeHours):
            return self.filePath
        return self.getOrCreateReport()

    ## Get the current report if it's fresh, otherwise request a new one and load it into a pandas DataFrame
    def getCurrentDataFrame(self, maxAgeHours=3.5):
        self.getCurrentReport(maxAgeHours)
        targetDf = None
        attempt = 0
        while targetDf is None and attempt < 10:
            try: ## Irregular try clause, do not comment out in testing
                targetDf = pd.read_csv(self.filePath)
            except EmptyDataError:
                time.sleep(3)
            attempt += 1
        return targetDf


    
    @classmethod
    def getAccountsDf(cls, localSetup):    
        """
    Retrieve the Canvas Accounts report as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
    
    Returns:
        pd.DataFrame: DataFrame containing account details from Canvas.
        """
        methodName = "getAccountsDf"
        localSetup.logger.info(f"Starting {methodName}...")
        try:
            report = cls(localSetup=localSetup, reportType="accounts")
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName}: {Error}")
            #raise


    @classmethod
    def getTermsDf(cls, localSetup):    
        """
    Retrieve the Canvas Terms report as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
    
    Returns:
        pd.DataFrame: DataFrame containing term details from Canvas.
        """
        methodName = "getTermsDf"
        localSetup.logger.info(f"Starting {methodName}...")
        try:
            report = cls(localSetup=localSetup, reportType="terms")
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName}: {Error}")
            #raise


    @classmethod
    def getUsersDf(cls, localSetup):  
        """
    Retrieve the Canvas Users report as a pandas DataFrame.
    Includes deleted users by default.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
    
    Returns:
        pd.DataFrame: DataFrame containing user details from Canvas.
        """
        methodName = "getUsersDf"
        localSetup.logger.info(f"Starting {methodName}...")
        try:
            report = cls(localSetup=localSetup, reportType="users", includeDeleted=True)
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName}: {Error}")
            #raise


    @classmethod
    def getEnrollmentsDf(cls, localSetup, term, includeDeleted=False):
        """
    Retrieve the Canvas Enrollments report for a given term as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): The SIS term code (e.g., "FA25").
        includeDeleted (bool): Whether to include deleted enrollments.
    
    Returns:
        pd.DataFrame: DataFrame containing enrollment details for the specified term.
        """
        methodName = "getEnrollmentsDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}...")
        try:
            report = cls(localSetup=localSetup, reportType="enrollments", termCode=term, includeDeleted=includeDeleted)
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName} for term={term}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName} for term={term}: {Error}")
            #raise


    @classmethod
    def getCoursesDf(cls, localSetup, term):    
        """
    Retrieve the Canvas Courses report for a given term as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): The SIS term code (e.g., "FA25").
    
    Returns:
        pd.DataFrame: DataFrame containing course details for the specified term.
        """
        methodName = "getCoursesDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}...")
        try:
            report = cls(localSetup=localSetup, reportType="courses", termCode=term)
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName} for term={term}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName} for term={term}: {Error}")
            #raise


    @classmethod
    def getSectionsDf(cls, localSetup, term="All"):
        """
    Retrieve the Canvas Sections report for a given term as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): The SIS term code or "All" for all terms.
    
    Returns:
        pd.DataFrame: DataFrame containing section details for the specified term.
        """
        methodName = "getSectionsDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}...")
        try:
            report = cls(localSetup=localSetup, reportType="sections", termCode=term)
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName} for term={term}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName} for term={term}: {Error}")
            #raise

    @classmethod
    def getOutcomesDf(cls, localSetup, term, account, targetDesignator=""):
        """
    Retrieve the Canvas Outcomes report for a given term and account as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): The SIS term code.
        account (str): The Canvas account name.
        targetDesignator (str): Optional designator for filtering outcomes.
    
    Returns:
        pd.DataFrame: DataFrame containing outcome details for the specified term and account.
        """
        methodName = "getOutcomesDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}, account={account}, targetDesignator={targetDesignator}...")
        try:
            filename = (
                f"{term}_{targetDesignator}_Canvas_Outcomes.csv"
                if targetDesignator else f"{term}_{account}_Canvas_Outcomes.csv"
            )
            payload = {"parameters[enrollment_term_id]": f"sis_term_id:{term}"}
            report = cls(
                localSetup=localSetup,
                reportType="outcome_export",
                apiUrl=f"{coreCanvasApiUrl}accounts/{account if account != 'NNU' else 1}/reports/outcome_export_csv",
                termCode=term,
                accountName=account,
                filename=filename,
                payload=payload,
                endpoint="outcome_export_csv"
            )

            ## Download the file and get the path
            targetDestination = report.getCurrentReport()

            # Wait until file has content
            downloadedFileLines = []
            while not downloadedFileLines:
                with open(targetDestination, 'r', encoding='utf-8') as file:
                    downloadedFileLines = file.readlines()
                if not downloadedFileLines:
                    time.sleep(5)

            # Fix header if needed
            downloadedFileFirstLine = downloadedFileLines[0]
            maxCommas = max(line.count(',') for line in downloadedFileLines)
            if maxCommas > 12:
                firstLineParts = downloadedFileFirstLine.strip().split(',')
                firstLineParts[-1] = 'rating 1 points'
                newFirstLine = ','.join(firstLineParts) + ','
                for i in range(1, maxCommas - 11):
                    if i == maxCommas - 11:
                        newFirstLine += f'rating {i} description'
                    else:
                        newFirstLine += f'rating {i} description,rating {i+1} points,'
                downloadedFileLines[0] = newFirstLine + '\n'

            # Join lines and clean unwanted characters
            downloadedFileAsSingleString = ''.join(downloadedFileLines).replace(r'', '')
            downloadedFileDf = pd.DataFrame()
            try:
                downloadedFileDf = pd.read_csv(io.StringIO(downloadedFileAsSingleString), quoting=csv.QUOTE_MINIMAL, encoding='utf-8')
            except:
                localSetup.logger.warning(f"Initial read_csv failed for {methodName} for term={term}, account={account}. Retrying with 'latin-1' encoding.")

            ## IF the downloadedFileDf isn't empty
            if not downloadedFileDf.empty:
            
                ## Drop empty columns beyond 12th
                downloadedFileDf = downloadedFileDf.dropna(axis=1, how='all')

                ## Clean title column
                if 'title' in downloadedFileDf.columns:
                    if downloadedFileDf['title'].str.contains(r'').any():
                        downloadedFileDf['title'] = downloadedFileDf['title'].str.replace(r'', '')
                    if downloadedFileDf['title'].str.contains(r'').any():
                        downloadedFileDf['title'] = downloadedFileDf['title'].str.replace('', '\u2013')

                ## Save cleaned file
                downloadedFileDf.to_csv(targetDestination, index=False, encoding='utf-8')
                localSetup.logger.info(f"Completed {methodName} for term={term}, account={account}")
            else:
                localSetup.logger.warning(f"{methodName} for term={term}, account={account} resulted in an empty DataFrame.")

            return downloadedFileDf

        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName} for term={term}, account={account}: {Error}")
            #raise

    @classmethod
    def getOutcomeResultsDf(cls, localSetup, term, account, targetDesignator=""):
        """
    Retrieve the Canvas Outcomes report for a given term and account as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): The SIS term code.
        account (str): The Canvas account name.
        targetDesignator (str): Optional designator for filtering outcomes.
    
    Returns:
        pd.DataFrame: DataFrame containing outcome details for the specified term and account.
        """
        methodName = "getOutcomeResultsDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}, account={account}, targetDesignator={targetDesignator}...")
        try:
            filename = (
                f"{term}_{targetDesignator}_Canvas_Outcomes_Results.csv"
                if targetDesignator else f"{term}_{account}_Canvas_Outcomes_Results.csv"
            )
            payload = {
                "parameters[enrollment_term_id]": f"sis_term_id:{term}",
                "parameters[order]": "courses"
            }
            report = cls(
                localSetup=localSetup,
                reportType="outcome_results",
                apiUrl=f"{coreCanvasApiUrl}accounts/1/reports/outcome_results_csv",
                termCode=term,
                accountName=account,
                filename=filename,
                payload=payload,
                endpoint="outcome_results_csv"
            )
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName} for term={term}, account={account}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName} for term={term}, account={account}: {Error}")
            #raise
    
    @classmethod
    def getUnpublishedCoursesDf(cls, localSetup, term):

        """
    Retrieve the Canvas Unpublished Courses report for a given term as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): The SIS term code.
    
    Returns:
        pd.DataFrame: DataFrame containing unpublished course details for the specified term.
        """
        methodName = "getUnpublishedCoursesDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}...")
        try:
            filename = f"{term}_Canvas_Unpublished_Courses.csv"
            payload = {"parameters[enrollment_term_id]": f"sis_term_id:{term}"}
            report = cls(
                localSetup=localSetup,
                reportType="unpublished_courses",
                apiUrl=f"{coreCanvasApiUrl}accounts/1/reports/unpublished_courses_csv",
                termCode=term,
                filename=filename,
                payload=payload,
                endpoint="unpublished_courses_csv"
            )
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName} for term={term}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName} for term={term}: {Error}")
            #raise
 
    @classmethod
    def getCanvasUserLastAccessDf(cls, localSetup):  
        """
    Retrieve the Canvas Last User Access report as a pandas DataFrame.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
    
    Returns:
        pd.DataFrame: DataFrame containing last user access details.
        """
        methodName = "getCanvasUserLastAccessDf"
        localSetup.logger.info(f"Starting {methodName}...")
        try:
            report = cls(
                localSetup=localSetup,
                reportType="last_user_access_csv",
                apiUrl=f"{coreCanvasApiUrl}accounts/1/reports/last_user_access_csv",
                endpoint="last_user_access_csv"
            )
            df = report.getCurrentDataFrame()
            localSetup.logger.info(f"Completed {methodName}")
            return df
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName}: {Error}")
            #raise

    @classmethod
    def getGpsStudentsDf(cls, localSetup, term):    
        """
    Generate a GPS Students DataFrame for a given term.
    Combines courses, enrollments, and users data filtered for GPS accounts.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): The SIS term code.
    
    Returns:
        pd.DataFrame: DataFrame containing GPS student details for the specified term.
        """
        methodName = "getGpsStudentsDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}...")
        try:
            # Get courses, enrollments, and users as DataFrames
            coursesDf = cls.getCoursesDf(localSetup, term)
            gpsCourses = coursesDf[
                coursesDf["account_id"].str.contains("G_") &
                (coursesDf["created_by_sis"] == True)
            ]

            enrollmentsDf = cls.getEnrollmentsDf(localSetup, term)
            gpsEnrollments = enrollmentsDf[
                enrollmentsDf["canvas_course_id"].isin(gpsCourses["canvas_course_id"]) &
                (enrollmentsDf["created_by_sis"] == True) &
                (enrollmentsDf["role"] == "student")
            ]

            usersDf = cls.getUsersDf(localSetup)
            gpsUsers = usersDf[
                usersDf["canvas_user_id"].isin(gpsEnrollments["canvas_user_id"].unique())
            ]

            localSetup.logger.info(f"Completed {methodName} for term={term}")
            return gpsUsers
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName} for term={term}: {Error}")
            #raise


    @classmethod
    def getTugStudentsDf(cls, localSetup, term):
        """
    Generate a TUG Students DataFrame for a given term.
    Combines courses, enrollments, and users data filtered for TUG accounts.
    
    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): The SIS term code.
    
    Returns:
        pd.DataFrame: DataFrame containing TUG student details for the specified term.
        """
        methodName = "getTugStudentsDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}...")
        try:
            # Get courses, enrollments, and users as DataFrames
            coursesDf = cls.getCoursesDf(localSetup, term)
            coursesDf["account_id"] = coursesDf["account_id"].fillna("")
            tugCourses = coursesDf[
                ~coursesDf["account_id"].str.contains("G_") &
                (coursesDf["created_by_sis"] == True)
            ]

            enrollmentsDf = cls.getEnrollmentsDf(localSetup, term)
            tugEnrollments = enrollmentsDf[
                enrollmentsDf["canvas_course_id"].isin(tugCourses["canvas_course_id"]) &
                (enrollmentsDf["created_by_sis"] == True) &
                (enrollmentsDf["role"] == "student")
            ]

            usersDf = cls.getUsersDf(localSetup)
            tugUsers = usersDf[
                usersDf["canvas_user_id"].isin(tugEnrollments["canvas_user_id"].unique())
            ]

            localSetup.logger.info(f"Completed {methodName} for term={term}")
            return tugUsers
        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName} for term={term}: {Error}")
            #raise

    @classmethod
    def getActiveOutcomeCoursesDf(cls, localSetup, term, targetDesignator):
        """
    Generate an Excel file of active Canvas courses that are published,
    have student enrollments, and are aligned with outcomes for a given term and designator.
    Includes both undergraduate and graduate terms.

    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        term (str): SIS term code (e.g., "FA25").
        targetDesignator (str): Outcome designator (e.g., "GE", "I-EDUC").

    Returns:
        str: Path to the generated Excel file.
        """
        methodName = "getActiveOutcomeCoursesDf"
        localSetup.logger.info(f"Starting {methodName} for term={term}, targetDesignator={targetDesignator}...")

        try:
            # Determine graduate term
            gradTerm = cls.determineGradTerm(term)

            ## Load outcome tool configuration
            sisResourcePath = localSetup.getExternalResourcePath("SIS")
            outcomeToolConfigPath = os.path.join(sisResourcePath, "Internal Tool Files", "Automated Outcome Tool Variables.xlsx")
            outcomeToolConfigDf = pd.read_excel(outcomeToolConfigPath)

            ## Get the designator row to determine course level
            designatorRow = outcomeToolConfigDf[outcomeToolConfigDf["Target Designator"] == targetDesignator]
            courseLevel = designatorRow.iloc[0]["Course Level"]

            ## Initialize the term variables
            targetTerm = gradTerm if courseLevel == "Graduate" else term ## Use grad term for graduate level designators
            termYear = int(str(localSetup.dateDict['century']) + str(targetTerm[2:]))
            termName = localSetup._determineTermName(targetTerm[:2])

            ## Initialize active course dictionary
            outputFilePath = localSetup.getTargetDesignatedOutputPath(termName, termYear, targetDesignator)
            fileName = f"{targetTerm}_{targetDesignator}_Active_Courses.xlsx"
            targetDestination = os.path.join(outputFilePath, fileName)

            # If file is recent, return it
            if isFileRecent(localSetup, targetDestination):
                localSetup.logger.info(f"{targetDestination} is up to date.")
                return pd.read_excel(targetDestination)

            # Retrieve Canvas data for both terms
            coursesDf = pd.concat([
                cls.getCoursesDf(localSetup, term), 
                cls.getCoursesDf(localSetup, gradTerm)
                ], ignore_index=True)
            sectionsDf = pd.concat([
                cls.getSectionsDf(localSetup, term), 
                cls.getSectionsDf(localSetup, gradTerm)
                ], ignore_index=True)
            enrollmentsDf = pd.concat([
                cls.getEnrollmentsDf(localSetup, term, includeDeleted=True),
                cls.getEnrollmentsDf(localSetup, gradTerm, includeDeleted=True)
                ], ignore_index=True)
            usersDf = cls.getUsersDf(localSetup)

            ## Define the output path for outcome course data
            outputPath = localSetup.getTargetDesignatedOutputPath(termName, termYear, targetDesignator)

            # Build active course dictionary
            activeCourseDict = {
                "Term": [], "Outcome Area": [], "Course_sis_id": [], "Parent_Course_sis_id": [],
                "Section_id": [], "Course_name": [], "Canvas_Account_id": [], "Number_of_students": [],
                "Instructor_#1_ID": [], "Instructor_#1_name": [], "Instructor_#1_email": []
            }

            # Call the internal method to get outcome course DataFrame
            outcomeCourseDf = cls._getOutcomeAssociatedCourseCodesDf(
                localSetup=localSetup,
                outputPath=outputPath,
                inputTerm=term,
                targetDesignator=targetDesignator,
                p1_outcomeToolConfigDf=outcomeToolConfigDf,
            )
            
            if outcomeCourseDf.empty:
                pd.DataFrame().to_excel(outputFilePath, index=False)
                return pd.read_excel(targetDestination)

            ## Identify outcome columns
            outcomeColumns = [col for col in outcomeCourseDf.columns if "Outcome" in col and "Area" not in col]

            ## Initialize active course dictionary with outcome columns
            for outcomeColumn in outcomeColumns:
                activeCourseDict[outcomeColumn] = []

            # Filter and populate courses
            for _, course in coursesDf.iterrows():
                ## The course doesn't have a sis id, wasn't created by sis, doesn't have an underscore in sis id, or is already added
                if (not course.get("course_id") 
                    or course.get("created_by_sis") != True 
                    or "_" not in course["course_id"]
                    or course["course_id"] in activeCourseDict["Course_sis_id"]
                    ):
                    continue ## Skip this course

                ## Make a list to hold crosslisted course sis ids and section ids
                crosslistedCanvasCourseIdList = []  
                crosslistedCanvasSectionIdsList = []

                ## If the course code is in the outcomeCourseDf
                if course["course_id"].split('_')[1] in outcomeCourseDf["Course Code"].values:

                    ## For each row that it appears in in the courseOutcomeAssociationsDf
                    #for index in courseOutcomeAssociationsDf[courseOutcomeAssociationsDf["Course Code"] == row["course_id"].split('_')[1]].index:
                    for index in outcomeCourseDf[outcomeCourseDf["Course Code"] == course["course_id"].split('_')[1]].index:

                        ## Define a primarySectionIndex
                        primarySectionIndex = None
                        ## ## try to get the index where the name column of the sectionsDf contains the course_id
                        try: ## Irregular try clause, do not comment out in testing
                            primarySectionIndex = sectionsDf[
                                sectionsDf["name"].fillna("").str.contains(
                                    course["course_id"]
                                    )
                                ].index[0]
                        except: ## Irregular except clause, do not comment out in testing     
                            ## Grab the section id from the course name in case it is different by splitting the course name by " " and getting the last element
                            try: ## Irregular try clause, do not comment out in testing
                                primarySectionIndex = sectionsDf[
                                    sectionsDf["name"].fillna("").str.contains(
                                        course["long_name"].split(" ")[-1]
                                        )
                                    ].index[0]
                            except: ## Irregular except clause, do not comment out in testing      
                                ## Otherwise log a warning that no section was found
                                localSetup.logger.warning (f"     \nCould not find a section that matched the course sis id or course name for {course['course_id']}.")
                                ## Skip to the next course
                                continue
                            ## If the primarySectionIndex is not None
                            if primarySectionIndex is not None:
                                ## Log a warning that no section was found that matched the course sis id but one was found that matched the course name
                                localSetup.logger.warning (f"     \nFound a section that matched the course name but not the course sis id for {course['course_id']}.")

                        ## Add the course to the active Outcome Courses Dict
                        activeCourseDict["Term"].append(term)
                        activeCourseDict["Outcome Area"].append(targetDesignator)
                        activeCourseDict["Course_sis_id"].append(course["course_id"])
                        activeCourseDict["Course_name"].append(course["long_name"])
                        activeCourseDict["Canvas_Account_id"].append(course["canvas_account_id"])
                        activeCourseDict["Parent_Course_sis_id"].append("")
                        activeCourseDict["Number_of_students"].append(0)
                        activeCourseDict["Instructor_#1_ID"].append("")
                        activeCourseDict["Instructor_#1_name"].append("")
                        activeCourseDict["Instructor_#1_email"].append("")
                   
                        ## Find the sections for this course
                        courseSectionsDf = sectionsDf[sectionsDf["canvas_course_id"] == course["canvas_course_id"]]

                        ## Add the section id that matches the course name to the active Outcome Courses Dict
                        activeCourseDict["Section_id"].append(sectionsDf.loc[primarySectionIndex, "canvas_section_id"])

                        targetCourseSectionsDf = sectionsDf[sectionsDf["canvas_course_id"] == course["canvas_course_id"]]

                        ## If the targetCourseSectionsDf has more than one section
                        if len(targetCourseSectionsDf) > 1:

                            ## For each additional section in the targetCourseSectionsDf
                            for sectionIndex in targetCourseSectionsDf.index:

                                ## If the section name is not the same as the course name
                                if targetCourseSectionsDf.loc[sectionIndex, "name"] != course["long_name"]:

                                    ## Add the crosslisted section and canvas_course id to the crosslistedCanvasSectionIdsList and crosslistedCanvasCourseIdList
                                    crosslistedCanvasSectionIdsList.append(targetCourseSectionsDf.loc[sectionIndex, "canvas_section_id"])
                                    crosslistedCanvasCourseIdList.append(targetCourseSectionsDf.loc[sectionIndex, "canvas_course_id"])
                                
                        ## For each outcome column in the outcomeCourseDf
                        for outcomeColumn in outcomeColumns:
                                    
                            ## Add the outcome to the active Outcome Courses Dict
                            activeCourseDict[outcomeColumn].append(outcomeCourseDf.loc[index, outcomeColumn])                                

                ## If there are crosslisted courses
                if crosslistedCanvasSectionIdsList:

                    ## For each crosslisted course sis id and crosslisted course section id
                    for crosslistedCanvasSectionId, crosslistedCanvasCourseId in zip(crosslistedCanvasSectionIdsList, crosslistedCanvasCourseIdList):

                        ## Get the index of the crosslistedCanvasCourseId in from the canvasAllCoursesDf
                        crosslistedSectionIndex = sectionsDf[sectionsDf["canvas_section_id"] == crosslistedCanvasSectionId].index[0]

                        ## Get the long name of the crosslistedCanvasCourseId
                        crosslistedCourseName = sectionsDf.loc[crosslistedSectionIndex, "name"]

                        ## Define variables to hold the course code and sis id
                        crosslistedCourseCode = None
                        crosslistedCourseSisId = None

                        ## Attempt to isolate the crosslisted course Code as it would show up in the outcomeCourseDf
                        try: ## Irregular try clause, do not comment out in testing
                                        
                            ## Isolate the course by getting the last element after spliting by " " and removing the "I_" if it is an independent study course
                            crosslistedCourseCode = (
                                crosslistedCourseName.replace('I_', '_').split('_')[1]
                                if "IS:" in crosslistedCourseName 
                                else crosslistedCourseName.split('_')[1]
                                )

                            ## Isolate the crosslisted course Sis Id by getting the last element after spliting by " "
                            crosslistedCourseSisId = crosslistedCourseName.split(' ')[-1]

                        ## If there is an error, the section was not an official course section
                        except: ## Irregular except clause, do not comment out in testing

                            ## Skip the course
                            continue

                        ## If the crosslisted course sis id appears in the outcomeCourseDf
                        if crosslistedCourseCode in outcomeCourseDf["Course Code"].values:

                            ## For each course that appears in in the outcomeCourseDf
                            for crosslistedIndex in outcomeCourseDf[outcomeCourseDf["Course Code"] == crosslistedCourseCode].index:

                                ## Add the course to the active Outcome Courses Dict
                                activeCourseDict["Term"].append(term)
                                activeCourseDict["Outcome Area"].append(outcomeCourseDf.loc[crosslistedIndex, "Outcome Area"])
                                activeCourseDict["Course_sis_id"].append(crosslistedCourseSisId)
                                activeCourseDict["Course_name"].append(crosslistedCourseName)
                                activeCourseDict["Canvas_Account_id"].append(course["canvas_account_id"])
                                activeCourseDict["Number_of_students"].append(0)
                                activeCourseDict["Instructor_#1_ID"].append("")
                                activeCourseDict["Instructor_#1_name"].append("")
                                activeCourseDict["Instructor_#1_email"].append("")
                                                
                                ## For each outcome column in the outcomeCourseDf
                                for outcomeColumn in outcomeColumns:
                                                    
                                    ## Add the outcome to the active Outcome Courses Dict
                                    activeCourseDict[outcomeColumn].append(outcomeCourseDf.loc[crosslistedIndex, outcomeColumn])

                                ## Add the parent course sis id to the active Outcome Courses Dict
                                activeCourseDict["Parent_Course_sis_id"].append(course["course_id"])
                                                
                                ## Get the index of the crosslisted course id in the crosslistedCourseNamesList
                                crosslistedCanvasCourseIdIndex = crosslistedCanvasCourseIdList.index(crosslistedCanvasCourseId)

                                ## Add the section id that matches the crosslisted course name + 1 to the active Outcome Courses Dict
                                activeCourseDict["Section_id"].append(crosslistedCanvasSectionIdsList[crosslistedCanvasCourseIdIndex])

            # Enrich with enrollments
            for _, row in enrollmentsDf.iterrows():
                if row["status"] not in ["active", "concluded"]:
                    continue
                if row["canvas_course_id"] not in coursesDf["canvas_course_id"].values:
                    continue
                targetIndex = activeCourseDict["Course_sis_id"].index(row["course_id"]) if row["course_id"] in activeCourseDict["Course_sis_id"] else None
                if targetIndex is None:
                    continue
                if row["base_role_type"] == "StudentEnrollment":
                    activeCourseDict["Number_of_students"][targetIndex] += 1
                elif (row["base_role_type"] == "TeacherEnrollment" 
                      and row["user_id"] not in ["63232.0", "63232"]
                      ):
                    if activeCourseDict["Instructor_#1_ID"][targetIndex] == "":
                        activeCourseDict["Instructor_#1_ID"][targetIndex] = row["user_id"]
                    else:
                        ## Make a variable to hold the key name that the instructor's id will be added to
                        targetInstructorIDKey = None
                                    
                        ## Make a list of the keys that have instructor and id in them
                        instructorIDKeys = [key for key in activeCourseDict.keys() if "Instructor" in key and "ID" in key]
                                    
                        ## Make a list of the processed instructor ids using the instructorIDKeys
                        processedInstructorIds = [activeCourseDict[key][targetIndex] for key in instructorIDKeys if activeCourseDict[key][targetIndex]]

                        ## If the user id is already in the processed instructor ids
                        if row["user_id"] in processedInstructorIds:
                                        
                            ## Skip it
                            continue
                                    
                        ## For each key in the instructorIDKeys
                        for key in instructorIDKeys:
                                        
                            ## If the key is not the first instructor id key
                            if key != "Instructor_#1_ID":
                                            
                                ## If the key's value at the index is empty
                                if activeCourseDict[key][targetIndex] == "":
                                                
                                    ## Set the targetInstructorIDKey to the key
                                    targetInstructorIDKey = key
                                    break

                        ## If there still is no targetInstructorIDKey
                        if not targetInstructorIDKey:
                                        
                            ## Create new instructor id, name, and email keys using the length of the instructorIDKeys alist +1
                            newInstructorIDKey = f"Instructor_#{len(instructorIDKeys) + 1}_ID"
                            newInstructorNameKey = f"Instructor_#{len(instructorIDKeys) + 1}_name"
                            newInstructorEmailKey = f"Instructor_#{len(instructorIDKeys) + 1}_email"
                                        
                            ## Add the new instructor id key to the instructorIDKeys list
                            instructorIDKeys.append(newInstructorIDKey)
                                        
                            ## Add the new keys to the activeCourseDict
                            activeCourseDict[newInstructorIDKey] = []
                            activeCourseDict[newInstructorNameKey] = []
                            activeCourseDict[newInstructorEmailKey] = []
                                        
                            ## For for the length of the Instructor_#1_ID list
                            for i in range(len(activeCourseDict["Instructor_#1_ID"])):
                                                
                                ## Add a blank value to the new lists so they are the same length as the Instructor_#1_ID list
                                activeCourseDict[newInstructorIDKey].append("")
                                activeCourseDict[newInstructorNameKey].append("")
                                activeCourseDict[newInstructorEmailKey].append("")
                                        
                            ## Set the targetInstructorIDColumn to the newInstructorIDColumn
                            targetInstructorIDColumn = newInstructorIDKey

                        ## Set the instructor's id to the targetInstructorIDColumn at the courseIndex
                        activeCourseDict[targetInstructorIDColumn][targetIndex] = row["user_id"]

            ## Keep only active courses with students
            indicesToRemove = [i for i, count in enumerate(activeCourseDict["Number_of_students"]) if count == 0]
            for key in activeCourseDict:
                activeCourseDict[key] = [v for i, v in enumerate(activeCourseDict[key]) if i not in indicesToRemove]

            ## Create a blank userMap dict
            userMap = {}

            # Enrich instructor details
            # Create a user map preferring rows where created_by_sis == True, then rows with an email, then fallback.
            if not usersDf.empty:
                tempUsersDf = usersDf.copy()
                # Build a numeric priority: created_by_sis (2) + has_email (1)
                tempUsersDf["_priority"] = tempUsersDf["created_by_sis"].fillna(False).astype(bool).astype(int) * 2 + tempUsersDf["email"].notna().astype(int)

                # Ensure deterministic ordering: higher priority first, then keep first occurrence per user_id
                tempUsersDf = tempUsersDf.sort_values(by=["user_id", "_priority"], ascending=[True, False])
                unduplicatedTempUsersDf = tempUsersDf.drop_duplicates(subset="user_id", keep="first")
                userMap = unduplicatedTempUsersDf.set_index("user_id")[["full_name", "email"]].to_dict("index")
            else:
                userMap = {}

            ## Make a list of the instructor id keys
            instructorIDKeys = [key for key in activeCourseDict.keys() if "Instructor" in key and "ID" in key]

            ## For each key in the instructorIDKeys
            for key in instructorIDKeys:
                
                ## For each user value in the key
                for user_id in activeCourseDict[key]:
                    ## Convert the user id to str
                    user_id = str(user_id)
                    
                    ## If the user id is not empty
                    if user_id:
                    
                        ## Make a list of all of the indexes where the user id appears in the key
                        userIndexes = [i for i, x in enumerate(activeCourseDict[key]) if x == user_id]

                        ## For each index in the userIndexes list
                        for userIndex in userIndexes:
                    
                            ## Replace the empty name and email values with the user's name and email
                            activeCourseDict[key.replace("ID", "name")][userIndex] = userMap[user_id]["full_name"]
                            activeCourseDict[key.replace("ID", "email")][userIndex] = userMap[user_id]["email"]

            
            # ## For each outcome column, append the value from outcomeCourseDf
            # for outcomeColumn in outcomeColumns:
            #     ## Ensure the course exists in outcomeCourseDf before accessing
            #     if courseCode in outcomeCourseDf["Course Code"].values:
            #         rowIndex = outcomeCourseDf[outcomeCourseDf["Course Code"] == courseCode].index[0]
            #         activeCourseDict[outcomeColumn].append(outcomeCourseDf.loc[rowIndex, outcomeColumn])
            #     else:
            #         activeCourseDict[outcomeColumn].append("")  # Blank if not found


            # Save to Excel, replacing all instances of \u200b with ""
            activeCourseDf = pd.DataFrame(activeCourseDict)
            activeCourseDf.replace("\u200b", "", regex=True, inplace=True)
            activeCourseDf.to_excel(targetDestination, index=False)
            localSetup.logger.info(f"Successfully created {fileName}")
            return activeCourseDf

        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName}: {Error}")
            #raise

    @classmethod
    def determineDepartmentSavePath(cls, localSetup, courseAccountId):
        """
    Determine the save path for a given Canvas account ID by traversing the account hierarchy.

    Args:
        localSetup (LocalSetup): The LocalSetup instance for logging and path management.
        courseAccountId (int): The Canvas account ID.

    Returns:
        str: The constructed department save path.
        """
        methodName = "determineDepartmentSavePath"

        try:
            # If root account
            if courseAccountId == 1:
                return "NNU\\"

            # Read the accounts CSV into a DataFrame
            departmentSavePathsDF = cls.getAccountsDf(localSetup)

            # Determine which column to use for matching
            targetRow = "account_id"
            if courseAccountId not in departmentSavePathsDF[targetRow].tolist():
                targetRow = "canvas_account_id"

            # Locate the row for the given account ID
            accountRow = departmentSavePathsDF.index.get_loc(
                departmentSavePathsDF[departmentSavePathsDF[targetRow] == courseAccountId].index[0]
            )

            # Start building the path with the account name
            accountName = departmentSavePathsDF["name"][accountRow]
            accountSavePath = f"{accountName}\\"

            # Traverse parent accounts until root
            targetAccountParentID = departmentSavePathsDF["canvas_parent_id"][accountRow]
            while pd.notna(targetAccountParentID) and targetAccountParentID != 1:
                parentAccountRow = departmentSavePathsDF.index.get_loc(
                    departmentSavePathsDF[departmentSavePathsDF["canvas_account_id"] == targetAccountParentID].index[0]
                )
                targetAccountName = departmentSavePathsDF["name"][parentAccountRow]
                accountSavePath = f"{targetAccountName}\\{accountSavePath}"
                targetAccountParentID = departmentSavePathsDF["canvas_parent_id"][parentAccountRow]

            # Clean up path formatting for department/college names
            if len(accountSavePath.rsplit("\\")) > 3:
                departmentName = accountSavePath.rsplit("\\")[1]
                accountSavePath = accountSavePath.replace(f" {departmentName}", "").replace(
                    "College of Arts &\\", "College of Arts & Humanities\\"
                )
            else:
                collegeName = accountSavePath.rsplit("\\")[0].replace("College of ", "")
                accountSavePath = accountSavePath.replace(f"Undergraduate {collegeName}", "Undergraduate").replace(
                    f"Graduate {collegeName}", "Graduate"
                )

            # Handle underscores in names
            if "_" in accountSavePath and "Undergraduate_" not in accountSavePath and "Graduate_" not in accountSavePath:
                if "Graduate " in accountSavePath:
                    stringWithUnderscore = accountSavePath.split("Graduate ")[1].split("_")[0]
                else:
                    stringWithUnderscore = accountSavePath.split("Undergraduate ")[1].split("_")[0]

                accountSavePath = (
                    accountSavePath.replace(f"Undergraduate {stringWithUnderscore}_", "Undergraduate_")
                    .replace(f"Graduate {stringWithUnderscore}_", "Graduate_")
                    .replace(f"{stringWithUnderscore}_", "")
                )

            return accountSavePath

        except Exception as Error:
            localSetup.logger.error(f"Error in {methodName}: {Error}")
            #raise



    @staticmethod
    def determineGradTerm(term):
        """
        Determine the graduate term equivalent for a given undergraduate term.
        Example: FA25 -> GF25, SP25 -> GP25, SU25 -> GU25
        """
        # Extract the prefix (first two characters)
        prefix = term[:2].upper()
        termName = undgTermsCodesToWordsDict.get(prefix, "")
        gradPrefix = gradTermsWordsToCodesDict[termName] if termName in gradTermsWordsToCodesDict else ""
        return term.replace(prefix, gradPrefix) if gradPrefix else term

    ## Retrieve the outcome course code list from SharePoint and return as a DataFrame.
    @staticmethod
    def _getOutcomeAssociatedCourseCodesDf(localSetup, outputPath, inputTerm, targetDesignator, p1_outcomeToolConfigDf):
        """
    Retrieve the outcome course code list from SharePoint and return as a DataFrame.
    Saves a cleaned Excel file locally for reuse.

    Args:
        outputPath (str): Path for term and target-specific output.
        inputTerm (str): SIS term code (e.g., "FA25").
        targetDesignator (str): Outcome designator (e.g., "GE", "I-EDUC").
        p1_outcomeToolConfigDf (pd.DataFrame): DataFrame containing outcome tool configuration.
        localSetup.logger (Logger): Logger instance for logging.

    Returns:
        pd.DataFrame: DataFrame containing outcome course associations.
        """
        try:
            # Define expected filenames and paths
            outcomeFileName = f"{inputTerm}_{targetDesignator}_Active_Course_Outcome_Associations.xlsx"
            rawOutputFileName = f"{inputTerm}_Raw_{targetDesignator}_Active_Course_Outcome_Associations.xlsx"
            outputFilePath = os.path.join(outputPath, outcomeFileName)
            rawOutputFilePath = os.path.join(outputPath, rawOutputFileName)

            # If file exists and is recent, return it
            if isFileRecent(localSetup, filePath=outputFilePath):
                    localSetup.logger.info(f"Outcome file {outcomeFileName} is up to date.")
                    return pd.read_excel(outputFilePath)

            # Retrieve SharePoint URL and sheet name for target designator
            shareUrl = p1_outcomeToolConfigDf.loc[p1_outcomeToolConfigDf["Target Designator"] == targetDesignator,
                                               "Outcome Course Association List URL"].values[0]
            sheetName = p1_outcomeToolConfigDf.loc[p1_outcomeToolConfigDf["Target Designator"] == targetDesignator,
                                                "Outcome Course Association Target Sheet Name"].values[0]

            # Download file from SharePoint
            downloadedFilePath = downloadSharedMicrosoftFile(
                p1_microsoftUserName=serviceEmailAccount,
                p1_microsoftShareUrl=shareUrl,
                p1_downloadSavePath=outputPath,
                p1_fileName=rawOutputFileName
            )

            if not rawOutputFilePath or not os.path.exists(rawOutputFilePath):
                localSetup.logger.error(f"Outcome file not found: {rawOutputFilePath}")
                return None

            # Choose engine based on extension
            fileExt = os.path.splitext(rawOutputFilePath)[1].lower()
            pdEngine = "xlrd" if fileExt == ".xls" else "openpyxl"

            # Load Excel file
            if not zipfile.is_zipfile(rawOutputFilePath):
                localSetup.logger.warning(f"Downloaded file is not a valid Excel file. Attempting repair...")
                # Try reading as CSV and resave as proper Excel
                try:
                    fileDataframe = pd.read_csv(rawOutputFilePath)
                    with pd.ExcelWriter(rawOutputFilePath, engine="openpyxl") as writer:
                        fileDataframe.to_excel(writer, index=False)
                    localSetup.logger.info(f"File repaired")
                except Exception as e:
                    localSetup.logger.error(f"Repair failed: {e}")
                    raise
            excelFile = pd.ExcelFile(rawOutputFilePath, engine=pdEngine)
            rawoutcomeCourseDf = None
            if sheetName and sheetName in excelFile.sheet_names:
                rawoutcomeCourseDf = pd.read_excel(excelFile, sheet_name=sheetName, engine=pdEngine)
            elif "By Course" in excelFile.sheet_names:
                rawoutcomeCourseDf = pd.read_excel(excelFile, sheet_name="By Course", engine=pdEngine)
            else:
                rawoutcomeCourseDf = pd.read_excel(excelFile, engine=pdEngine)

            # Normalize column names
            outcomeCourseDf = rawoutcomeCourseDf.copy()
            outcomeCourseDf.columns = [str(col).strip().lower() for col in outcomeCourseDf.columns]
            if "course number" in outcomeCourseDf.columns:
                outcomeCourseDf.rename(columns={"course number": "number"}, inplace=True)
            outcomeCourseDf.columns = [col.title() for col in outcomeCourseDf.columns]

            # Fix header if needed
            if outcomeCourseDf.columns[0].lower() != "prefix":
                outcomeCourseDf.columns = outcomeCourseDf.iloc[0].astype(str).str.strip().tolist()
                outcomeCourseDf = outcomeCourseDf[1:].reset_index(drop=True)

            # Add outcome area and clean course codes
            outcomeCourseDf["Outcome Area"] = targetDesignator
            if targetDesignator != "GE" and outcomeCourseDf["Prefix"].str.contains(targetDesignator).any():
                outcomeCourseDf["Prefix"] = outcomeCourseDf["Prefix"].str[2:]

            # Clean numeric columns
            for column in outcomeCourseDf.columns:
                if any(keyword in column.lower() for keyword in ["number", "course code", "course number"]):
                    outcomeCourseDf[column] = outcomeCourseDf[column].astype(str).str.replace(r'\.(0\d)$', '', regex=True)

            # Drop rows missing required values
            outcomeColumns = [col for col in outcomeCourseDf.columns if "Outcome" in col and "Area" not in col]
            outcomeCourseDf.dropna(subset=["Prefix", "Number", outcomeColumns[0]], inplace=True)

            # Add Course Code column
            outcomeCourseDf.insert(1, "Course Code", outcomeCourseDf["Prefix"] + outcomeCourseDf["Number"].astype(str))

            ## Drop Prefix and Number columns
            outcomeCourseDf.drop(columns=["Prefix", "Number"], inplace=True)

            ## Clean any .0 from Course Code
            outcomeCourseDf["Course Code"] = outcomeCourseDf["Course Code"].str.replace(r'\.0$', '', regex=True)

            # Save cleaned file
            outcomeCourseDf.to_excel(outputFilePath, index=False)
            return outcomeCourseDf

        except Exception as Error:
            localSetup.logger.error(f"Error in _getOutcomeAssociatedCourseCodesDf: {Error}")
            return pd.dataframe()


if __name__ == "__main__":


    # Initialize LocalSetup
    localSetup = LocalSetup(datetime.now(), __file__)

    while True:
        print("\nCanvas Report Menu")
        print("1. Accounts")
        print("2. Terms")
        print("3. Users")
        print("4. Last User Access")
        print("5. Enrollments")
        print("6. Courses")
        print("7. Sections")
        print("8. Outcomes")
        print("9. Outcome Results")
        print("10. Unpublished Courses")
        print("11. GPS Students")
        print("12. TUG Students")
        print("13. Active Outcome Courses")
        print("14. Run All Reports")
        print("0. Exit")

        choice = input("\nEnter the number of the report to run (or '0' to exit): ").strip()

        if choice == '0':
            print("Exiting Canvas Report Menu.")
            break

        if choice not in [str(i) for i in range(1, 15)]:
            print("Invalid selection. Please enter a number between 1 and 14, or 0 to exit.")
            continue

        # Prompt for term if needed
        term = None
        if choice in ['5', '6', '7', '8', '9', '10', '11', '12', '13', '14']:
            term_input = input("Enter the term code (e.g., 'FA25', 'GF25') or 'All': ").strip()
            term = term_input

        # Prompt for account if needed
        account = None
        if choice in ['8', '9']:
            account = input("Enter the account name (e.g., 'College of Arts'): ").strip()

        # Prompt for target designator if Active Outcome Courses
        targetDesignator = None
        if choice == '13':
            targetDesignator = input("Enter the target designator (e.g., 'GE', 'I-EDUC'): ").strip()

        try:
            if choice == '1':
                print(CanvasReport.getAccountsDf(localSetup))
            elif choice == '2':
                print(CanvasReport.getTermsDf(localSetup))
            elif choice == '3':
                print(CanvasReport.getUsersDf(localSetup))
            elif choice == '4':
                print(CanvasReport.getCanvasUserLastAccessDf(localSetup))
            elif choice == '5':
                print(CanvasReport.getEnrollmentsDf(localSetup, term))
            elif choice == '6':
                print(CanvasReport.getCoursesDf(localSetup, term))
            elif choice == '7':
                print(CanvasReport.getSectionsDf(localSetup, term))
            elif choice == '8':
                print(CanvasReport.getOutcomesDf(localSetup, term, account))
            elif choice == '9':
                print(CanvasReport.getOutcomeResultsDf(localSetup, term, account))
            elif choice == '10':
                print(CanvasReport.getUnpublishedCoursesDf(localSetup, term))
            elif choice == '11':
                print(CanvasReport.getGpsStudentsDf(localSetup, term))
            elif choice == '12':
                print(CanvasReport.getTugStudentsDf(localSetup, term))
            elif choice == '13':
                print(CanvasReport.getActiveOutcomeCoursesDf(localSetup, term, targetDesignator))
            elif choice == '14':
                # Run standard reports
                print(CanvasReport.getAccountsDf(localSetup))
                print(CanvasReport.getTermsDf(localSetup))
                print(CanvasReport.getUsersDf(localSetup))
                print(CanvasReport.getCanvasUserLastAccessDf(localSetup))
                print(CanvasReport.getEnrollmentsDf(localSetup, term))
                print(CanvasReport.getCoursesDf(localSetup, term))
                print(CanvasReport.getSectionsDf(localSetup, term))
                print(CanvasReport.getUnpublishedCoursesDf(localSetup, term))
                print(CanvasReport.getGpsStudentsDf(localSetup, term))
                print(CanvasReport.getTugStudentsDf(localSetup, term))

                # Retrieve outcomeToolConfigDf to get all target designators
                sisResourcePath = localSetup.getExternalResourcePath("SIS")
                outcomeToolConfigPath = os.path.join(sisResourcePath, "Internal Tool Files", "Automated Outcome Tool Variables.xlsx")
                outcomeToolConfigDf = pd.read_excel(outcomeToolConfigPath)

                # Get all target designators
                targetDesignators = outcomeToolConfigDf["Target Designator"].dropna().unique()

                # Run reports for each target designator
                for designator in targetDesignators:
                    print(f"\nRunning reports for Target Designator: {designator}")
                    print(CanvasReport.getOutcomesDf(localSetup, term, designator))
                    print(CanvasReport.getOutcomeResultsDf(localSetup, term, designator))
                    print(CanvasReport.getActiveOutcomeCoursesDf(localSetup, term, designator))

        except Exception as Error:
            print(f"An error occurred: {Error}")

## ===========================================================================
## FILE: ResourceModules\Core_Microsoft_Api.py
## ===========================================================================

## Define the encoding
## -*- coding: utf-8 -*-

##Author: Bryce Miller - brycezmiller@nnu.edu
##Last Updated by: Bryce Miller. On: 2/9/2024

## General Imports
import os, sys, base64, sys, asyncio, configparser, getpass, requests, mimetypes, re
from datetime import datetime
from cryptography.fernet import Fernet


## Microsoft Imports
from azure.identity import AuthenticationRecord
from azure.identity import TokenCachePersistenceOptions
from msgraph import GraphServiceClient
from configparser import SectionProxy
from azure.identity import InteractiveBrowserCredential
from msgraph.generated.users.users_request_builder import UsersRequestBuilder
from msgraph.generated.shares.item.drive_item.drive_item_request_builder import DriveItemRequestBuilder
from msgraph.generated.users.item.mail_folders.item.messages.messages_request_builder import (
    MessagesRequestBuilder)
from msgraph.generated.users.item.send_mail.send_mail_post_request_body import (
    SendMailPostRequestBody)
from msgraph.generated.models.message import Message
from msgraph.generated.models.item_body import ItemBody
from msgraph.generated.models.body_type import BodyType
from msgraph.generated.models.file import File
from msgraph.generated.models.recipient import Recipient
from msgraph.generated.models.email_address import EmailAddress
from msgraph.generated.models.drive_item import DriveItem
from kiota_abstractions.base_request_configuration import RequestConfiguration
from msgraph.generated.models.drive_item_uploadable_properties import DriveItemUploadableProperties
from msgraph.generated.drives.item.items.item.create_upload_session.create_upload_session_request_builder import CreateUploadSessionRequestBuilder
from msgraph.generated.drives.item.items.item.create_upload_session.create_upload_session_post_request_body import CreateUploadSessionPostRequestBody
from msgraph.generated.drives.item.items.item.workbook.functions.large.large_request_builder import LargeRequestBuilder

## Adjust system path to include ResourceModules
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "ResourceModules"))

try: ## If the module is run directly
    from TLC_Common import (downloadFile, getEncryptionKey)
    from Local_Setup import LocalSetup
except ImportError: ## Otherwise as a relative import if the module is imported
    from .TLC_Common import (downloadFile, getEncryptionKey)
    from .Local_Setup import LocalSetup

## import Config Variables
from Common_Configs import serviceEmailAccount

## Define the script name, purpose, and external requirements for logging and error reporting purposes
__scriptName = os.path.basename(__file__).replace(".py", "")
scriptPurpose = r"""
This class contains the base methods and variables to send emails with the Outlook API
"""
externalRequirements = r"""
Access to an appropriet "Credentials.json" file. See https://developers.google.com/outlook/api/auth/web-server \
for further details on the outlook api authorization requirements.
"""


class CoreMicrosoftAPI:
    settings: SectionProxy
    device_code_credential = None
    userClient: GraphServiceClient
    storedGraphConfig = None
    storedMicrosoftUsername = None

    def __init__(self, localSetup, graphConfigType, microsoftUserName):
        self.localSetup = localSetup
        self.storedGraphConfig = graphConfigType
        self.storedMicrosoftUsername = microsoftUserName

        ## Paths and localSetup.logger from LocalSetup
        configPath = self.localSetup.configPath
        microsoftResourcePath = self.localSetup.getInternalResourcePaths("Microsoft")
        logger = self.localSetup.logger

        ## Determine config file name
        if graphConfigType.lower() == 'outlook':
            configFileName = "Outlook_API_Config"
        elif graphConfigType.lower() == 'onedrive':
            configFileName = "OneDrive_and_Sharepoint_API_Config"
        else:
            raise ValueError("Invalid graphConfigType. Must be 'Outlook' or 'OneDrive'.")

        ## Load config settings
        config = configparser.ConfigParser()
        config.read([os.path.join(configPath, f"{configFileName}.cfg"), 'config.dev.cfg'])
        self.settings = config['azure']

        client_id = self.settings['clientId']
        tenant_id = self.settings['tenantId']
        graph_scopes = self.settings['graphUserScopes'].split(' ')

        ## Encryption key
        encryptionKey = getEncryptionKey(self.localSetup)
        fernet = Fernet(encryptionKey)

        ## Authentication logic using microsoftResourcePath
        pythonUser = getpass.getuser()
        credentialFile = os.path.join(microsoftResourcePath,
                                      f"{pythonUser}_Owned_{configFileName}_Authenticated_{microsoftUserName}_Credential.json")

        if os.path.exists(credentialFile):
            with open(credentialFile, "r") as json_file:
                encryptedContent = json_file.read()
                decryptedContent = fernet.decrypt(encryptedContent.encode()).decode()
                deserialized_record = AuthenticationRecord.deserialize(decryptedContent)
                self.device_code_credential = InteractiveBrowserCredential(
                    cache_persistence_options=TokenCachePersistenceOptions(),
                    authentication_record=deserialized_record
                )
                self.device_code_credential.authenticate(scopes=graph_scopes)
        else:
            self.device_code_credential = InteractiveBrowserCredential(
                client_id=client_id,
                tenant_id=tenant_id,
                cache_persistence_options=TokenCachePersistenceOptions()
            )
            authenticatedDeviceCodeCredential = self.device_code_credential.authenticate(scopes=graph_scopes)
            encryptedData = fernet.encrypt(authenticatedDeviceCodeCredential.serialize().encode())
            with open(credentialFile, "w") as json_file:
                json_file.write(encryptedData.decode())
                
        self.userClient = GraphServiceClient(self.device_code_credential, graph_scopes)

    ## This function sends an email asynchroniously with the option of using a shared mailbox 
    async def send_mail_async(self, subject: str, body: str, recipientEmailList: list, shared_mailbox: str = None, attempt = 1):
        
        ## Create the message
        message = Message()
        
        ## Set the message subject and create the message body
        message.subject = subject
        message.body = ItemBody()

        ## Set the message body type and content
        message.body.content_type = BodyType.Html if "!DOCTYPE html" in body else BodyType.Text
        message.body.content = body

        ## Create a list of intended recipients
        message.to_recipients = []

        ## The code takes email addresses as a single string with email addresses seperated by commas
        ## so split the email addresses into a list and remove any spaces
        recipientEmailList = [email.strip() for email in recipientEmailList.split(',')]
        
        ## For each recipient
        for recipientEmail in recipientEmailList:

            ## Create a recipient object
            intendedRecipient = Recipient()
        
            ## Create an email address object and set it to the recipient's email
            intendedRecipient.email_address = EmailAddress()
            intendedRecipient.email_address.address = recipientEmail
            
            ## Add the recipient to the list of recipients
            message.to_recipients.append(intendedRecipient)

        ## If a shared mailbox was given
        if shared_mailbox:
            
            ## Create a recipient object to act as a sender object and set the email address to the shared mailbox
            from_sender = Recipient(email_address=EmailAddress(address=shared_mailbox))
            message.from_ = from_sender

        ## Create the request body which contains the subject, body, and recipients
        request_body = SendMailPostRequestBody(message=message)
        
        ## Send the email
        await self.userClient.me.send_mail.post(request_body)

    ## This function downloads a microsoft file asynchroniously using a shared link
    async def downloadSharedMicrosoftFileAsync(self, localSetup, fileShareUrl, downloadSavePath, fileName, attempt = 1):

        ## Change the url to base64
        base64FileShareUrl = base64.urlsafe_b64encode(fileShareUrl.encode('utf-8')).decode('utf-8').rstrip('=').replace('/', '_').replace('+', '-')

        ## Change the base64 url to an encoded url
        encodedFileShareUrl = f"u!{base64FileShareUrl}"

        ## Define a variable to hold the api call result
        fileResult = await self.userClient.shares.by_shared_drive_item_id(encodedFileShareUrl).drive_item.get()
        
        ## Save the file download path
        fileDownloadUrl = fileResult.additional_data['@microsoft.graph.downloadUrl']
        
        ## If a file name was not given
        if not fileName:
            fileName = fileResult.name
            
        ## Otherwise, if a file name was given
        else:
            
            ## If the file name does not have the same extension as the file
            if not fileName.endswith(fileResult.name.split('.')[-1]):

                ## Add the correct file extension to the file name
                fileName = f"{fileName}.{fileResult.name.split('.')[-1]}"
            
        ## Make the download save location an absolute path
        absoluteDownloadSavePath = os.path.abspath(downloadSavePath)

        ## Download the file
        downloadFile(localSetup, fileDownloadUrl, f"{absoluteDownloadSavePath}\\{fileName}", "w")
        
        return os.path.abspath(f"{absoluteDownloadSavePath}\\{fileName}")

    ## This function finds takes an encoded file share url and file name and returns whether the url is a folder and the relavent drive id and drive item id if they exist
    async def findSharedMicrosoftFileAsync(self, p1_encodedFileShareUrl, fileName):

        ## Define variables to contain whether the target url is a folder and any relevant drive ids and drive item ids
        targetUrlIsAFolder = False
        targetUrlDriveItemId = None
        targetUrlDriveId = None
        targetFileDriveItemID = None
        targetFileDriveID = None

        ## Define a variable to hold the api call result
        requestResult = await self.userClient.shares.by_shared_drive_item_id(p1_encodedFileShareUrl).drive_item.get()

        ## Record the target url's drive id and drive item id
        targetUrlDriveItemId = requestResult.id
        targetUrlDriveId = requestResult.parent_reference.drive_id

        ## If the name of the target equals the file name
        if requestResult.name == fileName:

            ## Record the drive id and drive item id
            targetFileDriveItemID = requestResult.id
            targetFileDriveID = requestResult.parent_reference.drive_id


        ## Otherwise
        else:
            
            ## If the target is a folder
            if requestResult.folder:

                ## Set the target url is a folder to true
                targetUrlIsAFolder = True

                ## Search for the file in the folder
                searchResult = await self.userClient.drives.by_drive_id(requestResult.parent_reference.drive_id).items.by_drive_item_id(requestResult.id).search_with_q(fileName).get()
                
                ## If there are results
                if searchResult.value:

                    ## For each result
                    for result in searchResult.value:

                        ## If the result name equals the file name and no drive id has been found
                        if result.name == fileName and not targetFileDriveID:

                            ## Record the drive id and drive item id
                            targetFileDriveItemID = result.id
                            targetFileDriveID = result.parent_reference.drive_id

        ## Return target variables
        return targetUrlIsAFolder, targetUrlDriveItemId, targetUrlDriveId, targetFileDriveItemID, targetFileDriveID                    
    
    ## This function uploads a new microsoft file or updates an existing one
    async def uploadSharedMicrosoftFileAsync(self, targetShareUrl, uploadItemFilePath):

        ## Get the name from the file path and mime type
        fileBaseName = os.path.basename(uploadItemFilePath)
        test = os.path.splitext(uploadItemFilePath)[1]
        fileMimeType = mimetypes.guess_type(test)

        ## Make a drive item object with the file name
        ##uploadItem = DriveItem(name = fileBaseName, file = File(mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"))
        uploadItem = DriveItem(name = fileBaseName, file = File())

        ## Change the url to base64
        base64TargetShareUrl = base64.urlsafe_b64encode(targetShareUrl.encode('utf-8')).decode('utf-8').rstrip('=').replace('/', '_').replace('+', '-')
        
        ## Change the base64 url to an encoded url
        encodedTargetShareUrl = f"u!{base64TargetShareUrl}"
        
        ## Determine if the URL is a folder or a file
        targetUrlIsAFolder, targetUrlDriveItemId, targetUrlDriveId, targetFileDriveItemId, targetFileDriveId = await self\
            .findSharedMicrosoftFileAsync(encodedTargetShareUrl, fileBaseName)

        ## Prepare upload body
        uploadBody = CreateUploadSessionPostRequestBody.create_from_discriminator_value(uploadItem)
        uploadBody.item = DriveItemUploadableProperties(additional_data={'@microsoft.graph.conflictBehavior': 'replace'})

        ## Create the blank variable for uploadSessionBuilder
        uploadSessionBuilder = None

        ## Decide how to upload
        if targetFileDriveId and targetFileDriveItemId:
            ## URL is a file or file exists in folder ? update it
            self.localSetup.logger.info(f"Updating existing file: {fileBaseName}")
            uploadSessionBuilder = self.userClient.drives.by_drive_id(targetFileDriveId).items.by_drive_item_id(targetFileDriveItemId).create_upload_session
        elif targetUrlIsAFolder:
            ## URL is a folder and file doesn't exist ? create it
            self.localSetup.logger.info(f"Creating new file: {fileBaseName}")
            createNewDriveItemResult = await self.userClient.drives.by_drive_id(targetUrlDriveId).items.by_drive_item_id(targetUrlDriveItemId).children.post(uploadItem)
            uploadSessionBuilder = self.userClient.drives.by_drive_id(targetUrlDriveId).items.by_drive_item_id(createNewDriveItemResult.id).create_upload_session

        else:
            ## URL is a file but doesn't match the target file name ? fallback
            raise ValueError("Unable to determine target location for upload.")
            
                                
        ## Create the upload session
        uploadSession = await uploadSessionBuilder.post(uploadBody)

        ## Get the upload url
        uploadURL = uploadSession.upload_url

        ## Open the file
        with open (uploadItemFilePath, 'rb') as fileContent:

            ## Get the byte size of the file
            fileByteSize = os.path.getsize(uploadItemFilePath)
            
            ## Define the max chunk size for file uploads
            maxChunkSize = 320 * 1024
                            
            ## Count the number of complete chunks that will be needed to upload the file
            numberOfFileChunks = fileByteSize // maxChunkSize

            ## Calculate the amount left over after the chunks are uploaded in max chunk sizes
            fileChunkRemainder = fileByteSize - (numberOfFileChunks * maxChunkSize)

            ## Create a chunk counter variable
            fileChunkCounter = 0

            ## While the file hasn't completed uploading
            while fileChunkCounter <= numberOfFileChunks:

                ## Read a chunk size worth of data from the file
                targetChunkData = fileContent.read(maxChunkSize)

                ## Define the content range for the chunk
                contentStart = fileChunkCounter * maxChunkSize
                contentEnd = contentStart + maxChunkSize 

                ## If it is the last chunk
                if fileChunkCounter == numberOfFileChunks:

                    ## Set the content range for the last chunk using the remainder
                    contentEnd = contentStart + fileChunkRemainder

                ## Define the headers
                headers = {
                    "Content-Range": f"bytes {contentStart}-{contentEnd-1}/{fileByteSize}",
                    "Content-Length": str(maxChunkSize)
                }   
                                
                ## Upload the file
                uploadResult = requests.put(uploadURL, data = targetChunkData, headers = headers)
                                    
                ## Increment the chunk counter
                fileChunkCounter += 1
                                    
                # self.localSetup.logger.info the number of chunks remaining
                ## self.localSetup.logger.info (f"File Segments Remaining: {numberOfFileChunks - fileChunkCounter}")

            self.localSetup.logger.info (f"{fileBaseName} uploaded")

## This function us for when the script is called as a subprocess
def runAsASubprocess ():

    ## Define localSetup
    localSetup = LocalSetup(datetime.now(), __file__)
    
    ## Aceptable Method Arguments
    acceptableMethods = ['outlook', 'onedrive']

    localSetup.logger.info(sys.argv)
    
    ## Check if at least 3 sys arguments are passed and if the first sys argument is either outlook or onedrive and if the second sys argument is an email address
    if not len(sys.argv) >= 3 or (sys.argv[1].lower() not in acceptableMethods) or ('@' not in sys.argv[2]):
        
        ## self.localSetup.logger.info the usage of the general script
        localSetup.logger.info("Usage: graphConfigType: <Outlook or OneDrive>, microsoftUsername: <MicrosoftEmailAddress>")
        sys.exit(2)
        
    ## If the first sys argu passed is 'Outlook'
    if sys.argv[1].lower() == 'outlook':  
        
        ## Check if at least 6 sys arguments are passed
        if not len(sys.argv) >= 6:

            ## self.localSetup.logger.info the usage of the outlook portion of the script
            localSetup.logger.info("Usage: graphConfigType: <Outlook or OneDrive>, microsoftUsername: <MicrosoftEmailAddress>, subject: <EmailSubject>, body: <EmailBody>, recipientEmailList: <RecipientEmailList>, optional shared_mailbox: <SharedMailboxAddress>")
            sys.exit(2)   

        ## Save the sys arguments as variables
        configType = sys.argv[1]
        MicrosoftUserName = sys.argv[2]
        subject = sys.argv[3]
        body = sys.argv[4]
        recipientEmailList = sys.argv[5]
        shared_mailbox = sys.argv[6]

        ## Create a outlookApi object
        outlookApi = CoreMicrosoftAPI(localSetup, graphConfigType = configType, microsoftUserName = MicrosoftUserName)
        
        ## Send the email using the async method
        emailerResult = asyncio.run(outlookApi.send_mail_async(subject, body, recipientEmailList, shared_mailbox))
        
        ## self.localSetup.logger.info and return the emailer result
        localSetup.logger.info (emailerResult)
        return emailerResult

    ## If the first sys argu passed is 'Onedrive'
    elif sys.argv[1].lower() == 'onedrive':    

        ## Check if at least 6 sys arguments are passed
        if not len(sys.argv) >= 6:

            ## self.localSetup.logger.info the usage of the onedrive portion of the script
            localSetup.logger.info("Usage: graphConfigType: <Outlook or OneDrive>, microsoftUsername: <MicrosoftEmailAddress>, action: <'download' or 'upload'>, url: <MicrosoftSharedFileUrl>, filePath: <Path for file to be downloaded to or uploaded from>, optional fileName: <Final Name and exstension of the downloaded file>")
            sys.exit(2)
        
        ## Save the sys arguments as variables
        configType = sys.argv[1]
        MicrosoftUserName = sys.argv[2]
        action = sys.argv[3]
        url = sys.argv[4]
        filePath = sys.argv[5]
        fileName = sys.argv[6]
    
        ## Create a oneDriveAndSharepointApi object
        oneDriveAndSharepointApi = CoreMicrosoftAPI(localSetup, graphConfigType = configType, microsoftUserName = MicrosoftUserName)

        ## If the action is download
        if action.lower() == 'download':

            ## Download the file using the async method
            downloadResult = asyncio.run(oneDriveAndSharepointApi.downloadSharedMicrosoftFileAsync(localSetup, url, filePath, fileName))
    
            ## self.localSetup.logger.info and return the file path
            localSetup.logger.info (downloadResult)
            return downloadResult

        ## If the action is upload
        elif action.lower() == 'upload':
            
            ## Upload the file using the async method
                uploadResult = asyncio.run(oneDriveAndSharepointApi.uploadSharedMicrosoftFileAsync(url, filePath))
        
                ## self.localSetup.logger.info and return the upload result
                localSetup.logger.info (uploadResult)
                return uploadResult

## This function can take all of the necessary variables for sending outlook emails and runs the relavent function within a subprocess of this script
def sendOutlookEmail (p1_microsoftUserName = serviceEmailAccount, p1_subject = "", p1_body = "", p1_recipientEmailList = "", p1_shared_mailbox = "" ):
    
    import subprocess        
    
    ## Run this python script file as a subprocess with all of the neccessary microsoft object and emailer variables
    subprocessResult = subprocess.run([
                                    "python"
                                    , os.path.abspath(__file__)
                                    , "Outlook"
                                    , p1_microsoftUserName
                                    , p1_subject
                                    , p1_body
                                    , p1_recipientEmailList
                                    , p1_shared_mailbox
                                    ]
                                    , capture_output = True
                                    , text = True
                                    )
    
    ## Return the subprocess result
    return subprocessResult

## This function can take all of the necessary variables for downloading a shared microsoft file and runs the relavent function within a subprocess of this script
def downloadSharedMicrosoftFile (p1_microsoftUserName = serviceEmailAccount, p1_microsoftShareUrl = None, p1_downloadSavePath = None, p1_fileName = ""):
    
    import subprocess
    
    ## Run this python script file as a subprocess with all of the neccessary microsoft object and emailer variables
    subprocessResult = subprocess.run([
                                    "python"
                                    , os.path.abspath(__file__)
                                    , "OneDrive"
                                    , p1_microsoftUserName
                                    , "Download"
                                    , p1_microsoftShareUrl
                                    , p1_downloadSavePath
                                    , p1_fileName
                                    ]
                                    , capture_output = True
                                    , text = True
                                    )

    likelyPath = subprocessResult.stderr[subprocessResult.stderr.rfind("INFO"):].replace("INFO ","",1).replace(r"\n","")
    downloadedFilePath = likelyPath if likelyPath and os.path.exists(likelyPath) else p1_downloadSavePath

    ## Return the subprocess result
    return downloadedFilePath

## This function can take all of the necessary variables for uploading a shared microsoft file and runs the relavent function within a subprocess of this script
def uploadSharedMicrosoftFile (p1_microsoftUserName = serviceEmailAccount, p1_microsoftShareUrl = "", p1_uploadItemFilePath = ""):

    import subprocess

    ## Run this python script file as a subprocess with all of the neccessary microsoft object and emailer variables
    subprocessResult = subprocess.run([
                                    "python"
                                    , os.path.abspath(__file__)
                                    , "OneDrive"
                                    , p1_microsoftUserName
                                    , "Upload"
                                    , p1_microsoftShareUrl
                                    , p1_uploadItemFilePath
                                    ]
                                    , capture_output = True
                                    , text = True
                                    )

    ## Return the subprocess result
    return subprocessResult

## If the script is main
if __name__ == "__main__":

    ## If there are sys arguments
    if len(sys.argv) > 1:

        ## Run the subprocess function
        runAsASubprocess()

    else:

        ## Initialize LocalSetup
        localSetup = LocalSetup(datetime.now(), __file__)
        
        ## Configure outlook and sharepoint credentials ##

        ## Outlook
        sendOutlookEmail(p1_subject = 'Associated Course Outcomes: Course Start Information'
                         , p1_body = """test"""
                         , p1_recipientEmailList = 'brycezmiller@nnu.edu'
                         , p1_shared_mailbox = "gradedu@nnu.edu"
                         )

        ## Sharepoint
        tlcDownloadUrlPath = r'https://nnuedu.sharepoint.com/:w:/s/prod-InstructionalDesignTechnologyIDT/EQAniDUXoKNPmg27srCn-ZYBNLuk9XceTvghDyhLr708KQ?e=MfU8Ci'
        downloadSharedMicrosoftFile(p1_microsoftShareUrl = tlcDownloadUrlPath
                                    , p1_downloadSavePath = localSetup.configPath
                                  )

        ##  Direct Async test run (comment out the configure above)
        #outlookApi = CoreMicrosoftAPI(localSetup, graphConfigType = "Outlook", microsoftUserName = serviceEmailAccount)
        ## oneDriveAndSharepointApi = CoreMicrosoftAPI(localSetup, graphConfigType = "Onedrive", microsoftUserName = serviceEmailAccount)
        
        ## tlcUploadUrlPath = r'https://nnuedu.sharepoint.com/sites/prod-InstructionalDesignTechnologyIDT/Shared%20Documents'
        ## uploadfilepath = os.path.join(localSetup.configPath, "Test Doc.docx")
        ## downloadfilepath = localSetup.configPath
 
        ## Email Send test, file upload test, file download test ##
        ## MAKE SURE TO ONLY RUN ONE AT A TIME (the second one will always error out due to the event loop already running)

        #asyncioResult = asyncio.run(outlookApi.send_mail_async(subject = 'Testing Microsoft Graph New!', body = 'Hello world!!!!', recipientEmailList = 'brycezmiller@nnu.edu', shared_mailbox = "tlc@nnu.edu"))
        ##asyncioResult = asyncio.run(oneDriveAndSharepointApi.uploadSharedMicrosoftFileAsync(tlcUploadUrlPath, uploadfilepath))
        ##asyncioResult = asyncio.run(oneDriveAndSharepointApi.downloadSharedMicrosoftFileAsync(tlcDownloadUrlPath, downloadfilepath, 'Test Doc'))

        ######

        ## Create a outlookApi object
        ## Create a outlookApi object
        ## outlookApi = CoreMicrosoftAPI(graphConfigType = "Outlook", microsoftUserName = serviceEmailAccount)
        
        ## Create a oneDriveAndSharepointApi object
        ## oneDriveAndSharepointApi = CoreMicrosoftAPI(graphConfigType = "Onedrive", microsoftUserName = serviceEmailAccount)
    
        ## asyncio.run(outlookApi.send_mail_async(subject = 'Testing Microsoft Graph New!', body = 'Hello world!!!!', recipientEmailList = 'brycezmiller@nnu.edu', shared_mailbox = "ie@nnu.edu"))
        ## asyncio.run(outlookApi.send_mail_async(subject = "prime test"
        ##                      , body = "hey"
        ##                      , recipientEmailList = "tlc@nnu.edu, brycezmiller@nnu.edu"
        ##                      , shared_mailbox = "instructionaldesign@nnu.edu"))
        ## self.localSetup.logger.info('Mail sent.\n')

        ## studentCohortProfileLink = ''

        ## asyncioResult = asyncio.run(oneDriveAndSharepointApi.downloadSharedMicrosoftFileAsync(fileShareUrl = studentCohortProfileLink, downloadSavePath = departmentalDataResroucesPath))
        ## self.localSetup.logger.info ('File retrieved')
    
        
        ## asyncioResult = asyncio.run(oneDriveAndSharepointApi.uploadSharedMicrosoftFileAsync(fileLink, fr"{departmentalDataResroucesPath}Test Doc.docx"))
    
        ## upload a test file
        ## asyncio .run(oneDriveAndSharepointApi.upload_file_to_sharepoint_async(site_id="InstitutionalEffectiveness", folder_id="01KZJ3QKZ3F5JZ2W3L2Z6WZ7V7Z3Z5)

        ## oneDriveAndSharepointApi.upload_microsoft_file(r"Admissions Data.xlsx", 'EpoNInDhwb9OvsaU-R3lEtEB-wFaU9qPns8huA70F0TnLA?e=Kciv0X')

        ## outlookApi.send_mail(subject = 'Testing Microsoft Graph New!', body = 'Hello world!!!!', recipient = input("Enter the email addres that will recieve the email (i.e. example@nnu.edu): "), shared_mailbox = "instructionaldesign@nnu.edu")
        ## self.localSetup.logger.info('Mail sent.\n')

## ===========================================================================
## FILE: ResourceModules\Error_Email.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Modules
import traceback, logging, os, sys

try: ## If the module is run directly
    from Core_Microsoft_Api import sendOutlookEmail
except ImportError: ## Otherwise as a relative import if the module is imported
    from .Core_Microsoft_Api import sendOutlookEmail

## Import Config Variables
from Common_Configs import scriptLibrary, serviceEmailAccount, authorContactInformation


## Define the script name, purpose, and external requirements for logging and error reporting purposes
__scriptName = os.path.basename(__file__).replace(".py", "")
scriptPurpose = r"""
This class contains the methods and variables to send error emails \
with the Microsoft API utilizing the local Core Microsoft Api module
"""
externalRequirements = r"""
See https://learn.microsoft.com/en-us/graph/overview?context=graph%2Fapi%2F1.0&view=graph-rest-1.0 \
for the outlook api documentation and setup requirements.
"""

class errorEmail:
    """Used to send function-specific error emails"""

    ## Initializer / Instance Attributes
    def __init__(self, scriptName, scriptPurpose, externalRequirements, p1_localSetup):
        self.scriptName = scriptName
        self.scriptPurpose = scriptPurpose
        self.externalRequirements = externalRequirements
        self.localSetup = p1_localSetup
        self.sentErrors = set()

    ## This class method creates a formatted error email
    def _createErrorEmailBody(self, p1_functionName, errorInfo):
        functionName = "_createErrorEmailBody"

        return f"""To the LMS Admin or the department chair of {scriptLibrary},

An error has occurred in the {self.scriptName} script while running the function "{p1_functionName}"

Details on the purpose and function of the script are below.

{authorContactInformation}

Details regarding this script
Purpose:
{self.scriptPurpose}

Requirements to work properly:
{self.externalRequirements}

Error Description/Code: {errorInfo}
"""

    ## This method sends an error email for a specific function
    def sendError(self, p1_functionName, errorInfo):
        functionName = "Send Error"
        
        ## Log the error
        self.localSetup.logger.error(f"\nA script error occurred while running {p1_functionName}. Error: {str(errorInfo)}")

        ## If the function has already triggered an error email, skip sending again
        if p1_functionName in self.sentErrors:
            self.localSetup.logger.error(f"\nError email already sent for {p1_functionName}")
            return

        
        # Try to get the actual exception object
        exc = errorInfo if isinstance(errorInfo, BaseException) else None

        if exc is None:
            # Fall back to the currently handled exception (if any)
            excType, excValue, excTb = sys.exc_info()
            if excValue is not None:
                exc = excValue

        if exc is not None:
            # Build traceback with locals captured in each frame
            tbExc = traceback.TracebackException.from_exception(exc, capture_locals=True)
            traceWithLocals = ''.join(tbExc.format())
        else:
            # Fallback: no specific exception object, just use standard traceback
            traceWithLocals = traceback.format_exc()


        ## Format the full error info with traceback
        fullErrorInfo = f"{errorInfo}: \n\n{traceWithLocals}"

        ## Log the full error info
        self.localSetup.logger.error(f"\nFull Error Info:\n{fullErrorInfo}")

        ## Create the formatted email body
        emailBody = self._createErrorEmailBody(p1_functionName, fullErrorInfo)

        ## Send the error alert email
        sendOutlookEmail(
            p1_microsoftUserName=serviceEmailAccount,
            p1_subject=f"{self.scriptName}: Error in \"{p1_functionName}\"",
            p1_body=emailBody,
            p1_recipientEmailList=f"{scriptLibrary}@nnu.edu",
            p1_shared_mailbox=f"{scriptLibrary}@nnu.edu"
        )

        ## Track that an error email has been sent for this function
        self.sentErrors.add(p1_functionName)
        self.localSetup.logger.error(f"\nError Email Sent for {p1_functionName}")

## ===========================================================================
## FILE: ResourceModules\Get_Slate_Info.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Modules
from datetime import datetime
import traceback, paramiko, os, logging, json, re, time ## External Installation: paramiko: https://www.paramiko.org/installing.html

try: ## If the module is run directly
    from Error_Email import errorEmail
    from Local_Setup import LocalSetup
except ImportError: ## Otherwise as a relative import if the module is imported
    from .Error_Email import errorEmail  ## Import errorEmailApi
    from .Local_Setup import LocalSetup

from Common_Configs import undgTermsCodesToWordsDict, gradTermsCodesToWordsDict

## Define the purpose, and external requirements for logging and error reporting purposes
__scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
This script (Get_Slate_Info) connects to the NNU's slate SFTP server to retrieve the csv of incoming
students for the coming semester.
"""
externalRequirements = r"""
To function properly this script requires access to the SFTP server
"""

## Create the localsetup varabile
localSetup = localSetup = LocalSetup(datetime.now(), __file__)

## Setup the error handler
errorHandler = errorEmail(__scriptName, scriptPurpose, externalRequirements, localSetup)

## This function calls the GE Council's Outcome course code list Google Sheet and saves it as a csv
def getSlateInfo (p1_inputTerm):
    functionName = "Get Slate Info"

    try:

        ## Define a veriable to hold the slate creds json file
        slateCreds = None

        ## Define the number of attempts made this run to connect to the SFTP server
        attempt = 0
        ## Define the maximum number of retries to connect to the SFTP server before giving up
        retries = 5

        ## Open the slate creds json file from the configPath
        with open(os.path.join(localSetup.configPath, "Slate_Creds.json"), "r") as file:

            ## Load the json file
            slateCreds = json.load(file)

        ## Define the slate creds
        ASHost = slateCreds["ASHost"]
        ASPort = slateCreds["ASPort"]
        ASUsername = slateCreds["ASUsername"]
        ASPassword = slateCreds["ASPassword"]
        ASPublicKeyPath = os.path.join(localSetup.configPath, "Slate_Public_Key.txt")

        ## Create an SSH client
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        
        # try to connect to the SFTP server
        while attempt < retries:
            try:
                ssh_client.connect(hostname=ASHost
                                   , port=ASPort
                                   , username=ASUsername
                                   , password=ASPassword
                                   , key_filename=ASPublicKeyPath
                                   , banner_timeout=60
                                   )

                ## Create an SFTP client from the SSH client
                sftp_client = ssh_client.open_sftp()

                ## If the connection is successful, log the success and break out of the loop
                break

            ## If the connection fails
            except Exception as Error:

                ## Increment the attempt counter
                attempt += 1

                ## If the maximum number of retries has not been reached, log the error and retry
                if attempt < retries:
                    localSetup.logger.warning(f"Attempt {attempt} failed: {Error}. Retrying in 1 minute...")
                    time.sleep(60)

                ## Otherwise, log the error and return None
                else:
                    localSetup.logger.error(f"Attempt {attempt} failed: {Error}. No more retries.")
                    errorHandler.sendError (functionName, p1_ErrorInfo=Error)
                    return None
       

        ## List the contents of the remote directory
        fileList = sftp_client.listdir("./Outgoing//canvas")

        ## Specify the remote file path
        remoteBasePath = "./Outgoing//Canvas//"

        ## Determine and save the term's school year
        termCodePrefix = p1_inputTerm[:2]
        termWord = gradTermsCodesToWordsDict[termCodePrefix] if termCodePrefix in gradTermsCodesToWordsDict.keys() else undgTermsCodesToWordsDict[termCodePrefix]
        targetSchoolYear = localSetup.getSchoolYear(termWord, localSetup.dateDict["year"])

        ## Define the incoming School Year input path  
        incomingSchoolYearInputPath = os.path.join(localSetup.getInternalResourcePaths("Slate"), targetSchoolYear)
        termOutputPath = os.path.join(incomingSchoolYearInputPath, p1_inputTerm, "Incoming")
        os.makedirs(termOutputPath, exist_ok=True)
        
        ## If the incomingSchoolYearInputPath doesn't already exist, create it
        if not (os.path.exists(incomingSchoolYearInputPath)):
            os.makedirs(incomingSchoolYearInputPath, mode=0o777, exist_ok=False)

        ## If the localFilePath doesn't already exist, create it
        if not (os.path.exists(termOutputPath)):
            os.makedirs(termOutputPath, mode=0o777, exist_ok=False)

        ## Make a list of the downloaded file paths
        downloadedFiles = []

        try: ## Irregular try clause, do not comment out in testing
            ## Download the file from the SFTP server
            for file in fileList:
                fullRemotePath = os.path.join(remoteBasePath, file)
                fullLocalPath = os.path.join(termOutputPath, file)
                sftp_client.get(fullRemotePath, fullLocalPath)

                ## Define a variable to hold the file contents
                fileContents = None

                ## Read the file
                with open(fullLocalPath, "r") as file:
                    fileContents = file.read()
                    
                ## Count the number of \n's in the file, and if there is only one occurence
                ## the file is empty and should be deleted
                if fileContents.count("\n") == 1:
                    os.remove(fullLocalPath)

                    ## Split the full local path by .
                    splitFullLocalPath = fullLocalPath.split(".")

                    ## Split the file path by . to remove the file extension, and if a version of the file with _canvas_data exists delete it
                    if len(splitFullLocalPath) > 1:
                        if os.path.exists(f"{splitFullLocalPath[0]}_canvas_data.{splitFullLocalPath[1]}"):
                            os.remove(f"{splitFullLocalPath[0]}_canvas_data.{splitFullLocalPath[1]}")

                    localSetup.logger.warning(f"{fullLocalPath} is empty and has been deleted.")

                ## Otherwise
                else:

                    ## Add the downloaded file to the list of downloaded files
                    downloadedFiles.append(fullLocalPath)

            ## Log that the files were downloaded successfully
            localSetup.logger.info("Files downloaded successfully.")
        finally:
            ## Close the SFTP client and SSH connection
            sftp_client.close()
            ssh_client.close()

        return downloadedFiles



    except Exception as Error:
        errorHandler.sendError(functionName, Error)

if __name__ == "__main__":

    ## Start and download the Canvas report
    getSlateInfo (p1_inputTerm = input("Enter the desired term in \
four character format (FA20, SU20, SP20): "))

    input("Press enter to exit")

## ===========================================================================
## FILE: ResourceModules\Local_Setup.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Modules
import os, json, sys, logging, calendar, re
from datetime import datetime
## Add the config path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "Configs"))

## Import local config variables
from Common_Configs import (
    scriptLibrary, 
    externalResourcePathsDict, 
    undgTermsWordsToCodesDict, 
    undgTermsCodesToWordsDict,
    gradTermsWordsToCodesDict,
    gradTermsCodesToWordsDict,
    termMonthRanges,
    termSchoolYearLogic
)

## Define the script name, purpose, and external requirements for logging and error reporting purposes
__scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
This module (TLC_Common) provides the LocalSetup class for setting up common paths,
logging, and resource management for scripts within the TLC script library.
It standardizes the environment for scripts by establishing directory structures,
logging mechanisms, and resource access methods.
"""

externalRequirements = r"""
To function properly this module requires:
- Access to the filesystem to create and manage directories for logs and resources.
- Permissions to write log files in the designated log directory.
"""

class LocalSetup:
    def __init__(self, dateTime: datetime, __scriptPath: str, scriptLibrary: str = scriptLibrary):

        ## Private Variables ##

        ## Local Script Variables
        self.__scriptPath = __scriptPath
        self.__scriptName = os.path.basename(__scriptPath).replace(".py", "")
        self.__scriptLibraryName = scriptLibrary
        ## Term Dictionaries
        self.__undgTermsDict = undgTermsWordsToCodesDict
        self.__gradTermsWordsToCodesDict = gradTermsWordsToCodesDict

        ## Public Variables ##

        ## Date and Time Variables
        self.initialDateTime = dateTime
        self.dateDict = {
            "hour" : dateTime.hour,
            "day" : dateTime.day,
            "weekDay" : dateTime.weekday(),
            "month" : dateTime.month,
            "year" : dateTime.year,
            "century" : dateTime.year // 100, ## integer division to get century ## e.g. 2024 // 100 = 20
            "decade" : dateTime.year % 100, ## modulus to get decade ## e.g. 2024 % 100 = 24
            "lastDayOfCurrentMonth" : calendar.monthrange(dateTime.year, dateTime.month)[1]
        }
        ## Setup paths and logging
        self.absolutePath, self.baseLogPath, self.configPath = self._setupCommonPaths()
        self.logger = self._setupLogger()
        ## Path Storage
        self.internalResourcePathDict = {}
        self.externalResourcePaths = externalResourcePathsDict
        self.termPaths = {}
        self.internalDepartmentOutputPaths = {}

    ## Internal Methods

    ## Create common paths set working directory, and add module paths to sys.path
    def _setupCommonPaths(self): 
        fileDir = os.path.dirname(self.__scriptPath)
        os.chdir(fileDir)

        ## Traverse up until "Scripts_TLC" is found
        pfRelativePath = fileDir
        while True:
            if "Scripts_TLC" in os.listdir(pfRelativePath):
                break
            parent = os.path.abspath(os.path.join(pfRelativePath, ".."))
            if parent == pfRelativePath:
                raise FileNotFoundError("Scripts_TLC directory not found in parent hierarchy.")
            pfRelativePath = parent

        absolutePath = os.path.abspath(pfRelativePath)
        ## Add resource module paths to sys.path
        sys.path.append(os.path.join(absolutePath, f"Scripts_{self.__scriptLibraryName}", "ResourceModules"))
        sys.path.append(os.path.join(absolutePath, f"Scripts_{self.__scriptLibraryName}", "ReportModules"))
        sys.path.append(os.path.join(absolutePath, f"Scripts_{self.__scriptLibraryName}", "ActionModules"))
        sys.path.append(os.path.join(absolutePath, f"Scripts_{self.__scriptLibraryName}", "Configs"))
        ## Setup log and config paths using absolute path
        configPath = os.path.join(absolutePath, f"Scripts_{self.__scriptLibraryName}", "Configs")
        baseLogPath = os.path.join(absolutePath, "Logs", self.__scriptName)
        os.makedirs(baseLogPath, mode=0o777, exist_ok=True)

        return absolutePath, baseLogPath, configPath

    ## Create and configure a localSetup.logger for the script
    def _setupLogger(self):
        logger = logging.getLogger(self.__scriptName)
        FORMAT = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
        logging.basicConfig(format="%(asctime)s %(levelname)s %(message)s", encoding='utf-8', filemode="a", level=logging.INFO)

        ## Info Log
        infoLogFile = os.path.join(self.baseLogPath, "Info Log.txt")
        logInfo = logging.FileHandler(infoLogFile, mode='a')
        logInfo.setLevel(logging.INFO)
        logInfo.setFormatter(FORMAT)
        logger.addHandler(logInfo)

        ## Warning Log
        warningLogFile = os.path.join(self.baseLogPath, "Warning Log.txt")
        logWarning = logging.FileHandler(warningLogFile, mode='a')
        logWarning.setLevel(logging.WARNING)
        logWarning.setFormatter(FORMAT)
        logger.addHandler(logWarning)

        ## Error Log
        errorLogFile = os.path.join(self.baseLogPath, "Error Log.txt")
        logError = logging.FileHandler(errorLogFile, mode='a')
        logError.setLevel(logging.ERROR)
        logError.setFormatter(FORMAT)
        logger.addHandler(logError)

        return logger
    
    ## Validate term input
    def _validateTerm(self, term: str):
        if term not in termSchoolYearLogic:
            raise ValueError(f"Invalid term: {term}")

    ## Determine current term based on month
    def _determineCurrentTerm(self, currentMonth: int) -> str:
        for term, (start, end) in termMonthRanges.items():
            if start <= currentMonth <= end:
                return term

    ## Determine the previous term given the current term
    def _determinePreviousTerm(self, currentTerm: str) -> str:
        termOrder = list(termMonthRanges.keys())  ## ["Fall", "Spring", "Summer"]
        currentIndex = termOrder.index(currentTerm)
        previousTerm = termOrder[currentIndex - 1] if currentIndex > 0 else termOrder[-1]
        return previousTerm

    ## Determine the next term given the current term
    def _determineNextTerm(self, currentTerm: str) -> str:
        termOrder = list(termMonthRanges.keys())  ## ["Fall", "Spring", "Summer"]
        currentIndex = termOrder.index(currentTerm)
        nextTerm = termOrder[currentIndex + 1] if currentIndex < len(termOrder) - 1 else termOrder[0]
        return nextTerm

    ## Get school year range as tuple
    def _getSchoolYearRange(self, currentTerm: str, currentYear: int) -> tuple[int, int]:
        self._validateTerm(currentTerm)
        if termSchoolYearLogic[currentTerm] == "current-next":
            return currentYear, currentYear + 1
        else:
            return currentYear - 1, currentYear
    
    ## Determine School Year from term and year (wrapper)
    def _determineSchoolYear(self, term: str, year: int) -> str:
        startYear, endYear = self._getSchoolYearRange(term, year)
        return f"{startYear}-{endYear}"

    ## Take in a term and year and determine the term code
    def _determineTermCode(self, term: str, year: int, courseLevel: str) -> str:
        targetTerm = self.__gradTermsWordsToCodesDict.get(term) if courseLevel.lower() == "graduate" else self.__undgTermsDict.get(term)
        return targetTerm + str(year)[2:]

    ## Determine the term name
    def _determineTermName(self, rawTerm: str) -> str:
        refinedTerm = undgTermsCodesToWordsDict[rawTerm] if rawTerm in undgTermsCodesToWordsDict.keys() else gradTermsCodesToWordsDict[rawTerm] if rawTerm in gradTermsCodesToWordsDict.keys() else rawTerm
        return refinedTerm.capitalize()

    ## Get year for term
    def _getYearForTerm(self, term: str, startYear: int, endYear: int) -> int:
        self._validateTerm(term)
        return startYear if termSchoolYearLogic[term] == "current-next" else endYear

    ## Get decade for term
    def _getDecadeForTerm(self, term: str, startDecade: int, endDecade: int) -> int:
        self._validateTerm(term)
        return startDecade if termSchoolYearLogic[term] == "current-next" else endDecade

    ## Create term path for a given term and year
    def _createTermPath(self, term: str, year: int, courseLevel: str):
        ## Get the base Canvas resource path
        canvasOutputPath = self.getInternalResourcePaths("Canvas")

        termName = self._determineTermName(term)

        ## Determine school year using LocalSetup logic
        schoolYear = self._determineSchoolYear(termName, year)

        ## Build the full path for the term
        schoolYearPath = os.path.join(canvasOutputPath, schoolYear)
        termPath = os.path.join(schoolYearPath, termName)  ## Use full term string for folder name

        ## Create the term directory if it does not exist
        os.makedirs(termPath, exist_ok=True)

        ## Store the term path for quick lookup
        self.termPaths[term+str(year)] = termPath
    
    ## Create target designated output path for a given term and designator
    def _createCourseLevelPath(self, courseLevel: str, rawTerm: str, year: int):

        ## Determine term code using LocalSetup logic
        termCode = self._determineTermCode(term=rawTerm, year=year, courseLevel=courseLevel)
        termPathName = rawTerm+str(year)

        ## Ensure term path exists
        if termPathName not in self.termPaths:
            self._createTermPath(rawTerm, year, courseLevel)  ## Reuse updated _createTermPath logic

        ## Create course-level path
        courseLevelPath = os.path.join(self.termPaths[termPathName], courseLevel)
        os.makedirs(courseLevelPath, exist_ok=True)

        ## Store course-level path using termCode
        self.termPaths[termCode] = courseLevelPath


    ## Create target designated output path for a given term and designator
    def _createDepartmentPath(self, rawTerm: str, year: int, targetDesignator: str):

        ## Determine school year using LocalSetup logic 
        schoolYear = self._determineSchoolYear(rawTerm, year)

        ## Build paths
        canvasOutputPath = self.getInternalResourcePaths("Canvas")
        schoolYearPath = os.path.join(canvasOutputPath, schoolYear)
        termPath = os.path.join(schoolYearPath, rawTerm)  ## Use rawTerm for folder name
        os.makedirs(termPath, exist_ok=True)

        ## Create department-specific path
        departmentPath = os.path.join(termPath, "Departments", targetDesignator)
        os.makedirs(departmentPath, exist_ok=True)

        ## Store in internal dictionary
        self.termPaths[rawTerm] = termPath
        self.internalDepartmentOutputPaths[(rawTerm, targetDesignator)] = departmentPath

    ## Public Methods

    ## Return the internal resource path for the given resource type, creating it if necessary
    def getInternalResourcePaths(self, resourceType):
        """
        Public method to get or create the internal resource path for a given resource type.
        """
        if resourceType not in self.internalResourcePathDict:
            resourcePath = os.path.join(self.absolutePath, f"Resources_{resourceType.capitalize()}")
            os.makedirs(resourcePath, exist_ok=True)
            self.internalResourcePathDict[resourceType] = resourcePath
        return self.internalResourcePathDict[resourceType]

    
    ## Return the termPath for a given term code
    def getTermPath(self, term: str, year: int, courseLevel: str):
        """
        Public method to retrieve the term path for a given term and year.
        """
        termName = self._determineTermName(term)
        termPathName = rawTerm+str(year)
        if termPathName not in self.termPaths:
            self._createTermPath(termName, year, courseLevel)
        return self.termPaths[termPathName]

    ## Return the courselevel path for a given courseLevel, term, and year
    def getCourseLevelPath(self, courseLevel: str, term: str, year: int) -> str:
        """
        Public method to retrieve the course level path for a given courseLevel, term, and year.
        """
        termName = self._determineTermName(term)
        termCode = self._determineTermCode(term=term, year=year, courseLevel=courseLevel)
        if termCode not in self.termPaths:
            self._createCourseLevelPath(courseLevel, termName, year)
        return self.termPaths[termCode]

    ## Return or create the target designated output path for a given term and designator
    def getTargetDesignatedOutputPath(self, term: str, year: int, targetDesignator: str) -> str:
        """
        Public method to retrieve the target designated output path for a given term, year, and designator.
        """
        termName = self._determineTermName(term)
        if (termName, targetDesignator) not in self.internalDepartmentOutputPaths:
            self._createDepartmentPath(term, year, targetDesignator)
        return self.internalDepartmentOutputPaths[(termName, targetDesignator)]

    ## Return the external resource path for a given resource type
    def getExternalResourcePath(self, resourceType: str) -> str:
        """
        Public method to retrieve the external resource path for a given resource type.
        """
        return self.externalResourcePaths.get(resourceType)

    ## Return the school year for a given term and year`
    def getSchoolYear(self, term: str, year: int) -> str:
        """
        Return the school year string for the given term and year. ## e.g. "2023-2024"
        """
        return self._determineSchoolYear(term, year)
    
    ## Common function to get terms (full year codes)
    def getTerms(self, month: int, year: int) -> set:
        """
        Return full-year codes for the given month/year.
        ## e.g. ["SU2024", "SG2024"]
        """
        terms = set()
        for term, (start, end) in termMonthRanges.items():
            if start <= month <= end:
                terms.update([f"{undgTermsWordsToCodesDict[term]}{year}", f"{gradTermsWordsToCodesDict[term]}{year}"])
        return terms

    ## Common function to get term codes (decade codes)
    def getTermCodes(self, month: int, decade: int) -> set:
        """
        Return decade codes for the given month/year.
        ## e.g. ["SU24", "SG24"]
        """
        termCodes = set()
        for term, (start, end) in termMonthRanges.items():
            if start <= month <= end:
                termCodes.update([f"{undgTermsWordsToCodesDict[term]}{decade}", f"{gradTermsWordsToCodesDict[term]}{decade}"])
        return termCodes
    
    ## Return the current terms based on the current date
    def getCurrentTerms(self) -> set:
        """
        Return the current terms based on the current date.
        ## e.g. ["SU2024", "SG2024"]
        """
        return self.getTerms(self.dateDict["month"], self.dateDict["year"])

    ## Return the current term codes based on the current date
    def getCurrentTermCodes(self) -> set:
        """
        Return the current term codes based on the current date.
        ## e.g. ["SU24", "SG24"]
        """
        return self.getTermCodes(self.dateDict["month"], self.dateDict["decade"])

    ## Return all terms for the current school year
    def getCurrentSchoolYearTerms(self) -> set:
        """
        Return all unique terms for the current school year using getTerms.
        ## e.g. {"FA2025", "GF2025", "SP2026", "GS2026", "SU2026", "SG2026"}
        """
        currentTerm = self._determineCurrentTerm(self.dateDict["month"])
        startYear, endYear = self._getSchoolYearRange(currentTerm, self.dateDict["year"])

        terms = set()
        for term, logic in termSchoolYearLogic.items():
            yearForTerm = startYear if logic == "current-next" else endYear
            startMonth = termMonthRanges[term][0]
            terms.update(self.getTerms(startMonth, yearForTerm))
        return terms

    ## Return all decade codes for the current school year
    def getCurrentSchoolYearTermCodes(self) -> set:
        """
        Return all decade codes for the current school year using getTermCodes and termSchoolYearLogic.
        ## e.g. {"FA25", "GF25", "SP26", "GS26", "SU26", "SG26"}
        """
        currentTerm = self._determineCurrentTerm(self.dateDict["month"])
        startYear, endYear = self._getSchoolYearRange(currentTerm, self.dateDict["year"])
        startDecade, endDecade = startYear % 100, endYear % 100

        termCodes = set()
        for term, logic in termSchoolYearLogic.items():
            decadeForTerm = startDecade if logic == "current-next" else endDecade
            startMonth = termMonthRanges[term][0]
            termCodes.update(self.getTermCodes(startMonth, decadeForTerm))
        return termCodes

    ## Return the most recent completed terms
    def getMostRecentCompletedTerms(self) -> set:
        """
        Return the most recently completed full-year term codes based on the current date.
        ## e.g. ["SU2024", "SG2024"]
        """
        currentMonth = self.dateDict["month"]
        currentYear = self.dateDict["year"]

        currentTerm = self._determineCurrentTerm(currentMonth)
        previousTerm = self._determinePreviousTerm(currentTerm)

        ## Determine the correct year for the previous term
        previousTermYear = currentYear - 1 if termSchoolYearLogic[previousTerm] == 'current-next' else currentYear

        startYear, endYear = self._getSchoolYearRange(previousTerm, previousTermYear)
        yearForPreviousTerm = startYear if termSchoolYearLogic[previousTerm] == "current-next" else endYear

        return self.getTerms(termMonthRanges[previousTerm][0], yearForPreviousTerm)

    ## Return the most recent completed term codes
    def getMostRecentCompletedTermCodes(self) -> set:
        """
        Return the most recently completed decade term codes based on the current date.
        ## e.g. ["SU24", "SG24"]
        """
        currentMonth = self.dateDict["month"]
        currentYear = self.dateDict["year"]
        currentTerm = self._determineCurrentTerm(currentMonth)
        previousTerm = self._determinePreviousTerm(currentTerm)
        ## Determine the correct year for the previous term
        previousTermYear = currentYear - 1 if termSchoolYearLogic[previousTerm] == 'current-next' else currentYear
        startYear, endYear = self._getSchoolYearRange(previousTerm, previousTermYear)
        decadeForPreviousTerm = (startYear % 100) if termSchoolYearLogic[previousTerm] == "current-next" else (endYear % 100)
        return self.getTermCodes(termMonthRanges[previousTerm][0], decadeForPreviousTerm)

    ## Return the most recent completed decade term codes        
    def getPreviousSchoolYearTerms(self) -> set:
        """
        Return all full-year term codes for the previous school year using dynamic logic.
        ## e.g. {"FA2024", "GF2024", "SP2025", "GS2025", "SU2025", "SG2025"}
        """    
        currentTerm = self._determineCurrentTerm(self.dateDict["month"])
        previousTerm = self._determinePreviousTerm(currentTerm)
        currentYear = self.dateDict["year"]

        ## Determine correct year for previous term
        previousTermYear = currentYear - 1 if termSchoolYearLogic[previousTerm] == 'current-next' else currentYear

        startYear, endYear = self._getSchoolYearRange(previousTerm, previousTermYear)

        terms = set()
        for term, logic in termSchoolYearLogic.items():
            yearForTerm = startYear if logic == "current-next" else endYear
            startMonth = termMonthRanges[term][0]
            terms.update(self.getTerms(startMonth, yearForTerm))
        return terms

    ## Return all terms for the previous school year
    def getPreviousSchoolYearTermCodes(self) -> set:
        """
        Return all decade codes for the previous school year using _determineSchoolYear and termSchoolYearLogic.
        ## e.g. {"FA24", "GF24", "SP25", "GS25", "SU25", "SG25"}
        """
        currentTerm = self._determineCurrentTerm(self.dateDict["month"])
        previousTerm = self._determinePreviousTerm(currentTerm)
        currentYear = self.dateDict["year"]

        previousTermYear = currentYear - 1 if termSchoolYearLogic[previousTerm] == 'current-next' else currentYear

        startYear, endYear = self._getSchoolYearRange(previousTerm, previousTermYear)
        startDecade, endDecade = startYear % 100, endYear % 100

        termCodes = set()
        for term, logic in termSchoolYearLogic.items():
            decadeForTerm = startDecade if logic == "current-next" else endDecade
            startMonth = termMonthRanges[term][0]
            termCodes.update(self.getTermCodes(startMonth, decadeForTerm))
        return termCodes

    ## Return the next term
    def getNextTerms(self) -> set:
        """
        Return the next full-year term codes based on the current date.
        ## e.g. ["FA2024", "GF2024"]
        """
        currentMonth = self.dateDict["month"]
        currentYear = self.dateDict["year"]
        currentTerm = self._determineCurrentTerm(currentMonth)
        nextTerm = self._determineNextTerm(currentTerm)
        ## Determine the correct year for the next term
        nextTermYear = currentYear if termSchoolYearLogic[nextTerm] == 'current-next' else currentYear + 1
        return self.getTerms(termMonthRanges[nextTerm][0], nextTermYear)

    ## Return the next term codes
    def getNextTermCodes(self) -> set:
        """
        Return the next decade term codes based on the current date.
        ## e.g. ["FA24", "GF24"]
        """
        currentMonth = self.dateDict["month"]
        currentYear = self.dateDict["year"]
        currentTerm = self._determineCurrentTerm(currentMonth)
        nextTerm = self._determineNextTerm(currentTerm)
        ## Determine the correct year for the next term
        nextTermYear = currentYear if termSchoolYearLogic[nextTerm] == 'current-next' else currentYear + 1
        nextTermDecade = nextTermYear % 100
        return self.getTermCodes(termMonthRanges[nextTerm][0], nextTermDecade)


    ## Return all terms for the next school year
    def getNextSchoolYearTerms(self) -> set:
        """
        Return all full-year term codes for the next school year using dynamic logic.
        ## e.g. {"FA2026", "GF2026", "SP2027", "GS2027", "SU2027", "SG2027"}
        """
        currentTerm = self._determineCurrentTerm(self.dateDict["month"])
        currentYear = self.dateDict["year"]

        startYear, endYear = self._getSchoolYearRange(currentTerm, currentYear + 1)

        terms = set()
        for term, logic in termSchoolYearLogic.items():
            yearForTerm = startYear if logic == "current-next" else endYear
            startMonth = termMonthRanges[term][0]
            terms.update(self.getTerms(startMonth, yearForTerm))
        return terms

    ## Return all terms for the previous school year
    def getNextSchoolYearTermCodes(self) -> set:
        """
        Return all decade codes for the next school year using _determineSchoolYear and termSchoolYearLogic.
        ## e.g. {"FA26", "GF26", "SP27", "GS27", "SU27", "SG27"}
        """
        currentTerm = self._determineCurrentTerm(self.dateDict["month"])
        currentYear = self.dateDict["year"]

        startYear, endYear = self._getSchoolYearRange(currentTerm, currentYear + 1)

        ## Determine the next school year decades
        startDecade, endDecade = startYear % 100, endYear % 100

        termCodes = set()
        for term, logic in termSchoolYearLogic.items():
            decadeForTerm = startDecade if logic == "current-next" else endDecade
            startMonth = termMonthRanges[term][0]
            termCodes.update(self.getTermCodes(startMonth, decadeForTerm))
        return termCodes

## ===========================================================================
## FILE: ResourceModules\TLC_Common.py
## ===========================================================================

## Author: Bryce Miller - brycezmiller@nnu.edu
## Last Updated by: Bryce Miller

## Import Generic Modules
import os, sys, requests, time, functools, zipfile, pandas as pd
from datetime import datetime
from dotenv import load_dotenv
from typing import Callable, Tuple, Type

try: ## If the module is run directly
    from Local_Setup import LocalSetup
except ImportError: ## Otherwise as a relative import if the module is imported
    from .Local_Setup import LocalSetup

## Define the script name, purpose, and external requirements for logging and error reporting purposes
__scriptName = os.path.basename(__file__).replace(".py", "")

scriptPurpose = r"""
Provide common variables, dictionaries, and setup functions for use in TLC scripts.
"""

externalRequirements = r"""
To be located within a folder named "Resource Folder" which has "Configs" folder at the same courseLevel.
Both folders should be under a main project folder, often named for the department, ## e.g., "Scripts_TLC".
"""

## Add the config path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "Configs"))

from Common_Configs import canvasAccessToken

def retry(
    max_attempts: int = 5,
    delay: float = 5.0,
    backoff: float = 1.5,
    exceptions: Tuple[Type[Exception], ...] = (Exception,)
):
    """
    Retry decorator that uses the localSetup.logger from a LocalSetup instance passed as the first argument.
    Assumes the decorated function's first argument is a LocalSetup object.
    """
    def decorator(func: Callable):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            localSetup = args[0]  ## Assumes LocalSetup is the first argument

            attempts = 0
            current_delay = delay

            while attempts < max_attempts:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    attempts += 1
                    if localSetup.logger:
                        localSetup.logger.warning(
                            f"Attempt {attempts} failed for {func.__name__}: {e}. Retrying in {current_delay:.1f} seconds..."
                        )
                    if attempts == max_attempts:
                        if localSetup.logger:
                            localSetup.logger.error(f"{func.__name__} failed after {attempts} attempts.")
                        raise
                    time.sleep(current_delay)
                    current_delay *= backoff
        return wrapper
    return decorator


## Return Encryption Key Function
def getEncryptionKey(localSetup: LocalSetup):
    ## Load .env from configPath
    envPath = os.path.join(localSetup.configPath, ".env")
    load_dotenv(dotenv_path=envPath) 

    ## Retrieve the encryption key from environment variables
    encryptionKey = os.getenv("ENCRYPTION_KEY")
    
    ## If the encryption key is not found, raise an error
    if not encryptionKey:
        localSetup.logger.error("ENCRYPTION_KEY not found in environment variables.")
        raise ValueError("ENCRYPTION_KEY not found in environment variables.")

    return encryptionKey

## File Download Function
@retry(max_attempts=5, delay=5, backoff=2.0)
def downloadFile(localSetup: LocalSetup, fileLink, filePathWithName, mode):
    """
    Downloads a file from the given URL to the specified path.
    Automatically retries on failure using the retry decorator.
    """
    ## Define a blank variable for the final file path
    finalFilePathWithName = ""
    ## Shorten filename if path exceeds 255 characters
    if len(filePathWithName) > 255:
        fileName = filePathWithName.split("\\")[-1]
        fileNameWithoutExt = fileName.split(".")[0]
        numCharsToRemove = len(filePathWithName) - 255
        cutoffPoint = len(fileNameWithoutExt) - numCharsToRemove
        newFileName = fileNameWithoutExt[:cutoffPoint] + "." + fileName.split(".")[-1]
        filePathWithoutName = filePathWithName.rsplit("\\", maxsplit=1)[0]
        finalFilePathWithName = filePathWithoutName + "\\" + newFileName
    else:
        finalFilePathWithName = filePathWithName
    ## Ensure the directory exists
    filePathWithoutName = finalFilePathWithName.rsplit("\\", maxsplit=1)[0]
    os.makedirs(filePathWithoutName, mode=0o777, exist_ok=True)
    ## Download the file in chunks
    response = requests.get(fileLink, stream=True, allow_redirects=True)
    if response.status_code != 200:
        raise Exception(f"Failed to download file from URL: {response.url}: HTTP {response.status_code}")
    with open(finalFilePathWithName, 'wb' if mode == "w" else 'ab') as f:
        for chunk in response.iter_content(1024 * 1024 * 2):  ## 2 MiB chunks
            f.write(chunk)
    ## Validate the downloaded file if it's an Excel file
    try:
        if finalFilePathWithName.lower().endswith(".xlsx"):
            if not zipfile.is_zipfile(finalFilePathWithName):
                localSetup.logger.warning(f"Downloaded file is not a valid Excel file. Attempting repair...")
                ## Try reading as CSV and resave as proper Excel
                try:
                    fileDataframe = pd.read_csv(finalFilePathWithName)
                    with pd.ExcelWriter(finalFilePathWithName, engine="openpyxl") as writer:
                        fileDataframe.to_excel(writer, index=False)
                    localSetup.logger.info(f"File repaired")
                    return finalFilePathWithName
                except Exception as e:
                    localSetup.logger.error(f"Repair failed: {e}")
                    raise
        ## If valid or not Excel, return original path
        return finalFilePathWithName
    except Exception as e:
        localSetup.logger.error(f"Validation/repair step failed: {e}")
    return finalFilePathWithName


## This function takes a api header and url and returns the json object of the api call, recursively calling itself in a seperate instance up to 5 times if the call fails
@retry(max_attempts=5, delay=5, backoff=2.0)
def makeApiCall(
    localSetup: LocalSetup, 
    p1_apiUrl,
    p1_header = {'Authorization': f'Bearer {canvasAccessToken}'},
    p1_payload={},
    p1_files={},
    p1_apiCallType="get",
    firstPageOnly=False,
):
    """
    Makes an API call with retry logic.
    Supports GET, POST, PUT, DELETE methods.
    Automatically retries on failure using the retry decorator.
    """
    p1_apiObject = None
    p1_apiObjectList = []
    ## Perform the API call based on type
    if p1_apiCallType.lower() == "get":
        p1_payload.setdefault("per_page", 100)
        p1_apiObject = requests.get(url=p1_apiUrl, headers=p1_header, params=p1_payload)

    elif p1_apiCallType.lower() == "post":
        if p1_payload and p1_files:
            p1_apiObject = requests.post(url=p1_apiUrl, headers=p1_header, json=p1_payload, files=p1_files)
        elif p1_payload:
            p1_apiObject = requests.post(url=p1_apiUrl, headers=p1_header, params=p1_payload)
        else:
            p1_apiObject = requests.post(url=p1_apiUrl, headers=p1_header)

    elif p1_apiCallType.lower() == "put":
        if p1_payload:
            p1_apiObject = requests.put(url=p1_apiUrl, headers=p1_header, json=p1_payload)
        else:
            p1_apiObject = requests.put(url=p1_apiUrl, headers=p1_header)

    elif p1_apiCallType.lower() == "delete":
        if p1_payload:
            p1_apiObject = requests.delete(url=p1_apiUrl, headers=p1_header, params=p1_payload)
        else:
            p1_apiObject = requests.delete(url=p1_apiUrl, headers=p1_header)

    else:
        raise ValueError(f"Unsupported API call type: {p1_apiCallType}")    
    ## Validate response
    ## log the response status code
    if not p1_apiObject.status_code or p1_apiObject.status_code not in [200, 400]:
        if p1_apiObject.status_code:
            ## --- SPECIAL CASE: 409 Conflict for PUT/PATCH ---
            if p1_apiObject.status_code == 409 and p1_apiCallType.lower() in ["put", "patch", "post"]:
                localSetup.logger.warning(f"Received 409 Conflict for {p1_apiCallType.upper()} {p1_apiUrl}. Checking for active existing item...")

                ## Make the GET call to retrieve current index
                indexResponse = makeApiCall(
                    localSetup,
                    p1_apiUrl=p1_apiUrl,
                    p1_header=p1_header,
                    p1_apiCallType="get",
                    firstPageOnly=True,
                )
                indexData = indexResponse.json() if hasattr(indexResponse, "json") else []

                requestedParams = {
                        key[len("parameters["):-1]: value
                        for key, value in p1_payload.items()
                        if key.startswith("parameters[")
                    }
          
                ## Find any active report with matching parameters
                matchingReport = next(
                    (r for r in indexData
                     if r.get("status") in ["running", "pending", "created"]
                     and r.get("parameters", {}) == requestedParams),
                    None
                )                                 
                if matchingReport:
                    localSetup.logger.info("Found active report with matching parameters. Returning its status response instead of retrying.")
                    reportId = matchingReport["id"]
                    statusUrl = f"{p1_apiUrl}/{reportId}"
                    statusResponse = makeApiCall(
                        localSetup,
                        p1_apiUrl=statusUrl,
                        p1_header=p1_header
                    )
                    return statusResponse
                else:
                    localSetup.logger.info(f"409 received but no matching active report with paramters: {requestedParams}, found - retrying normally.")
            try:
                p1_apiObject.close()
            except Exception as close_error:
                localSetup.logger.warning(f"Failed to close API response before retry: {close_error}")
            if p1_apiCallType != "delete":
                raise Exception(f"Failed API call to {p1_apiUrl}: HTTP {p1_apiObject.status_code}")  
            else:
                localSetup.logger.warning(f"Failed to delete resource at {p1_apiUrl}: HTTP {p1_apiObject.status_code}")
                ## Break out of the retry loop for delete calls
                return None
    ## Handle pagination if applicable
    if hasattr(p1_apiObject, 'links') and 'next' in getattr(p1_apiObject, 'links', {}) and not firstPageOnly:
        p1_apiObjectList.append(p1_apiObject)
        next_url = p1_apiObject.links["next"]["url"]
        next_page = makeApiCall(
            localSetup,
            p1_apiUrl=next_url,
            p1_header=p1_header,
            p1_payload=p1_payload,
            p1_files=p1_files,
            p1_apiCallType=p1_apiCallType,
            firstPageOnly=firstPageOnly
        )
        if isinstance(next_page, list):
            p1_apiObjectList.extend(next_page)
        elif next_page:
            p1_apiObjectList.append(next_page)

    return p1_apiObjectList if p1_apiObjectList else p1_apiObject

## Check if a file exists and was modified within the last X hours
def isFileRecent(localSetup: LocalSetup, filePath, maxAgeHours=3.5):
    functionName = "isFileRecent"
    try:

        ## If the file does not exist, return False
        if not os.path.exists(filePath):
            if localSetup.logger:
                localSetup.logger.info(f"\n{filePath} does not exist.")
            return False

        ## Get the last modified time and calculate age in hours
        lastModified = os.path.getmtime(filePath)
        fileAgeHours = (datetime.now() - datetime.fromtimestamp(lastModified)).total_seconds() / 3600

        ## Log and return based on file age
        if fileAgeHours < maxAgeHours:
            if localSetup.logger:
                localSetup.logger.info(f"\n{filePath} is recent ({fileAgeHours:.2f} hours old).")
            return True
        else:
            if localSetup.logger:
                localSetup.logger.info(f"\n{filePath} is outdated ({fileAgeHours:.2f} hours old).")
            return False
    except Exception as Error:
        ## Log any unexpected errors
        if localSetup.logger:
            localSetup.logger.error(f"Couldn't determine file age. Error: {Error}")
        return False

## Load Excel File with Multiple Strategies
def loadExcelFile(filePath, sheetName=None):
    """
    Attempts to load an Excel file using multiple strategies.
    
    Parameters:
        filePath (str): Path to the Excel file.
        sheetName (str or None): Sheet name to read. If None, reads all sheets.
    
    Returns:
        pd.DataFrame or dict of DataFrames: Loaded data, or None if failed.
    """
    ## Validate file existence
    if not os.path.exists(filePath):
        raise FileNotFoundError(f"File not found: {filePath}")
    
    ## Validate file size
    if os.path.getsize(filePath) == 0:
        raise ValueError(f"File is empty: {filePath}")
    
    ## Validate extension
    if not filePath.lower().endswith((".xlsx", ".xls")):
        raise ValueError(f"Invalid file type. Expected Excel (.xlsx or .xls), got: {filePath}")
    
    ## Try multiple engines
    engines = ["openpyxl", "xlrd"]
    lastError = None
    
    for engine in engines:
        try:
            print(f"Trying engine: {engine}")
            excelFile = pd.ExcelFile(filePath, engine=engine)
            
            ## If sheetName is None, return all sheets as dict
            if sheetName is None:
                return {sheet: excelFile.parse(sheet) for sheet in excelFile.sheet_names}
            else:
                return excelFile.parse(sheetName)
        
        except Exception as e:
            lastError = e
            print(f"Engine {engine} failed: {e}")
    
    ## If all attempts fail
    raise RuntimeError(f"Failed to load Excel file after trying all engines. Last error: {lastError}")

## Helper function to determine if a value is missing/NA based on multiple criteria
def isMissing(value):
    """
    Returns True if the value should be considered 'missing'.
    Handles:
    - None
    - NaN / pd.NA / numpy.nan
    - empty string ""
    - whitespace-only strings
    - strings that spell 'nan' (case-insensitive)
    """

    ## String-like values -> normalize and check
    if isinstance(value, str):
        stripped = value.strip()

        ## Empty or whitespace-only
        if stripped == "":
            return True

        ## Literal "nan", any casing
        if stripped.lower() == "nan":
            return True

    ## True NaN / None / pd.NA -> missing
    if pd.isna(value):
        return True

    return False

## Inverse helper function to determine if a value is present (not missing)
def isPresent(value):
    """Inverse helper for convenience."""
    return not isMissing(value)


## ===========================================================================
## FILE: ResourceModules\__init__.py
## ===========================================================================




## ===========================================================================
## FILE: __init__.py
## ===========================================================================


